:description: This section describes how to recover databases that have become unavailable.
[role=enterprise-edition]
[[cluster-recovery]]
= Disaster recovery

A database can become unavailable due to issues on different system levels.
For example, a data center failover may lead to the loss of multiple servers, which may cause a set of databases to become unavailable.

This section contains a step-by-step guide on how to recover *unavailable databases* that are incapable of serving writes, while possibly still being able to serve reads.
The guide recovers the unavailable databases and make them fully operational, with minimal impact on the other databases in the cluster.
However, if a database is not performing as expected for other reasons, this section cannot help.

[CAUTION]
====
If *all* servers in a Neo4j cluster are lost in a disaster, it is not possible to recover the current cluster.
You have to create a new cluster and restore the databases, see xref:clustering/setup/deploy.adoc[Deploy a basic cluster] and xref:clustering/databases.adoc#cluster-seed[Seed a database] for more information.
====

== Faults in clusters

Databases in clusters follow an allocation strategy.
This means that they are allocated differently within the cluster and may also have different numbers of primaries and secondaries.
The consequence of this is that all servers may be different in which databases they are hosting.
Losing a server in a cluster may cause some databases to lose a member while others are unaffected.
Therefore, in a disaster where one or more servers go down, some databases may keep running with little to no impact, while others may lose all their allocated resources.

== Guide structure
[NOTE]
====
In this guide, an _offline_ server is a server that is not running but may be restartable.
A _lost_ server, however, is a server that is currently not running and cannot be restarted.
A _write available_ database is able to serve writes, while a _write unavailable_ database is not.
====

There are three main steps to recovering a cluster from a disaster.
First, ensure the `system` database is write available.
Then, detach any potential lost servers from the cluster and replace them by new ones.
Finish disaster recovery by starting or continuing to manage databases and verify that they are write available.

Every step consists of the following three sections:

. A state that needs to be verified, with optional motivation.
. An example of how the state can be verified.
. A proposed series of steps to get to the correct state.

[CAUTION]
====
Verifying each state before continuing to the next step, regardless of the disaster scenario, is recommended to ensure the cluster is fully operational.
====


== Guide to disaster recovery

[NOTE]
====
Disasters may sometimes affect the routing capabilities of the driver and may prevent the use of the `neo4j` scheme for routing.
One way to remedy this is to connect directly to the server using `bolt` instead of `neo4j`.
See xref:clustering/setup/routing.adoc#clustering-routing[Server-side routing] for more information on the `bolt` scheme.
====

=== Neo4j process started

==== State
====
The Neo4j process is started on all servers which are not _lost_.
====

==== Path to correct state
Start the Neo4j process on all servers that are _offline_.
If a server is unable to start, inspect the logs and contact support personnel.
The server may have to be considered indefinitely lost.

[[restore-the-system-database]]
=== `System` database write availability

==== State
====
The `system` database is write available.
====

The `system` database contains the view of the cluster.
This includes which servers and databases are present, where they live and how they are configured.
During a disaster, the view of the cluster might need to change to reflect a new reality, for example by removing lost servers.
Databases might also need to be recreated to regain write availability.
Because both of these steps are executed by modifying the `system` database, making the `system` database write available is a vital first step during disaster recovery.

==== Example verification
The `system` database's write availability can be verified by using the xref:clustering/monitoring/status-check.adoc#monitoring-replication[Status check] procedure.
The procedure should be called on all remaining primary allocations of the `system` database, in order to provide the correct view.
The default timeout for the procedure is 1 second, but depending on the network latency in the environment it might need to be extended to produce an accurate result.
If any of the primary `system` allocations report `replicationSuccessful` = `TRUE`, the `system` database is write available.
Therefore, the desired state has been verified.

[source, shell]
----
CALL dbms.cluster.statusCheck(["system"]);
----

[NOTE]
=====
The write availability of a database configured to have a single primary cannot be checked with the status check, instead check that the primary is allocated on an available server and that it has `currentStatus` = `STARTED`.
The procedure will still produce an accurate result if all but one primary have been lost during a disaster.
=====

==== Path to correct state
The following steps can be used to regain write availability for the `system` database if it has been lost.
They create a new `system` database from the most up-to-date copy of the `system` database that can be found in the cluster.
It is important to get a `system` database that is as up-to-date as possible, so it corresponds to the view before the disaster closely.

.Guide
[%collapsible]
====

[NOTE]
=====
This section of the disaster recovery guide uses `neo4j-admin`, for more information about the used commands, see xref:tools/neo4j-admin/index.adoc#neo4j-admin-commands[neo4j-admin commands].
=====

. Shut down the Neo4j process on all servers.
This causes downtime for all databases in the cluster until the processes are started again at the end of this section.
. On each server, run `bin/neo4j-admin dbms unbind-system-db` to reset the `system` database state on the servers.
. On each server, run `bin/neo4j-admin database info system` and compare the `lastCommittedTransaction` to find out which server has the most up-to-date copy of the `system` database.
. On the most up-to-date server, run `bin/neo4j-admin database dump system --to-path=[path-to-dump]` to take a dump of the current `system` database and store it in an accessible location.
. For every _lost_ server, add a new *unconstrained* one according to xref:clustering/servers.adoc#cluster-add-server[Add a server to the cluster].
It is important that the new servers are unconstrained, or deallocating servers in the next step of this guide might be blocked, even though enough servers were added.
+
[NOTE]
=====
While recommended, it is not strictly necessary to add new servers in this step.
There is also an option to change the `system` database mode (`server.cluster.system_database_mode`) on secondary allocations to make them primary allocations for the new `system` database.
The amount of primary allocations needed is defined by `dbms.cluster.minimum_initial_system_primaries_count`, see the xref:configuration/configuration-settings.adoc#config_dbms.cluster.minimum_initial_system_primaries_count[Configuration settings] for more information.
Be aware that not replacing servers can cause cluster overload when databases are moved from lost servers to available ones in the next step of this guide.
=====
+
. On each server, run `bin/neo4j-admin database load system --from-path=[path-to-dump] --overwrite-destination=true` to load the current `system` database dump.
. On each server, ensure that the discovery settings are correct, see xref:clustering/setup/discovery.adoc[Cluster server discovery] for more information.
. Start the Neo4j process on all servers.
====


[[recover-servers]]
=== Server availability

==== State
====
All servers in the cluster's view are available and enabled.
====

A lost server will still be in the `system` database's view of the cluster, but in an unavailable state.
Furthermore, according to the view of the cluster, these lost servers are still hosting the databases they had before they became lost.
Therefore, informing the cluster of servers which are lost is not enough.
The databases hosted on lost servers also need to be moved onto available servers in the cluster, before the lost servers can be removed.

==== Example verification
The cluster's view of servers can be seen by listing the servers, see xref:clustering/servers.adoc#_listing_servers[Listing servers] for more information.
The state has been verified if *all* servers show `health` = `AVAILABLE` and `status` = `ENABLED`.

[source, cypher]
----
SHOW SERVERS;
----

==== Path to correct state
The following steps can be used to remove lost servers and add new ones to the cluster.
That includes moving any potential database allocations from lost servers to available servers.
These steps might also recreate some databases, since a database which has lost a majority of its primary allocations cannot be moved from one server to another.

.Guide
[%collapsible]
====
. For each `UNAVAILABLE` server, run `CALL dbms.cluster.cordonServer("unavailable-server-id")` on one of the available servers.
This prevents new database allocations from being moved to this server.
. For each `CORDONED` server, make sure a new *unconstrained* server has been added to the cluster to take its place, see xref:clustering/servers.adoc#cluster-add-server[Add a server to the cluster] for more information.
If servers were added in the 'System database write availability' step of this guide, additional servers might not be needed here.
It is important that the new servers are unconstrained, or deallocating servers might be blocked even though enough servers were added.
+
[NOTE]
=====
While recommended, it is not strictly necessary to add new servers in this step.
However, not adding new servers reduces the capacity of the cluster to handle work.
Furthermore, it might require the topology for a database to be altered to make deallocating servers and recreating databases possible.
=====

. For each stopped database (`currentStatus`= `offline`), start them by running `START DATABASE stopped-db`.
This is necessary since stopped databases cannot be moved from one server to another.
Verify that they are in `currentStatus` = `started` on all servers which are not lost before moving to the next step, otherwise they might be recreated unnecessarily.
If a database fails to start, leave it to be recreated in the next step of this guide.
+
[NOTE]
=====
A database can be set to `READ-ONLY` before it is started to avoid updates on a database that is desired to be stopped with the following command:
`ALTER DATABASE database-name SET ACCESS READ ONLY`.
=====

. On each server, run `CALL dbms.cluster.statusCheck([])` to check the write availability for all databases running in primary mode on this server, see xref:clustering/monitoring/status-check.adoc#monitoring-replication[Monitoring replication] for more information.
Depending on the network latency in the environment, consider extending the timeout for this procedure to produce an accurate result.
If any of the primary allocations for a database report `replicationSuccessful` = `TRUE`, this database is write available.
+
[NOTE]
=====
The write availability of a database configured to have a single primary cannot be checked with the status check, instead check that the primary is allocated on an available server and that it has `currentStatus` = `STARTED`.
The procedure will still produce an accurate result if all but one primary have been lost during a disaster.
=====

. For each database that is not write available, recreate it to move it from lost servers and regain write availability.
Go to xref:clustering/databases.adoc#recreate-databases[Recreate databases] for more information about recreate options.
Remember to make sure there are recent backups for the databases before recreating them, see xref:backup-restore/online-backup.adoc[Online backup] for more information.
If any database has `currentStatus` = `QUARANTINED` on an available server, recreate them from backup using xref:clustering/databases.adoc#uri-seed[Backup as seed].
+
[NOTE]
=====
By using recreate with xref:clustering/databases.adoc#undefined-servers-backup[Undefined servers with fallback backup], the store will be replaced by the most up-to-date copy according to the cluster's view without manual intervention.
Furthermore, this option will automatically recreate the database based on a backup if no available allocation can be found.
=====

. For each `CORDONED` server, run `DEALLOCATE DATABASES FROM SERVER cordoned-server-id` on one of the available servers.
This will try to move all database allocations from this server to an available server in the cluster.
+
[NOTE]
=====
This operation might fail if enough unconstrained servers were not added to the cluster to replace lost servers.
Another reason is that some available servers are also `CORDONED`.
=====

. For each deallocating or deallocated server, run `DROP SERVER deallocated-server-id`.
This removes the server from the cluster's view.
====


[[recover-databases]]
=== Database availability

==== State
====
All databases which are desired to be started are write available.
====

Once this state is verified, disaster recovery is complete.
However, remember that previously stopped databases might have been started during this process.
If they are still desired to be in stopped state, run `STOP DATABASE started-db WAIT`.

[CAUTION]
====
Remember, recreating a database takes an unbounded amount of time since it may involve copying the store to a new server, as described in xref:clustering/databases.adoc#recreate-databases[Recreate databases].
Therefore, an allocation with `currentStatus` = `STARTING` will probably reach the `requestedStatus` given some time.
====

[[example-verification]]
==== Example verification
All databases' write availability can be verified by using the xref:clustering/monitoring/status-check.adoc#monitoring-replication[Status check] procedure.
The procedure should be called on all servers in the cluster, in order to provide the correct view.
The default timeout for the procedure is 1 second, but depending on the network latency in the environment it might need to be extended to produce an accurate result.
If any of the primary allocations for a database report `replicationSuccessful` = `TRUE`, this database is write available.
Therefore, the desired state has been verified when this is true for all *started* databases.

[source, shell]
----
CALL dbms.cluster.statusCheck([]);
----

[NOTE]
=====
The write availability of a database configured to have a single primary cannot be checked with the status check, instead check that the primary is allocated on an available server and that it has `currentStatus` = `STARTED`.
The procedure will still produce an accurate result if all but one primary have been lost during a disaster.
=====

A stricter verification can be done to verify that all databases are in their desired states on all servers.
For the stricter check, run `SHOW DATABASES` and verify that `requestedStatus` = `currentStatus` for all database allocations on all servers.

==== Path to correct state
The following steps can be used to make all databases in the cluster write available again.
They include recreating any databases that are not write available, as well as identifying any recreations which will not complete.
Recreations might fail for different reasons, but one example is that the checksums does not match for the same transaction on different copies.

.Guide
[%collapsible]
====
. Identify all write unavailable databases that are desired to be `STARTED` by running `CALL dbms.cluster.statusCheck([])` as described in the xref:clustering/disaster-recovery.adoc#example-verification[Example verification] part of this disaster recovery step.
. Recreate every database that is not write available and has not been recreated previously, see xref:clustering/databases.adoc#recreate-databases[Recreate databases] for more information.
Remember to make sure there are recent backups for the databases before recreating them, see xref:backup-restore/online-backup.adoc[Online backup] for more information.
If any database has `currentStatus` = `QUARANTINED` on an available server, recreate them from backup using xref:clustering/databases.adoc#uri-seed[Backup as seed].
+
[NOTE]
=====
By using recreate with xref:clustering/databases.adoc#undefined-servers-backup[Undefined servers with fallback backup], the store will be replaced by the most up-to-date copy according to the cluster's view without manual intervention.
Furthermore, this option will automatically recreate the database based on a backup if no available allocation can be found.
=====

. Run `SHOW DATABASES` and check any recreated databases which are not write available.
Recreating a database will not complete if one of the following messages is displayed in the message field:
** `Seeders ServerId1 and ServerId2 have different checksums for transaction TransactionId. All seeders must have the same checksum for the same append index.`
** `Seeders ServerId1 and ServerId2 have incompatible storeIds. All seeders must have compatible storeIds.`
** `No store found on any of the seeders ServerId1, ServerId2...`
. For each database which will not complete recreation, recreate them from backup using xref:clustering/databases.adoc#uri-seed[Backup as seed].

====
