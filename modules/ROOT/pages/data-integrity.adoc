= Data consistency and maintenance
:description: Transaction logs, checkpointing, and log pruning. The retention and rotation policies for the Neo4j transaction logs, and how to configure them.


[[transaction-logging]]
== Transaction logging

Neo4j keeps track of all write operations to each database to ensure data consistency and enable recovery.
This process is called _transaction logging_ and is enabled by default.

[[transaction-log-files]]
== Transaction log files

A transaction log file contains a sequence of records with all changes made to a particular database as part of each transaction, including data, indexes, and constraints.

The transaction log serves multiple purposes, including providing differential backups and supporting cluster operations. At a minimum, the most recent non-empty transaction log is retained for any given configuration.
It is important to note that transaction logs are unrelated to log monitoring.

[[transaction-logging-config]]
== Configure transaction logging

The transaction logging configuration is set per database and can be configured using the following configuration settings:

[[transaction-logging-log-location]]
=== Log location

By default, transaction logs for a database are located at  _<neo4j-home>/data/transactions/<database-name>_.

The root directory where those folders are located is configured by xref:configuration/configuration-settings.adoc#config_server.directories.transaction.logs.root[`server.directories.transaction.logs.root`].
The value is a path.
If relative, it is resolved from `server.directories.data`.
For maximum performance, it is recommended to configure transaction logs to be stored on a dedicated device.

[[transaction-logging-log-prealocation]]
=== Log preallocation

You can specify if Neo4j should try to preallocate logical log files in advance using the parameter xref:configuration/configuration-settings.adoc#config_db.tx_log.preallocate[`db.tx_log.preallocate`].
By default, it is `true`.
Log preallocation optimizes the filesystem by ensuring there is room to accommodate newly generated files and avoid file-level fragmentation.
This configuration setting is Dynamic and can be changed at runtime.

[[transaction-logging-log-rotation]]
=== Log rotation

At which file size the logical log should auto-rotate is configured using the parameter xref:configuration/configuration-settings.adoc#config_db.tx_log.rotation.size[`db.tx_log.rotation.size`].
By default, log switches happen when log sizes surpass 250 MB.
The minimum accepted value is `128K` (128 KiB).
This configuration setting is Dynamic and can be changed at runtime.

[[transaction-logging-log-retention]]
=== Log retention

[WARNING]
====
Manually deleting transaction log files is not supported.
====

You can control the number of transaction logs that Neo4j keeps to back up the database using the parameter xref:configuration/configuration-settings.adoc#config_db.tx_log.rotation.retention_policy[`db.tx_log.rotation.retention_policy`].
This configuration setting is Dynamic and can be changed at runtime.

By default, it is set to `2 days`, which means Neo4j keeps logical logs that contain any transaction committed within 2 days and prunes the ones that only contain transactions older than 2 days.

Other possible ways to configure the log retention policy are:

* `db.tx_log.rotation.retention_policy=true|keep_all` -- keep transaction logs indefinitely.
+
[NOTE]
====
This option is not recommended due to the effectively unbounded storage usage.
Old transaction logs cannot be safely archived or removed by external jobs since safe log pruning requires knowledge about the most recent successful checkpoint.
For more information, see <<checkpointing>>.
====

* `db.tx_log.rotation.retention_policy=false|keep_none` -- keep only the most recent non-empty log.
+
Log pruning is called only after checkpoint completion to ensure at least one checkpoint and points to a valid place in the transaction log data.
In reality, this means that all transaction logs created between checkpoints are kept for some time, and only after a checkpoint, the pruning strategy removes them.
For more details on how to speed up checkpointing, see <<transaction-logging-log-pruning>>.
To force a checkpoint, run the procedure xref:reference/procedures.adoc#procedure_db_checkpoint[`CALL db.checkpoint()`].
+
[NOTE]
====
This option is not recommended in production Enterprise Edition environments, as <<differential-backup, differential backups>> rely on the presence of the transaction logs since the last backup.
====

* `<number><optional unit> <type>` where valid units are `k`, `M`, and `G`, and valid types are `files`, `size`, `txs`, `entries`, `hours`, and `days`.
+
.Types that can be used to control log retention
[options="header",cols="<5,<45,<50"]
|===

| Type
| Description
| Example

| files
| The number of the most recent logical log files to keep.
m| db.tx_log.rotation.retention_policy=10 files

| size
| Max disk size to allow log files to occupy.
m| db.tx_log.rotation.retention_policy=300M size

| txs
| The number of transactions to keep.
If set, the policy keeps the 500k txs latest transactions from each database and prunes any older transactions.
m| db.tx_log.rotation.retention_policy=500k txs


| hours
| Keep logs that contain any transaction committed within N hours from the current time.
m| db.tx_log.rotation.retention_policy=10 hours

| days
| Keep logs that contain any transaction committed within N days from the current time.
m| db.tx_log.rotation.retention_policy=30 days
|===

[[checkpointing-log-pruning]]
== Checkpointing and log pruning

Checkpointing refers to the procedure of transferring all pending updates of pages from the page cache to the storage files.
This action is crucial to limit the number of transactions that need to be replayed during the recovery process, particularly in order to minimize the time required for recovery after an improper shutdown.

Despite the presence of checkpoints, database operations remain secure, as any transactions that have not been confirmed to have their modifications persisted to storage will be replayed upon the next database startup.
However, this assurance is contingent upon the availability of the collection of changes comprising these transactions, which is maintained in the transaction logs.

Maintaining a long list of unapplied transactions (due to infrequent checkpoints) leads to the accumulation of transaction logs, as they are essential for recovery purposes.
Checkpointing involves the inclusion of a special "Checkpointing" entry in the transaction log, marking the last transaction at which checkpointing occurred.
This entry serves the purpose of identifying transaction logs that are no longer necessary, as all the transactions they contain have been securely stored in the storage files.

The process of eliminating transaction logs that are no longer required for recovery is known as pruning. From the aforementioned explanation, it becomes evident that pruning is reliant on checkpointing.
In other words, checkpointing determines which logs can be pruned and determines the occurrence of pruning, as the absence of a checkpoint implies that the set of transaction log files available for pruning cannot have changed.
Consequently, pruning is triggered whenever checkpointing takes place, with or without a specific verification of their existence.

=== Triggering of checkpointing (and pruning) events

The checkpointing policy, which is the driving event for pruning is configured by xref:configuration/configuration-settings.adoc#config_db.checkpoint[`db.checkpoint`] and can be triggered in a few different ways:

* `PERIODIC` label:default[Default]
+
By default, this policy checks every 15 minutes whether there are changes pending flushing (i.e. transactions that have not been checkpointed yet).
If so, it performs a checkpoint and subsequently triggers a log prune.
Note that no checkpointing is being performed implying no pruning happens.
This is the default behavior and the only one available in Community Edition.

* `CONTINUOUS` label:enterprise[Enterprise Edition]
This policy constantly checks if a checkpoint is possible (i.e if any transactions committed since the last successful checkpoint) and if so, it performs it.
* Pruning is triggered immediately after it completes, just like in the periodic policy.

* `VOLUMETRIC` label:enterprise[Enterprise Edition]
This checkpointing policy checks every 10 seconds if any logs are available for pruning and, if so, it triggers a checkpoint and subsequently, it prunes the logs.
This policy appears to invert the control between checkpointing and pruning, but in reality, it only changes the criteria for when checkpointing must happen.
Instead of relying on a time trigger, as in the previous two, it relies on a pruning check.
Pruning will still happen after checkpointing has occurred, as with the other two policies.
Nevertheless, since the check depends on the existence of prunable transaction log files, this policy depends on pruning configuration.

[[transaction-logging-log-pruning]]
=== Configure log pruning

Transaction log pruning refers to the safe and automatic removal of old, unnecessary transaction log files.
The transaction log can be pruned when one or more files fall outside of the configured retention policy.

Two things are necessary for a file to be removed:

* The file must have been rotated.
* At least one checkpoint must have happened in a more recent log file.

Observing that you have more transaction log files than you expected is likely due to checkpoints either not happening frequently enough, or taking too long.
This is a temporary condition and the gap between the expected and the observed number of log files will be closed on the next successful checkpoint.
The interval between checkpoints can be configured using:

[cols="3", options="header"]
|===
| Checkpoint configuration
| Default value
| Description

| xref:configuration/configuration-settings.adoc#config_db.checkpoint.interval.time[`db.checkpoint.interval.time`]
| `15m`
| Configures the time interval between checkpoints.

| xref:configuration/configuration-settings.adoc#config_db.checkpoint.interval.tx[`db.checkpoint.interval.tx`]
| `100000`
| Configures the transaction interval between checkpoints.
|===

=== Controlling transaction log pruning

Transaction log pruning configuration primarily deals with specifing the number of transaction logs that should remain available. The primary reason for leaving more than the absolute minimum amount required for recovery comes from requirements of clustered deployments and online backup. Since database updates are communicated between cluster members and backup clients through the transaction logs, keeping more than the minimum amount necessary allows for transferring just the incremental changes (in the form of transactions) instead of the whole store files, which can lead to substantial savings in time and network bandwidth. This is true for HA deployments, backups and Read Replicas in Causal Clusters. However, in the case of Core members in Causal Clustering it is not the transaction logs that matter, but rather the Raft log contents. That scenario is covered in a separate KB article.

The amount of transaction logs left after a pruning operation is controlled by the setting `dbms.tx_log.rotation.retention_policy` and it can take a variety of values. They are of the form `<numerical value> <measurement>`.

`<measurement>` can be "files", "size", "txs", "entries", "hours", or "days".

* *"files"* determines the minimum number of transaction log files left after pruning. That means that once the checkpoint is performed, a number of log files will be deleted to leave at least as many as specified - for example the value "5 files" will leave at least 5 files of transaction logs.
* *"size"* behaves similarly but instead of counting files, it counts total file size. For example, "500M size" will leave at least 500M worth of files behind.
* *"txs"* and *"entries"* are synonymous. They behave similarly to the above but they count transactions present in the files, regardless of file count or size. "100 txs" will leave at least 100 transactions worth of logs unpruned after every operation.
* *"hours"* and *"days"* measure time instead of size or transaction count, but otherwise behave similarly. Setting the value to "20 hours" will ensure that at least 20 hours' worth of transactions will be present in the logs.

If your goal is to have the least amount of transaction log data, it can also help to speed up the checkpoint process itself.
The configuration parameter xref:configuration/configuration-settings.adoc#config_db.checkpoint.iops.limit[`db.checkpoint.iops.limit`] controls the number of IOs per second the checkpoint process is allowed to use.
Setting the value of this parameter to `-1` allows unlimited IOPS, which can speed up checkpointing.

[NOTE]
====
Disabling the IOPS limit can cause transaction processing to slow down a bit.
For more information, see xref:performance/disks-ram-and-other-tips.adoc#performance-checkpoint-iops-limit[Checkpoint IOPS limit].
====


=== Checkpoint logging and metrics

The following details the expected messages to appear in the _logs\debug.log_ upon a checkpoint event:

* Checkpoint based upon `db.checkpoint.interval.time`:
+
....
2019-08-28 12:55:05.174+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by "Scheduled checkpoint for time threshold" @ txId: 49 checkpoint started...
2019-08-28 12:55:05.253+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by "Scheduled checkpoint for time threshold" @ txId: 49 checkpoint completed in 79ms
....

* Checkpoint based upon `db.checkpoint.interval.tx`:
+
....
2019-08-28 13:08:51.603+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by "Scheduled checkpoint for tx count threshold" @ txId: 118 checkpoint started...
2019-08-28 13:08:51.669+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by "Scheduled checkpoint for tx count threshold" @ txId: 118 checkpoint completed in 66ms
....

* Checkpoint when `db.checkpoint=continuous`:
+
....
2019-08-28 13:17:21.927+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by "Scheduled checkpoint for continuous threshold" @ txId: 171 checkpoint started...
2019-08-28 13:17:21.941+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by "Scheduled checkpoint for continuous threshold" @ txId: 171 checkpoint completed in 13ms
....

* Checkpoint as a result of database shutdown:
_
....
2019-08-28 12:35:56.272+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by "Database shutdown" @ txId: 47 checkpoint started...
2019-08-28 12:35:56.306+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by "Database shutdown" @ txId: 47 checkpoint completed in 34ms
....

* Checkpoint as a result of `CALL db.checkpoint()`:
+
....
2019-08-28 12:31:56.463+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by "Call to dbms.checkpoint() procedure" @ txId: 47 checkpoint started...
2019-08-28 12:31:56.490+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by "Call to dbms.checkpoint() procedure" @ txId: 47 checkpoint completed in 27ms
....

Checkpoint as a result of a backup run

....
2019-08-28 12:33:30.489+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by "Full backup" @ txId: 47 checkpoint started...
2019-08-28 12:33:30.509+0000 INFO [o.n.k.i.t.l.c.CheckPointerImpl] Checkpoint triggered by "Full backup" @ txId: 47 checkpoint completed in 20ms
....

https://neo4j.com/docs/operations-manual/current/monitoring/metrics/reference/#metrics-general-purpose[Checkpoint Metrics] are also available and are detailed in `metrics/` and the following files

....
neo4j.check_point.check_point_duration.csv
neo4j.check_point.total_time.csv
neo4j.check_point.events.csv
....

== Check the contents of a transaction log

The `neo4j-admin` tool can be used to inspect the contents of a transaction log file.
This can be useful for debugging purposes, for example, to check if a transaction log file contains a specific transaction or an update of a specific node or relationship, or a property with a specific value.