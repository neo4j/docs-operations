[[configuration-settings]]
= Configuration settings
:description: This page provides a complete reference to the Neo4j configuration settings. 

This page provides a complete reference to the Neo4j configuration settings, which can be set in xref::/configuration/file-locations.adoc#file-locations[_neo4j.conf_].
Refer to xref::/configuration/neo4j-conf.adoc#neo4j-conf[The neo4j.conf file] for details on how to use configuration settings.

[[settings-reference-all-settings]]
.All settings
ifndef::nonhtmloutput[]
[options="header"]
|===
|Name|Description
|<<config_browser.allow_outgoing_connections,browser.allow_outgoing_connections>>|label:enterprise-edition[Enterprise only]Configure the policy for outgoing Neo4j Browser connections.
|<<config_browser.credential_timeout,browser.credential_timeout>>|label:enterprise-edition[Enterprise only]Configure the Neo4j Browser to time out logged in users after this idle period.
|<<config_browser.post_connect_cmd,browser.post_connect_cmd>>|Commands to be run when Neo4j Browser successfully connects to this server.
|<<config_browser.remote_content_hostname_whitelist,browser.remote_content_hostname_whitelist>>|Whitelist of hosts for the Neo4j Browser to be allowed to fetch content from.
|<<config_browser.retain_connection_credentials,browser.retain_connection_credentials>>|label:enterprise-edition[Enterprise only]Configure the Neo4j Browser to store or not store user credentials.
|<<config_browser.retain_editor_history,browser.retain_editor_history>>|label:enterprise-edition[Enterprise only]Configure the Neo4j Browser to store or not store user editor history.
|<<config_client.allow_telemetry,client.allow_telemetry>>|Configure client applications such as Browser and Bloom to send Product Analytics data.
|<<config_db.checkpoint,db.checkpoint>>|Configures the general policy for when check-points should occur.
|<<config_db.checkpoint.interval.time,db.checkpoint.interval.time>>|Configures the time interval between check-points.
|<<config_db.checkpoint.interval.tx,db.checkpoint.interval.tx>>|Configures the transaction interval between check-points.
|<<config_db.checkpoint.interval.volume,db.checkpoint.interval.volume>>|Configures the volume of transaction logs between check-points.
|<<config_db.checkpoint.iops.limit,db.checkpoint.iops.limit>>|Limit the number of IOs the background checkpoint process will consume per second.
|<<config_db.cluster.catchup.pull_interval,db.cluster.catchup.pull_interval>>|label:enterprise-edition[Enterprise only]Interval of pulling updates from cores.
|<<config_db.cluster.raft.apply.buffer.max_bytes,db.cluster.raft.apply.buffer.max_bytes>>|label:enterprise-edition[Enterprise only]The maximum number of bytes in the apply buffer.
|<<config_db.cluster.raft.apply.buffer.max_entries,db.cluster.raft.apply.buffer.max_entries>>|label:enterprise-edition[Enterprise only]The maximum number of entries in the raft log entry prefetch buffer.
|<<config_db.cluster.raft.in_queue.batch.max_bytes,db.cluster.raft.in_queue.batch.max_bytes>>|label:enterprise-edition[Enterprise only]Largest batch processed by RAFT in bytes.
|<<config_db.cluster.raft.in_queue.max_bytes,db.cluster.raft.in_queue.max_bytes>>|label:enterprise-edition[Enterprise only]Maximum number of bytes in the RAFT in-queue.
|<<config_db.cluster.raft.leader_transfer.priority_group,db.cluster.raft.leader_transfer.priority_group>>|label:enterprise-edition[Enterprise only]The name of a server_group whose members should be prioritized as leaders.
|<<config_db.cluster.raft.log.prune_strategy,db.cluster.raft.log.prune_strategy>>|label:enterprise-edition[Enterprise only]RAFT log pruning strategy that determines which logs are to be pruned.
|<<config_db.cluster.raft.log_shipping.buffer.max_bytes,db.cluster.raft.log_shipping.buffer.max_bytes>>|label:enterprise-edition[Enterprise only]The maximum number of bytes in the in-flight cache.
|<<config_db.cluster.raft.log_shipping.buffer.max_entries,db.cluster.raft.log_shipping.buffer.max_entries>>|label:enterprise-edition[Enterprise only]The maximum number of entries in the in-flight cache.
|<<config_db.filewatcher.enabled,db.filewatcher.enabled>>|Allows the enabling or disabling of the file watcher service.
|<<config_db.format,db.format>>|Database format.
|<<config_db.import.csv.buffer_size,db.import.csv.buffer_size>>|The size of the internal buffer in bytes used by `LOAD CSV`.
|<<config_db.import.csv.legacy_quote_escaping,db.import.csv.legacy_quote_escaping>>|Selects whether to conform to the standard https://tools.ietf.org/html/rfc4180 for interpreting escaped quotation characters in CSV files loaded using `LOAD CSV`.
|<<config_db.index.fulltext.default_analyzer,db.index.fulltext.default_analyzer>>|The name of the analyzer that the fulltext indexes should use by default.
|<<config_db.index.fulltext.eventually_consistent,db.index.fulltext.eventually_consistent>>|Whether or not fulltext indexes should be eventually consistent by default or not.
|<<config_db.index.fulltext.eventually_consistent_index_update_queue_max_length,db.index.fulltext.eventually_consistent_index_update_queue_max_length>>|The eventually_consistent mode of the fulltext indexes works by queueing up index updates to be applied later in a background thread.
|<<config_db.index_sampling.background_enabled,db.index_sampling.background_enabled>>|Enable or disable background index sampling.
|<<config_db.index_sampling.sample_size_limit,db.index_sampling.sample_size_limit>>|Index sampling chunk size limit.
|<<config_db.index_sampling.update_percentage,db.index_sampling.update_percentage>>|Percentage of index updates of total index size required before sampling of a given index is triggered.
|<<config_db.lock.acquisition.timeout,db.lock.acquisition.timeout>>|The maximum time interval within which lock should be acquired.
|<<config_db.logs.query.early_raw_logging_enabled,db.logs.query.early_raw_logging_enabled>>|Log query text and parameters without obfuscating passwords.
|<<config_db.logs.query.enabled,db.logs.query.enabled>>|Log executed queries.
|<<config_db.logs.query.max_parameter_length,db.logs.query.max_parameter_length>>|Sets a maximum character length use for each parameter in the log.
|<<config_db.logs.query.obfuscate_literals,db.logs.query.obfuscate_literals>>|Obfuscates all literals of the query before writing to the log.
|<<config_db.logs.query.parameter_logging_enabled,db.logs.query.parameter_logging_enabled>>|Log parameters for the executed queries being logged.
|<<config_db.logs.query.plan_description_enabled,db.logs.query.plan_description_enabled>>|Log query plan description table, useful for debugging purposes.
|<<config_db.logs.query.threshold,db.logs.query.threshold>>|If the execution of query takes more time than this threshold, the query is logged once completed - provided query logging is set to INFO.
|<<config_db.logs.query.transaction.enabled,db.logs.query.transaction.enabled>>|Log the start and end of a transaction.
|<<config_db.logs.query.transaction.threshold,db.logs.query.transaction.threshold>>|If the transaction is open for more time than this threshold, the transaction is logged once completed - provided transaction logging (db.logs.query.transaction.enabled) is set to `INFO`.
|<<config_db.memory.pagecache.warmup.enable,db.memory.pagecache.warmup.enable>>|Page cache can be configured to perform usage sampling of loaded pages that can be used to construct active load profile.
|<<config_db.memory.pagecache.warmup.preload,db.memory.pagecache.warmup.preload>>|Page cache warmup can be configured to prefetch files, preferably when cache size is bigger than store size.
|<<config_db.memory.pagecache.warmup.preload.allowlist,db.memory.pagecache.warmup.preload.allowlist>>|Page cache warmup prefetch file allowlist regex.
|<<config_db.memory.pagecache.warmup.profile.interval,db.memory.pagecache.warmup.profile.interval>>|The profiling frequency for the page cache.
|<<config_db.memory.transaction.max,db.memory.transaction.max>>|Limit the amount of memory that a single transaction can consume, in bytes (or kilobytes with the 'k' suffix, megabytes with 'm' and gigabytes with 'g').
|<<config_db.memory.transaction.total.max,db.memory.transaction.total.max>>|Limit the amount of memory that all transactions in one database can consume, in bytes (or kilobytes with the 'k' suffix, megabytes with 'm' and gigabytes with 'g').
|<<config_db.recovery.fail_on_missing_files,db.recovery.fail_on_missing_files>>|If `true`, Neo4j will abort recovery if transaction log files are missing.
|<<config_db.relationship_grouping_threshold,db.relationship_grouping_threshold>>|Relationship count threshold for considering a node to be dense.
|<<config_db.shutdown_transaction_end_timeout,db.shutdown_transaction_end_timeout>>|The maximum amount of time to wait for running transactions to complete before allowing initiated database shutdown to continue.
|<<config_db.store.files.preallocate,db.store.files.preallocate>>|Specify if Neo4j should try to preallocate store files as they grow.
|<<config_db.temporal.timezone,db.temporal.timezone>>|Database timezone for temporal functions.
|<<config_db.track_query_cpu_time,db.track_query_cpu_time>>|Enables or disables tracking of how much time a query spends actively executing on the CPU.
|<<config_db.transaction.bookmark_ready_timeout,db.transaction.bookmark_ready_timeout>>|The maximum amount of time to wait for the database state represented by the bookmark.
|<<config_db.transaction.concurrent.maximum,db.transaction.concurrent.maximum>>|The maximum number of concurrently running transactions.
|<<config_db.transaction.monitor.check.interval,db.transaction.monitor.check.interval>>|Configures the time interval between transaction monitor checks.
|<<config_db.transaction.sampling.percentage,db.transaction.sampling.percentage>>|Transaction sampling percentage.
|<<config_db.transaction.timeout,db.transaction.timeout>>|The maximum time interval of a transaction within which it should be completed.
|<<config_db.transaction.tracing.level,db.transaction.tracing.level>>|Transaction creation tracing level.
|<<config_db.tx_log.buffer.size,db.tx_log.buffer.size>>|On serialization of transaction logs, they will be temporary stored in the byte buffer that will be flushed at the end of the transaction or at any moment when buffer will be full.
|<<config_db.tx_log.preallocate,db.tx_log.preallocate>>|Specify if Neo4j should try to preallocate the logical log file in advance. 
It optimizes the filesystem by ensuring there is room to accommodate newly generated files and avoid file-level fragmentation.
|<<config_db.tx_log.rotation.retention_policy,db.tx_log.rotation.retention_policy>>|Tell Neo4j how long logical transaction logs should be kept to backup the database.For example, "10 days" will prune logical logs that only contain transactions older than 10 days.Alternatively, "100k txs" will keep the 100k latest transactions from each database and prune any older transactions.
|<<config_db.tx_log.rotation.size,db.tx_log.rotation.size>>|Specifies at which file size the logical log will auto-rotate.
|<<config_db.tx_state.memory_allocation,db.tx_state.memory_allocation>>|Defines whether memory for transaction state should be allocated on- or off-heap.
|<<config_dbms.cluster.catchup.client_inactivity_timeout,dbms.cluster.catchup.client_inactivity_timeout>>|label:enterprise-edition[Enterprise only]The catch up protocol times out if the given duration elapses with no network activity.
|<<config_dbms.cluster.discovery.endpoints,dbms.cluster.discovery.endpoints>>|label:enterprise-edition[Enterprise only]A comma-separated list of endpoints which a server should contact in order to discover other cluster members.
|<<config_dbms.cluster.discovery.log_level,dbms.cluster.discovery.log_level>>|label:enterprise-edition[Enterprise only]The level of middleware logging.
|<<config_dbms.cluster.discovery.type,dbms.cluster.discovery.type>>|label:enterprise-edition[Enterprise only]Configure the discovery type used for cluster name resolution.
|<<config_dbms.cluster.minimum_initial_system_primaries_count,dbms.cluster.minimum_initial_system_primaries_count>>|label:enterprise-edition[Enterprise only]Minimum number of machines initially required to formed a clustered DBMS.
|<<config_dbms.cluster.network.handshake_timeout,dbms.cluster.network.handshake_timeout>>|label:enterprise-edition[Enterprise only]Time out for protocol negotiation handshake.
|<<config_dbms.cluster.network.max_chunk_size,dbms.cluster.network.max_chunk_size>>|label:enterprise-edition[Enterprise only]Maximum chunk size allowable across network by clustering machinery.
|<<config_dbms.cluster.network.supported_compression_algos,dbms.cluster.network.supported_compression_algos>>|label:enterprise-edition[Enterprise only]Network compression algorithms that this instance will allow in negotiation as a comma-separated list.
|<<config_dbms.cluster.raft.binding_timeout,dbms.cluster.raft.binding_timeout>>|label:enterprise-edition[Enterprise only]The time allowed for a database on a Neo4j server to either join a cluster or form a new cluster with the other Neo4j Servers provided by `dbms.cluster.discovery.endpoints`.
|<<config_dbms.cluster.raft.client.max_channels,dbms.cluster.raft.client.max_channels>>|label:enterprise-edition[Enterprise only]The maximum number of TCP channels between two nodes to operate the raft protocol.
|<<config_dbms.cluster.raft.election_failure_detection_window,dbms.cluster.raft.election_failure_detection_window>>|label:enterprise-edition[Enterprise only]The rate at which leader elections happen.
|<<config_dbms.cluster.raft.leader_failure_detection_window,dbms.cluster.raft.leader_failure_detection_window>>|label:enterprise-edition[Enterprise only]The time window within which the loss of the leader is detected and the first re-election attempt is held.
|<<config_dbms.cluster.raft.leader_transfer.balancing_strategy,dbms.cluster.raft.leader_transfer.balancing_strategy>>|label:enterprise-edition[Enterprise only]Which strategy to use when transferring database leaderships around a cluster.
|<<config_dbms.cluster.raft.log.pruning_frequency,dbms.cluster.raft.log.pruning_frequency>>|label:enterprise-edition[Enterprise only]RAFT log pruning frequency.
|<<config_dbms.cluster.raft.log.reader_pool_size,dbms.cluster.raft.log.reader_pool_size>>|label:enterprise-edition[Enterprise only]RAFT log reader pool size.
|<<config_dbms.cluster.raft.log.rotation_size,dbms.cluster.raft.log.rotation_size>>|label:enterprise-edition[Enterprise only]RAFT log rotation size.
|<<config_dbms.cluster.raft.membership.join_max_lag,dbms.cluster.raft.membership.join_max_lag>>|label:enterprise-edition[Enterprise only]Maximum amount of lag accepted for a new follower to join the Raft group.
|<<config_dbms.cluster.raft.membership.join_timeout,dbms.cluster.raft.membership.join_timeout>>|label:enterprise-edition[Enterprise only]Time out for a new member to catch up.
|<<config_dbms.cluster.store_copy.max_retry_time_per_request,dbms.cluster.store_copy.max_retry_time_per_request>>|label:enterprise-edition[Enterprise only]Maximum retry time per request during store copy.
|<<config_dbms.cypher.forbid_exhaustive_shortestpath,dbms.cypher.forbid_exhaustive_shortestpath>>|This setting is associated with performance optimization.
|<<config_dbms.cypher.forbid_shortestpath_common_nodes,dbms.cypher.forbid_shortestpath_common_nodes>>|This setting is associated with performance optimization.
|<<config_dbms.cypher.hints_error,dbms.cypher.hints_error>>|Set this to specify the behavior when Cypher planner or runtime hints cannot be fulfilled.
|<<config_dbms.cypher.lenient_create_relationship,dbms.cypher.lenient_create_relationship>>|Set this to change the behavior for Cypher create relationship when the start or end node is missing.
|<<config_dbms.cypher.min_replan_interval,dbms.cypher.min_replan_interval>>|The minimum time between possible cypher query replanning events.
|<<config_dbms.cypher.planner,dbms.cypher.planner>>|Set this to specify the default planner for the default language version.
|<<config_dbms.cypher.render_plan_description,dbms.cypher.render_plan_description>>|If set to `true` a textual representation of the plan description will be rendered on the server for all queries running with `EXPLAIN` or `PROFILE`.
|<<config_dbms.cypher.statistics_divergence_threshold,dbms.cypher.statistics_divergence_threshold>>|The threshold for statistics above which a plan is considered stale.
+
If any of the underlying statistics used to create the plan have changed more than this value, the plan will be considered stale and will be replanned.
|<<config_dbms.databases.seed_from_uri_providers,dbms.databases.seed_from_uri_providers>>|label:enterprise-edition[Enterprise only]Databases may be created from an existing 'seed' (a database backup or dump) stored at some source URI.
|<<config_dbms.db.timezone,dbms.db.timezone>>|Database timezone.
|<<config_dbms.kubernetes.address,dbms.kubernetes.address>>|label:enterprise-edition[Enterprise only]Address for Kubernetes API.
|<<config_dbms.kubernetes.ca_crt,dbms.kubernetes.ca_crt>>|label:enterprise-edition[Enterprise only]File location of CA certificate for Kubernetes API.
|<<config_dbms.kubernetes.cluster_domain,dbms.kubernetes.cluster_domain>>|label:enterprise-edition[Enterprise only]Kubernetes cluster domain.
|<<config_dbms.kubernetes.label_selector,dbms.kubernetes.label_selector>>|label:enterprise-edition[Enterprise only]LabelSelector for Kubernetes API.
|<<config_dbms.kubernetes.namespace,dbms.kubernetes.namespace>>|label:enterprise-edition[Enterprise only]File location of namespace for Kubernetes API.
|<<config_dbms.kubernetes.service_port_name,dbms.kubernetes.service_port_name>>|label:enterprise-edition[Enterprise only]Service port name for discovery for Kubernetes API.
|<<config_dbms.kubernetes.token,dbms.kubernetes.token>>|label:enterprise-edition[Enterprise only]File location of token for Kubernetes API.
|<<config_dbms.logs.http.enabled,dbms.logs.http.enabled>>|Enable HTTP request logging.
|<<config_dbms.max_databases,dbms.max_databases>>|label:enterprise-edition[Enterprise only]The maximum number of databases.
|<<config_dbms.memory.tracking.enable,dbms.memory.tracking.enable>>|Enable off heap and on heap memory tracking.
|<<config_dbms.memory.transaction.total.max,dbms.memory.transaction.total.max>>|Limit the amount of memory that all of the running transactions can consume, in bytes (or kilobytes with the 'k' suffix, megabytes with 'm' and gigabytes with 'g').
|<<config_dbms.netty.ssl.provider,dbms.netty.ssl.provider>>|Netty SSL provider.
|<<config_dbms.routing.client_side.enforce_for_domains,dbms.routing.client_side.enforce_for_domains>>|Always use client side routing (regardless of the default router) for neo4j:// protocol connections to these domains.
|<<config_dbms.routing.default_router,dbms.routing.default_router>>|Routing strategy for neo4j:// protocol connections.
Default is `CLIENT`, using client-side routing, with server-side routing as a fallback (if enabled).
When set to `SERVER`, client-side routing is short-circuited, and requests will rely on server-side routing (which must be enabled for proper operation, i.e.
|<<config_dbms.routing.driver.connection.connect_timeout,dbms.routing.driver.connection.connect_timeout>>|Socket connection timeout.
A timeout of zero is treated as an infinite timeout and will be bound by the timeout configured on the
operating system level.
|<<config_dbms.routing.driver.connection.max_lifetime,dbms.routing.driver.connection.max_lifetime>>|Pooled connections older than this threshold will be closed and removed from the pool.
Setting this option to a low value will cause a high connection churn and might result in a performance hit.
It is recommended to set maximum lifetime to a slightly smaller value than the one configured in network
equipment (load balancer, proxy, firewall, etc.
|<<config_dbms.routing.driver.connection.pool.acquisition_timeout,dbms.routing.driver.connection.pool.acquisition_timeout>>|Maximum amount of time spent attempting to acquire a connection from the connection pool.
This timeout only kicks in when all existing connections are being used and no new connections can be created because maximum connection pool size has been reached.
Error is raised when connection can't be acquired within configured time.
Negative values are allowed and result in unlimited acquisition timeout.
|<<config_dbms.routing.driver.connection.pool.idle_test,dbms.routing.driver.connection.pool.idle_test>>|Pooled connections that have been idle in the pool for longer than this timeout will be tested before they are used again, to ensure they are still alive.
If this option is set too low, an additional network call will be incurred when acquiring a connection, which causes a performance hit.
If this is set high, no longer live connections might be used which might lead to errors.
Hence, this parameter tunes a balance between the likelihood of experiencing connection problems and performance
Normally, this parameter should not need tuning.
Value 0 means connections will always be tested for validity.
|<<config_dbms.routing.driver.connection.pool.max_size,dbms.routing.driver.connection.pool.max_size>>|Maximum total number of connections to be managed by a connection pool.
The limit is enforced for a combination of a host and user.
|<<config_dbms.routing.driver.logging.level,dbms.routing.driver.logging.level>>|Sets level for driver internal logging.
|<<config_dbms.routing.enabled,dbms.routing.enabled>>|Enable server-side routing in clusters using an additional bolt connector.
When configured, this allows requests to be forwarded from one cluster member to another, if the requests can't be satisfied by the first member (e.g.
|<<config_dbms.routing.load_balancing.plugin,dbms.routing.load_balancing.plugin>>|label:enterprise-edition[Enterprise only]The load balancing plugin to use.
|<<config_dbms.routing.load_balancing.shuffle_enabled,dbms.routing.load_balancing.shuffle_enabled>>|label:enterprise-edition[Enterprise only]Enables shuffling of the returned load balancing result.
|<<config_dbms.routing.reads_on_primaries_enabled,dbms.routing.reads_on_primaries_enabled>>|label:enterprise-edition[Enterprise only]Configure if the `dbms.routing.getRoutingTable()` procedure should include non-writer primaries as read endpoints or return only secondaries.
|<<config_dbms.routing.reads_on_writers_enabled,dbms.routing.reads_on_writers_enabled>>|label:enterprise-edition[Enterprise only]Configure if the `dbms.routing.getRoutingTable()` procedure should include the writer as read endpoint or return only non-writers (non writer primaries and secondaries) Note: writer is returned as read endpoint if no other member is present all.
|<<config_dbms.routing_ttl,dbms.routing_ttl>>|How long callers should cache the response of the routing procedure `dbms.routing.getRoutingTable()`.
|<<config_dbms.security.allow_csv_import_from_file_urls,dbms.security.allow_csv_import_from_file_urls>>|Determines if Cypher will allow using file URLs when loading data using `LOAD CSV`.
|<<config_dbms.security.auth_cache_max_capacity,dbms.security.auth_cache_max_capacity>>|label:enterprise-edition[Enterprise only]The maximum capacity for authentication and authorization caches (respectively).
|<<config_dbms.security.auth_cache_ttl,dbms.security.auth_cache_ttl>>|label:enterprise-edition[Enterprise only]The time to live (TTL) for cached authentication and authorization info when using external auth providers (LDAP or plugin).
|<<config_dbms.security.auth_cache_use_ttl,dbms.security.auth_cache_use_ttl>>|label:enterprise-edition[Enterprise only]Enable time-based eviction of the authentication and authorization info cache for external auth providers (LDAP or plugin).
|<<config_dbms.security.auth_enabled,dbms.security.auth_enabled>>|Enable auth requirement to access Neo4j.
|<<config_dbms.security.auth_minimum_password_length,dbms.security.auth_minimum_password_length>>|label:version-number[Neo4j 5.3]The minimum number of characters required in a password.
|<<config_dbms.security.auth_lock_time,dbms.security.auth_lock_time>>|The amount of time user account should be locked after a configured number of unsuccessful authentication attempts.
|<<config_dbms.security.auth_max_failed_attempts,dbms.security.auth_max_failed_attempts>>|The maximum number of unsuccessful authentication attempts before imposing a user lock for  the configured amount of time, as defined by `dbms.security.auth_lock_time`.The locked out user will not be able to log in until the lock period expires, even if correct  credentials are provided.
|<<config_dbms.security.authentication_providers,dbms.security.authentication_providers>>|label:enterprise-edition[Enterprise only]A list of security authentication providers containing the users and roles.
|<<config_dbms.security.authorization_providers,dbms.security.authorization_providers>>|label:enterprise-edition[Enterprise only]A list of security authorization providers containing the users and roles.
|<<config_dbms.security.cluster_status_auth_enabled,dbms.security.cluster_status_auth_enabled>>|label:enterprise-edition[Enterprise only]Require authorization for access to the Causal Clustering status endpoints.
|<<config_dbms.security.http_access_control_allow_origin,dbms.security.http_access_control_allow_origin>>|Value of the Access-Control-Allow-Origin header sent over any HTTP or HTTPS connector.
|<<config_dbms.security.http_auth_allowlist,dbms.security.http_auth_allowlist>>|Defines an allowlist of http paths where Neo4j authentication is not required.
|<<config_dbms.security.http_strict_transport_security,dbms.security.http_strict_transport_security>>|Value of the HTTP Strict-Transport-Security (HSTS) response header.
|<<config_dbms.security.key.name,dbms.security.key.name>>|label:enterprise-edition[Enterprise only]Name of the 256 length AES encryption key, which is used for the symmetric encryption.
|<<config_dbms.security.keystore.password,dbms.security.keystore.password>>|label:enterprise-edition[Enterprise only]Password for accessing the keystore holding a 256 length AES encryption key, which is used for the symmetric encryption.
|<<config_dbms.security.keystore.path,dbms.security.keystore.path>>|label:enterprise-edition[Enterprise only]Location of the keystore holding a 256 length AES encryption key, which is used for the symmetric encryption of secrets held in system database.
|<<config_dbms.security.ldap.authentication.attribute,dbms.security.ldap.authentication.attribute>>|label:enterprise-edition[Enterprise only]The attribute to use when looking up users.
Using this setting requires `dbms.security.ldap.authentication.search_for_attribute` to be true and thus `dbms.security.ldap.authorization.system_username` and `dbms.security.ldap.authorization.system_password` to be configured.
|<<config_dbms.security.ldap.authentication.cache_enabled,dbms.security.ldap.authentication.cache_enabled>>|label:enterprise-edition[Enterprise only]Determines if the result of authentication via the LDAP server should be cached or not.
|<<config_dbms.security.ldap.authentication.mechanism,dbms.security.ldap.authentication.mechanism>>|label:enterprise-edition[Enterprise only]LDAP authentication mechanism.
|<<config_dbms.security.ldap.authentication.search_for_attribute,dbms.security.ldap.authentication.search_for_attribute>>|label:enterprise-edition[Enterprise only]Perform authentication by searching for an unique attribute of a user.
Using this setting requires `dbms.security.ldap.authorization.system_username` and `dbms.security.ldap.authorization.system_password` to be configured.
|<<config_dbms.security.ldap.authentication.user_dn_template,dbms.security.ldap.authentication.user_dn_template>>|label:enterprise-edition[Enterprise only]LDAP user DN template.
|<<config_dbms.security.ldap.authorization.access_permitted_group,dbms.security.ldap.authorization.access_permitted_group>>|label:enterprise-edition[Enterprise only]The LDAP group to which a user must belong to get any access to the system.Set this to restrict access to a subset of LDAP users belonging to a particular group.
|<<config_dbms.security.ldap.authorization.group_membership_attributes,dbms.security.ldap.authorization.group_membership_attributes>>|label:enterprise-edition[Enterprise only]A list of attribute names on a user object that contains groups to be used for mapping to roles when LDAP authorization is enabled.
|<<config_dbms.security.ldap.authorization.group_to_role_mapping,dbms.security.ldap.authorization.group_to_role_mapping>>|label:enterprise-edition[Enterprise only]An authorization mapping from LDAP group names to Neo4j role names.
|<<config_dbms.security.ldap.authorization.nested_groups_enabled,dbms.security.ldap.authorization.nested_groups_enabled>>|label:enterprise-edition[Enterprise only]This setting determines whether multiple LDAP search results will be processed (as is required for the lookup of nested groups).
|<<config_dbms.security.ldap.authorization.nested_groups_search_filter,dbms.security.ldap.authorization.nested_groups_search_filter>>|label:enterprise-edition[Enterprise only]The search template which will be used to find the nested groups which the user is a member of.
|<<config_dbms.security.ldap.authorization.system_password,dbms.security.ldap.authorization.system_password>>|label:enterprise-edition[Enterprise only]An LDAP system account password to use for authorization searches when `dbms.security.ldap.authorization.use_system_account` is `true`.
|<<config_dbms.security.ldap.authorization.system_username,dbms.security.ldap.authorization.system_username>>|label:enterprise-edition[Enterprise only]An LDAP system account username to use for authorization searches when `dbms.security.ldap.authorization.use_system_account` is `true`.
|<<config_dbms.security.ldap.authorization.use_system_account,dbms.security.ldap.authorization.use_system_account>>|label:enterprise-edition[Enterprise only]Perform LDAP search for authorization info using a system account instead of the user's own account.
If this is set to `false` (default), the search for group membership will be performed directly after authentication using the LDAP context bound with the user's own account.
|<<config_dbms.security.ldap.authorization.user_search_base,dbms.security.ldap.authorization.user_search_base>>|label:enterprise-edition[Enterprise only]The name of the base object or named context to search for user objects when LDAP authorization is enabled.
|<<config_dbms.security.ldap.authorization.user_search_filter,dbms.security.ldap.authorization.user_search_filter>>|label:enterprise-edition[Enterprise only]The LDAP search filter to search for a user principal when LDAP authorization is enabled.
|<<config_dbms.security.ldap.connection_timeout,dbms.security.ldap.connection_timeout>>|label:enterprise-edition[Enterprise only]The timeout for establishing an LDAP connection.
|<<config_dbms.security.ldap.host,dbms.security.ldap.host>>|label:enterprise-edition[Enterprise only]URL of LDAP server to use for authentication and authorization.
|<<config_dbms.security.ldap.read_timeout,dbms.security.ldap.read_timeout>>|label:enterprise-edition[Enterprise only]The timeout for an LDAP read request (i.e.
|<<config_dbms.security.ldap.referral,dbms.security.ldap.referral>>|label:enterprise-edition[Enterprise only]The LDAP referral behavior when creating a connection.
|<<config_dbms.security.ldap.use_starttls,dbms.security.ldap.use_starttls>>|label:enterprise-edition[Enterprise only]Use secure communication with the LDAP server using opportunistic TLS.
|<<config_dbms.security.log_successful_authentication,dbms.security.log_successful_authentication>>|label:enterprise-edition[Enterprise only]Set to log successful authentication events to the security log.
|<<config_dbms.security.oidc.-provider-.audience,dbms.security.oidc.<provider>.audience>>|label:enterprise-edition[Enterprise only]Expected values of the Audience (aud) claim in the id token.
|<<config_dbms.security.oidc.-provider-.auth_endpoint,dbms.security.oidc.<provider>.auth_endpoint>>|label:enterprise-edition[Enterprise only]The OIDC authorization endpoint.
|<<config_dbms.security.oidc.-provider-.auth_flow,dbms.security.oidc.<provider>.auth_flow>>|label:enterprise-edition[Enterprise only]The OIDC flow to use.
|<<config_dbms.security.oidc.-provider-.auth_params,dbms.security.oidc.<provider>.auth_params>>|label:enterprise-edition[Enterprise only]Optional additional parameters that the auth endpoint requires.
|<<config_dbms.security.oidc.-provider-.authorization.group_to_role_mapping,dbms.security.oidc.<provider>.authorization.group_to_role_mapping>>|label:enterprise-edition[Enterprise only]An authorization mapping from IdP group names to Neo4j role names.
|<<config_dbms.security.oidc.-provider-.claims.groups,dbms.security.oidc.<provider>.claims.groups>>|label:enterprise-edition[Enterprise only]The claim to use as the list of groups in Neo4j.
|<<config_dbms.security.oidc.-provider-.claims.username,dbms.security.oidc.<provider>.claims.username>>|label:enterprise-edition[Enterprise only]The claim to use as the username in Neo4j.
|<<config_dbms.security.oidc.-provider-.client_id,dbms.security.oidc.<provider>.client_id>>|label:enterprise-edition[Enterprise only]Client id needed if token contains multiple Audience (aud) claims.
|<<config_dbms.security.oidc.-provider-.config,dbms.security.oidc.<provider>.config>>|label:enterprise-edition[Enterprise only]
|<<config_dbms.security.oidc.-provider-.display_name,dbms.security.oidc.<provider>.display_name>>|label:enterprise-edition[Enterprise only]The user-facing name of the provider as provided by the discovery endpoint to clients (Bloom, Browser etc.).
|<<config_dbms.security.oidc.-provider-.get_groups_from_user_info,dbms.security.oidc.<provider>.get_groups_from_user_info>>|label:enterprise-edition[Enterprise only]When turned on, Neo4j gets the groups from the provider user info endpoint.
|<<config_dbms.security.oidc.-provider-.get_username_from_user_info,dbms.security.oidc.<provider>.get_username_from_user_info>>|label:enterprise-edition[Enterprise only]When turned on, Neo4j gets the username from the provider user info endpoint.
|<<config_dbms.security.oidc.-provider-.issuer,dbms.security.oidc.<provider>.issuer>>|label:enterprise-edition[Enterprise only]The expected value of the iss claim in the id token.
|<<config_dbms.security.oidc.-provider-.jwks_uri,dbms.security.oidc.<provider>.jwks_uri>>|label:enterprise-edition[Enterprise only]The location of the JWK public key set for the identity provider.
|<<config_dbms.security.oidc.-provider-.params,dbms.security.oidc.<provider>.params>>|label:enterprise-edition[Enterprise only]The map is a semicolon separated list of key-value pairs.
|<<config_dbms.security.oidc.-provider-.token_endpoint,dbms.security.oidc.<provider>.token_endpoint>>|label:enterprise-edition[Enterprise only]The OIDC token endpoint.
|<<config_dbms.security.oidc.-provider-.token_params,dbms.security.oidc.<provider>.token_params>>|label:enterprise-edition[Enterprise only]Optional query parameters that the token endpoint requires.
|<<config_dbms.security.oidc.-provider-.user_info_uri,dbms.security.oidc.<provider>.user_info_uri>>|label:enterprise-edition[Enterprise only]The identity providers user info uri.
|<<config_dbms.security.oidc.-provider-.well_known_discovery_uri,dbms.security.oidc.<provider>.well_known_discovery_uri>>|label:enterprise-edition[Enterprise only]The 'well known' OpenID Connect Discovery endpoint used to fetch identity provider settings.
|<<config_dbms.security.procedures.allowlist,dbms.security.procedures.allowlist>>|A list of procedures (comma separated) that are to be loaded.
|<<config_dbms.security.procedures.unrestricted,dbms.security.procedures.unrestricted>>|A list of procedures and user defined functions (comma separated) that are allowed full access to the database.
|<<config_initial.dbms.database_allocator,initial.dbms.database_allocator>>|label:enterprise-edition[Enterprise only]Name of the initial database allocator.
|<<config_initial.dbms.default_database,initial.dbms.default_database>>|Name of the default database (aliases are not supported).
|<<config_initial.dbms.default_primaries_count,initial.dbms.default_primaries_count>>|label:enterprise-edition[Enterprise only]Initial default number of primary instances of user databases.
|<<config_initial.dbms.default_secondaries_count,initial.dbms.default_secondaries_count>>|label:enterprise-edition[Enterprise only]Initial default number of secondary instances of user databases.
|<<config_initial.server.allowed_databases,initial.server.allowed_databases>>|label:enterprise-edition[Enterprise only]The names of databases that are allowed on this server - all others are denied.
|<<config_initial.server.denied_databases,initial.server.denied_databases>>|label:enterprise-edition[Enterprise only]The names of databases that are not allowed on this server.
|<<config_initial.server.mode_constraint,initial.server.mode_constraint>>|label:enterprise-edition[Enterprise only]An instance can restrict itself to allow databases to be hosted only as primaries or secondaries.
|<<config_server.backup.enabled,server.backup.enabled>>|label:enterprise-edition[Enterprise only]Enable support for running online backups.
|<<config_server.backup.listen_address,server.backup.listen_address>>|label:enterprise-edition[Enterprise only]Network interface and port for the backup server to listen on.
|<<config_server.backup.store_copy_max_retry_time_per_request,server.backup.store_copy_max_retry_time_per_request>>|label:enterprise-edition[Enterprise only]Maximum retry time per request during store copy.
|<<config_server.bolt.advertised_address,server.bolt.advertised_address>>|Advertised address for this connector.
|<<config_server.bolt.connection_keep_alive,server.bolt.connection_keep_alive>>|The maximum time to wait before sending a NOOP on connections waiting for responses from active ongoing queries.The minimum value is 1 millisecond.
|<<config_server.bolt.connection_keep_alive_for_requests,server.bolt.connection_keep_alive_for_requests>>|The type of messages to enable keep-alive messages for (ALL, STREAMING or OFF).
|<<config_server.bolt.connection_keep_alive_probes,server.bolt.connection_keep_alive_probes>>|The total amount of probes to be missed before a connection is considered stale.The minimum for this value is 1.
|<<config_server.bolt.connection_keep_alive_streaming_scheduling_interval,server.bolt.connection_keep_alive_streaming_scheduling_interval>>|The interval between every scheduled keep-alive check on all connections with active queries.
|<<config_server.bolt.enabled,server.bolt.enabled>>|Enable the bolt connector.
|<<config_server.bolt.listen_address,server.bolt.listen_address>>|Address the connector should bind to.
|<<config_server.bolt.ocsp_stapling_enabled,server.bolt.ocsp_stapling_enabled>>|Enable server OCSP stapling for bolt and http connectors.
|<<config_server.bolt.thread_pool_keep_alive,server.bolt.thread_pool_keep_alive>>|The maximum time an idle thread in the thread pool bound to this connector will wait for new tasks.
|<<config_server.bolt.thread_pool_max_size,server.bolt.thread_pool_max_size>>|The maximum number of threads allowed in the thread pool bound to this connector.
|<<config_server.bolt.thread_pool_min_size,server.bolt.thread_pool_min_size>>|The number of threads to keep in the thread pool bound to this connector, even if they are idle.
|<<config_server.bolt.tls_level,server.bolt.tls_level>>|Encryption level to require this connector to use.
|<<config_server.cluster.advertised_address,server.cluster.advertised_address>>|label:enterprise-edition[Enterprise only]Advertised hostname/IP address and port for the transaction shipping server.
|<<config_server.cluster.catchup.connect_randomly_to_server_group,server.cluster.catchup.connect_randomly_to_server_group>>|label:enterprise-edition[Enterprise only]Comma separated list of groups to be used by the connect-randomly-to-server-group selection strategy.
|<<config_server.cluster.catchup.upstream_strategy,server.cluster.catchup.upstream_strategy>>|label:enterprise-edition[Enterprise only]An ordered list in descending preference of the strategy which secondaries use to choose the upstream server from which to pull transactional updates.
|<<config_server.cluster.catchup.user_defined_upstream_strategy,server.cluster.catchup.user_defined_upstream_strategy>>|label:enterprise-edition[Enterprise only]Configuration of a user-defined upstream selection strategy.
|<<config_server.cluster.listen_address,server.cluster.listen_address>>|label:enterprise-edition[Enterprise only]Network interface and port for the transaction shipping server to listen on.
|<<config_server.cluster.network.native_transport_enabled,server.cluster.network.native_transport_enabled>>|label:enterprise-edition[Enterprise only]Use native transport if available.
|<<config_server.cluster.raft.advertised_address,server.cluster.raft.advertised_address>>|label:enterprise-edition[Enterprise only]Advertised hostname/IP address and port for the RAFT server.
|<<config_server.cluster.raft.listen_address,server.cluster.raft.listen_address>>|label:enterprise-edition[Enterprise only]Network interface and port for the RAFT server to listen on.
|<<config_server.cluster.system_database_mode,server.cluster.system_database_mode>>|label:enterprise-edition[Enterprise only]Users must manually specify the mode for the system database on each instance.
|<<config_server.config.strict_validation.enabled,server.config.strict_validation.enabled>>|A strict configuration validation will prevent the database from starting up if unknown configuration options are specified in the neo4j settings namespace (such as dbms., cypher., etc) or if settings are declared multiple times.
|<<config_server.databases.default_to_read_only,server.databases.default_to_read_only>>|Whether or not any database on this instance are read_only by default.
|<<config_server.databases.read_only,server.databases.read_only>>|List of databases for which to prevent write queries.
|<<config_server.databases.writable,server.databases.writable>>|List of databases for which to allow write queries.
|<<config_server.db.query_cache_size,server.db.query_cache_size>>|The number of cached Cypher query execution plans per database.
|<<config_server.default_advertised_address,server.default_advertised_address>>|Default hostname or IP address the server uses to advertise itself.
|<<config_server.default_listen_address,server.default_listen_address>>|Default network interface to listen for incoming connections.
|<<config_server.directories.cluster_state,server.directories.cluster_state>>|label:enterprise-edition[Enterprise only]Directory to hold cluster state including Raft log.
|<<config_server.directories.data,server.directories.data>>|Path of the data directory.
|<<config_server.directories.dumps.root,server.directories.dumps.root>>|Root location where Neo4j will store database dumps optionally produced when dropping said databases.
|<<config_server.directories.import,server.directories.import>>|Sets the root directory for file URLs used with the Cypher `LOAD CSV` clause.
|<<config_server.directories.lib,server.directories.lib>>|Path of the lib directory.
|<<config_server.directories.licenses,server.directories.licenses>>|Path of the licenses directory.
|<<config_server.directories.logs,server.directories.logs>>|Path of the logs directory.
|<<config_server.directories.metrics,server.directories.metrics>>|label:enterprise-edition[Enterprise only]The target location of the CSV files: a path to a directory wherein a CSV file per reported field  will be written.
|<<config_server.directories.neo4j_home,server.directories.neo4j_home>>|Root relative to which directory settings are resolved.
|<<config_server.directories.plugins,server.directories.plugins>>|Location of the database plugin directory.
|<<config_server.directories.run,server.directories.run>>|Path of the run directory.
|<<config_server.directories.script.root,server.directories.script.root>>|Root location where Neo4j will store scripts for configured databases.
|<<config_server.directories.transaction.logs.root,server.directories.transaction.logs.root>>|Root location where Neo4j will store transaction logs for configured databases.
|<<config_server.discovery.advertised_address,server.discovery.advertised_address>>|label:enterprise-edition[Enterprise only]Advertised cluster member discovery management communication.
|<<config_server.discovery.listen_address,server.discovery.listen_address>>|label:enterprise-edition[Enterprise only]Host and port to bind the cluster member discovery management communication.
|<<config_server.dynamic.setting.allowlist,server.dynamic.setting.allowlist>>|label:enterprise-edition[Enterprise only]A list of setting name patterns (comma separated) that are allowed to be dynamically changed.
|<<config_server.groups,server.groups>>|label:enterprise-edition[Enterprise only]A list of tag names for the server used when configuring load balancing and replication policies.
|<<config_server.http.advertised_address,server.http.advertised_address>>|Advertised address for this connector.
|<<config_server.http.enabled,server.http.enabled>>|Enable the http connector.
|<<config_server.http.listen_address,server.http.listen_address>>|Address the connector should bind to.
|<<config_server.http_enabled_modules,server.http_enabled_modules>>|Defines the set of modules loaded into the Neo4j web server.
|<<config_server.https.advertised_address,server.https.advertised_address>>|Advertised address for this connector.
|<<config_server.https.enabled,server.https.enabled>>|Enable the https connector.
|<<config_server.https.listen_address,server.https.listen_address>>|Address the connector should bind to.
|<<config_server.jvm.additional,server.jvm.additional>>|Additional JVM arguments.
|<<config_server.logs.config,server.logs.config>>|Path to the logging configuration for debug, query, http and security logs.
|<<config_server.logs.debug.enabled,server.logs.debug.enabled>>|Enable the debug log.
|<<config_server.logs.gc.enabled,server.logs.gc.enabled>>|Enable GC Logging.
|<<config_server.logs.gc.options,server.logs.gc.options>>|GC Logging Options.
|<<config_server.logs.gc.rotation.keep_number,server.logs.gc.rotation.keep_number>>|Number of GC logs to keep.
|<<config_server.logs.gc.rotation.size,server.logs.gc.rotation.size>>|Size of each GC log that is kept.
|<<config_server.logs.user.config,server.logs.user.config>>|Path to the logging configuration of user logs.
|<<config_server.max_databases,server.max_databases>>|label:enterprise-edition[Enterprise only]The maximum number of databases. 
This setting will be deprecated in favour of <<config_dbms.max_databases,`dbms.max_databases`>> in a future version.
|<<config_server.memory.heap.initial_size,server.memory.heap.initial_size>>|Initial heap size.
|<<config_server.memory.heap.max_size,server.memory.heap.max_size>>|Maximum heap size.
|<<config_server.memory.off_heap.block_cache_size,server.memory.off_heap.block_cache_size>>|Defines the size of the off-heap memory blocks cache.
|<<config_server.memory.off_heap.max_cacheable_block_size,server.memory.off_heap.max_cacheable_block_size>>|Defines the maximum size of an off-heap memory block that can be cached to speed up allocations.
|<<config_server.memory.off_heap.max_size,server.memory.off_heap.max_size>>|The maximum amount of off-heap memory that can be used to store transaction state data; it's a total amount of memory shared across all active transactions.
|<<config_server.memory.pagecache.directio,server.memory.pagecache.directio>>|Use direct I/O for page cache.
|<<config_server.memory.pagecache.flush.buffer.enabled,server.memory.pagecache.flush.buffer.enabled>>|Page cache can be configured to use a temporal buffer for flushing purposes.
|<<config_server.memory.pagecache.flush.buffer.size_in_pages,server.memory.pagecache.flush.buffer.size_in_pages>>|Page cache can be configured to use a temporal buffer for flushing purposes.
|<<config_server.memory.pagecache.scan.prefetchers,server.memory.pagecache.scan.prefetchers>>|The maximum number of worker threads to use for pre-fetching data when doing sequential scans.
|<<config_server.memory.pagecache.size,server.memory.pagecache.size>>|The amount of memory to use for mapping the store files.
|<<config_server.metrics.csv.enabled,server.metrics.csv.enabled>>|label:enterprise-edition[Enterprise only]Set to `true` to enable exporting metrics to CSV files.
|<<config_server.metrics.csv.interval,server.metrics.csv.interval>>|label:enterprise-edition[Enterprise only]The reporting interval for the CSV files.
|<<config_server.metrics.csv.rotation.compression,server.metrics.csv.rotation.compression>>|label:enterprise-edition[Enterprise only]Decides what compression to use for the csv history files.
|<<config_server.metrics.csv.rotation.keep_number,server.metrics.csv.rotation.keep_number>>|label:enterprise-edition[Enterprise only]Maximum number of history files for the csv files.
|<<config_server.metrics.csv.rotation.size,server.metrics.csv.rotation.size>>|label:enterprise-edition[Enterprise only]The file size in bytes at which the csv files will auto-rotate.
|<<config_server.metrics.enabled,server.metrics.enabled>>|label:enterprise-edition[Enterprise only]Enable metrics.
|<<config_server.metrics.filter,server.metrics.filter>>|label:enterprise-edition[Enterprise only]Specifies which metrics should be enabled by using a comma separated list of globbing patterns.
|<<config_server.metrics.graphite.enabled,server.metrics.graphite.enabled>>|label:enterprise-edition[Enterprise only]Set to `true` to enable exporting metrics to Graphite.
|<<config_server.metrics.graphite.interval,server.metrics.graphite.interval>>|label:enterprise-edition[Enterprise only]The reporting interval for Graphite.
|<<config_server.metrics.graphite.server,server.metrics.graphite.server>>|label:enterprise-edition[Enterprise only]The hostname or IP address of the Graphite server.
|<<config_server.metrics.jmx.enabled,server.metrics.jmx.enabled>>|label:enterprise-edition[Enterprise only]Set to `true` to enable the JMX metrics endpoint.
|<<config_server.metrics.prefix,server.metrics.prefix>>|label:enterprise-edition[Enterprise only]A common prefix for the reported metrics field names.
|<<config_server.metrics.prometheus.enabled,server.metrics.prometheus.enabled>>|label:enterprise-edition[Enterprise only]Set to `true` to enable the Prometheus endpoint.
|<<config_server.metrics.prometheus.endpoint,server.metrics.prometheus.endpoint>>|label:enterprise-edition[Enterprise only]The hostname and port to use as Prometheus endpoint.
|<<config_server.panic.shutdown_on_panic,server.panic.shutdown_on_panic>>|label:enterprise-edition[Enterprise only]If there is a Database Management System Panic (an irrecoverable error) should the neo4j process shut down or continue running.
|<<config_server.routing.advertised_address,server.routing.advertised_address>>|label:enterprise-edition[Enterprise only]The advertised address for the intra-cluster routing connector.
|<<config_server.routing.listen_address,server.routing.listen_address>>|The address the routing connector should bind to.
|<<config_server.threads.worker_count,server.threads.worker_count>>|Number of Neo4j worker threads.
|<<config_server.unmanaged_extension_classes,server.unmanaged_extension_classes>>|Comma-separated list of <classname>=<mount point> for unmanaged extensions.
|<<config_server.windows_service_name,server.windows_service_name>>|Name of the Windows Service managing Neo4j when installed using `neo4j install-service`.
|===
endif::nonhtmloutput[]

ifdef::nonhtmloutput[]
* <<config_browser.allow_outgoing_connections,browser.allow_outgoing_connections>>: label:enterprise-edition[Enterprise only]Configure the policy for outgoing Neo4j Browser connections.
* <<config_browser.credential_timeout,browser.credential_timeout>>: label:enterprise-edition[Enterprise only]Configure the Neo4j Browser to time out logged in users after this idle period.
* <<config_browser.post_connect_cmd,browser.post_connect_cmd>>: Commands to be run when Neo4j Browser successfully connects to this server.
* <<config_browser.remote_content_hostname_whitelist,browser.remote_content_hostname_whitelist>>: Whitelist of hosts for the Neo4j Browser to be allowed to fetch content from.
* <<config_browser.retain_connection_credentials,browser.retain_connection_credentials>>: label:enterprise-edition[Enterprise only]Configure the Neo4j Browser to store or not store user credentials.
* <<config_browser.retain_editor_history,browser.retain_editor_history>>: label:enterprise-edition[Enterprise only]Configure the Neo4j Browser to store or not store user editor history.
* <<config_client.allow_telemetry,client.allow_telemetry>>: Configure client applications such as Browser and Bloom to send Product Analytics data.
* <<config_db.checkpoint,db.checkpoint>>: Configures the general policy for when check-points should occur.
* <<config_db.checkpoint.interval.time,db.checkpoint.interval.time>>: Configures the time interval between check-points.
* <<config_db.checkpoint.interval.tx,db.checkpoint.interval.tx>>: Configures the transaction interval between check-points.
* <<config_db.checkpoint.interval.volume,db.checkpoint.interval.volume>>: Configures the volume of transaction logs between check-points.
* <<config_db.checkpoint.iops.limit,db.checkpoint.iops.limit>>: Limit the number of IOs the background checkpoint process will consume per second.
* <<config_db.cluster.catchup.pull_interval,db.cluster.catchup.pull_interval>>: label:enterprise-edition[Enterprise only]Interval of pulling updates from cores.
* <<config_db.cluster.raft.apply.buffer.max_bytes,db.cluster.raft.apply.buffer.max_bytes>>: label:enterprise-edition[Enterprise only]The maximum number of bytes in the apply buffer.
* <<config_db.cluster.raft.apply.buffer.max_entries,db.cluster.raft.apply.buffer.max_entries>>: label:enterprise-edition[Enterprise only]The maximum number of entries in the raft log entry prefetch buffer.
* <<config_db.cluster.raft.in_queue.batch.max_bytes,db.cluster.raft.in_queue.batch.max_bytes>>: label:enterprise-edition[Enterprise only]Largest batch processed by RAFT in bytes.
* <<config_db.cluster.raft.in_queue.max_bytes,db.cluster.raft.in_queue.max_bytes>>: label:enterprise-edition[Enterprise only]Maximum number of bytes in the RAFT in-queue.
* <<config_db.cluster.raft.leader_transfer.priority_group,db.cluster.raft.leader_transfer.priority_group>>: label:enterprise-edition[Enterprise only]The name of a server_group whose members should be prioritized as leaders.
* <<config_db.cluster.raft.log.prune_strategy,db.cluster.raft.log.prune_strategy>>: label:enterprise-edition[Enterprise only]RAFT log pruning strategy that determines which logs are to be pruned.
* <<config_db.cluster.raft.log_shipping.buffer.max_bytes,db.cluster.raft.log_shipping.buffer.max_bytes>>: label:enterprise-edition[Enterprise only]The maximum number of bytes in the in-flight cache.
* <<config_db.cluster.raft.log_shipping.buffer.max_entries,db.cluster.raft.log_shipping.buffer.max_entries>>: label:enterprise-edition[Enterprise only]The maximum number of entries in the in-flight cache.
* <<config_db.filewatcher.enabled,db.filewatcher.enabled>>: Allows the enabling or disabling of the file watcher service.
* <<config_db.format,db.format>>: Database format.
* <<config_db.import.csv.buffer_size,db.import.csv.buffer_size>>: The size of the internal buffer in bytes used by `LOAD CSV`.
* <<config_db.import.csv.legacy_quote_escaping,db.import.csv.legacy_quote_escaping>>: Selects whether to conform to the standard https://tools.ietf.org/html/rfc4180 for interpreting escaped quotation characters in CSV files loaded using `LOAD CSV`.
* <<config_db.index.fulltext.default_analyzer,db.index.fulltext.default_analyzer>>: The name of the analyzer that the fulltext indexes should use by default.
* <<config_db.index.fulltext.eventually_consistent,db.index.fulltext.eventually_consistent>>: Whether or not fulltext indexes should be eventually consistent by default or not.
* <<config_db.index.fulltext.eventually_consistent_index_update_queue_max_length,db.index.fulltext.eventually_consistent_index_update_queue_max_length>>: The eventually_consistent mode of the fulltext indexes works by queueing up index updates to be applied later in a background thread.
* <<config_db.index_sampling.background_enabled,db.index_sampling.background_enabled>>: Enable or disable background index sampling.
* <<config_db.index_sampling.sample_size_limit,db.index_sampling.sample_size_limit>>: Index sampling chunk size limit.
* <<config_db.index_sampling.update_percentage,db.index_sampling.update_percentage>>: Percentage of index updates of total index size required before sampling of a given index is triggered.
* <<config_db.lock.acquisition.timeout,db.lock.acquisition.timeout>>: The maximum time interval within which lock should be acquired.
* <<config_db.logs.query.early_raw_logging_enabled,db.logs.query.early_raw_logging_enabled>>: Log query text and parameters without obfuscating passwords.
* <<config_db.logs.query.enabled,db.logs.query.enabled>>: Log executed queries.
* <<config_db.logs.query.max_parameter_length,db.logs.query.max_parameter_length>>: Sets a maximum character length use for each parameter in the log.
* <<config_db.logs.query.obfuscate_literals,db.logs.query.obfuscate_literals>>: Obfuscates all literals of the query before writing to the log.
* <<config_db.logs.query.parameter_logging_enabled,db.logs.query.parameter_logging_enabled>>: Log parameters for the executed queries being logged.
* <<config_db.logs.query.plan_description_enabled,db.logs.query.plan_description_enabled>>: Log query plan description table, useful for debugging purposes.
* <<config_db.logs.query.threshold,db.logs.query.threshold>>: If the execution of query takes more time than this threshold, the query is logged once completed - provided query logging is set to INFO.
* <<config_db.logs.query.transaction.enabled,db.logs.query.transaction.enabled>>: Log the start and end of a transaction.
* <<config_db.logs.query.transaction.threshold,db.logs.query.transaction.threshold>>: If the transaction is open for more time than this threshold, the transaction is logged once completed - provided transaction logging (db.logs.query.transaction.enabled) is set to `INFO`.
* <<config_db.memory.pagecache.warmup.enable,db.memory.pagecache.warmup.enable>>: Page cache can be configured to perform usage sampling of loaded pages that can be used to construct active load profile.
* <<config_db.memory.pagecache.warmup.preload,db.memory.pagecache.warmup.preload>>: Page cache warmup can be configured to prefetch files, preferably when cache size is bigger than store size.
* <<config_db.memory.pagecache.warmup.preload.allowlist,db.memory.pagecache.warmup.preload.allowlist>>: Page cache warmup prefetch file allowlist regex.
* <<config_db.memory.pagecache.warmup.profile.interval,db.memory.pagecache.warmup.profile.interval>>: The profiling frequency for the page cache.
* <<config_db.memory.transaction.max,db.memory.transaction.max>>: Limit the amount of memory that a single transaction can consume, in bytes (or kilobytes with the 'k' suffix, megabytes with 'm' and gigabytes with 'g').
* <<config_db.memory.transaction.total.max,db.memory.transaction.total.max>>: Limit the amount of memory that all transactions in one database can consume, in bytes (or kilobytes with the 'k' suffix, megabytes with 'm' and gigabytes with 'g').
* <<config_db.recovery.fail_on_missing_files,db.recovery.fail_on_missing_files>>: If `true`, Neo4j will abort recovery if transaction log files are missing.
* <<config_db.relationship_grouping_threshold,db.relationship_grouping_threshold>>: Relationship count threshold for considering a node to be dense.
* <<config_db.shutdown_transaction_end_timeout,db.shutdown_transaction_end_timeout>>: The maximum amount of time to wait for running transactions to complete before allowing initiated database shutdown to continue.
* <<config_db.store.files.preallocate,db.store.files.preallocate>>: Specify if Neo4j should try to preallocate store files as they grow.
* <<config_db.temporal.timezone,db.temporal.timezone>>: Database timezone for temporal functions.
* <<config_db.track_query_cpu_time,db.track_query_cpu_time>>: Enables or disables tracking of how much time a query spends actively executing on the CPU.
* <<config_db.transaction.bookmark_ready_timeout,db.transaction.bookmark_ready_timeout>>: The maximum amount of time to wait for the database state represented by the bookmark.
* <<config_db.transaction.concurrent.maximum,db.transaction.concurrent.maximum>>: The maximum number of concurrently running transactions.
* <<config_db.transaction.monitor.check.interval,db.transaction.monitor.check.interval>>: Configures the time interval between transaction monitor checks.
* <<config_db.transaction.sampling.percentage,db.transaction.sampling.percentage>>: Transaction sampling percentage.
* <<config_db.transaction.timeout,db.transaction.timeout>>: The maximum time interval of a transaction within which it should be completed.
* <<config_db.transaction.tracing.level,db.transaction.tracing.level>>: Transaction creation tracing level.
* <<config_db.tx_log.buffer.size,db.tx_log.buffer.size>>: On serialization of transaction logs, they will be temporary stored in the byte buffer that will be flushed at the end of the transaction or at any moment when buffer will be full.
* <<config_db.tx_log.preallocate,db.tx_log.preallocate>>: Specify if Neo4j should try to preallocate logical log file in advance.
* <<config_db.tx_log.rotation.retention_policy,db.tx_log.rotation.retention_policy>>: Tell Neo4j how long logical transaction logs should be kept to backup the database.For example, "10 days" will prune logical logs that only contain transactions older than 10 days.Alternatively, "100k txs" will keep the 100k latest transactions from each database and prune any older transactions.
* <<config_db.tx_log.rotation.size,db.tx_log.rotation.size>>: Specifies at which file size the logical log will auto-rotate.
* <<config_db.tx_state.memory_allocation,db.tx_state.memory_allocation>>: Defines whether memory for transaction state should be allocated on- or off-heap.
* <<config_dbms.cluster.catchup.client_inactivity_timeout,dbms.cluster.catchup.client_inactivity_timeout>>: label:enterprise-edition[Enterprise only]The catch up protocol times out if the given duration elapses with no network activity.
* <<config_dbms.cluster.discovery.endpoints,dbms.cluster.discovery.endpoints>>: label:enterprise-edition[Enterprise only]A comma-separated list of endpoints which a server should contact in order to discover other cluster members.
* <<config_dbms.cluster.discovery.log_level,dbms.cluster.discovery.log_level>>: label:enterprise-edition[Enterprise only]The level of middleware logging.
* <<config_dbms.cluster.discovery.type,dbms.cluster.discovery.type>>: label:enterprise-edition[Enterprise only]Configure the discovery type used for cluster name resolution.
* <<config_dbms.cluster.minimum_initial_system_primaries_count,dbms.cluster.minimum_initial_system_primaries_count>>: label:enterprise-edition[Enterprise only]Minimum number of machines initially required to formed a clustered DBMS.
* <<config_dbms.cluster.network.handshake_timeout,dbms.cluster.network.handshake_timeout>>: label:enterprise-edition[Enterprise only]Time out for protocol negotiation handshake.
* <<config_dbms.cluster.network.max_chunk_size,dbms.cluster.network.max_chunk_size>>: label:enterprise-edition[Enterprise only]Maximum chunk size allowable across network by clustering machinery.
* <<config_dbms.cluster.network.supported_compression_algos,dbms.cluster.network.supported_compression_algos>>: label:enterprise-edition[Enterprise only]Network compression algorithms that this instance will allow in negotiation as a comma-separated list.
* <<config_dbms.cluster.raft.binding_timeout,dbms.cluster.raft.binding_timeout>>: label:enterprise-edition[Enterprise only]The time allowed for a database on a Neo4j server to either join a cluster or form a new cluster with the other Neo4j Servers provided by `dbms.cluster.discovery.endpoints`.
* <<config_dbms.cluster.raft.client.max_channels,dbms.cluster.raft.client.max_channels>>: label:enterprise-edition[Enterprise only]The maximum number of TCP channels between two nodes to operate the raft protocol.
* <<config_dbms.cluster.raft.election_failure_detection_window,dbms.cluster.raft.election_failure_detection_window>>: label:enterprise-edition[Enterprise only]The rate at which leader elections happen.
* <<config_dbms.cluster.raft.leader_failure_detection_window,dbms.cluster.raft.leader_failure_detection_window>>: label:enterprise-edition[Enterprise only]The time window within which the loss of the leader is detected and the first re-election attempt is held.
* <<config_dbms.cluster.raft.leader_transfer.balancing_strategy,dbms.cluster.raft.leader_transfer.balancing_strategy>>: label:enterprise-edition[Enterprise only]Which strategy to use when transferring database leaderships around a cluster.
* <<config_dbms.cluster.raft.log.pruning_frequency,dbms.cluster.raft.log.pruning_frequency>>: label:enterprise-edition[Enterprise only]RAFT log pruning frequency.
* <<config_dbms.cluster.raft.log.reader_pool_size,dbms.cluster.raft.log.reader_pool_size>>: label:enterprise-edition[Enterprise only]RAFT log reader pool size.
* <<config_dbms.cluster.raft.log.rotation_size,dbms.cluster.raft.log.rotation_size>>: label:enterprise-edition[Enterprise only]RAFT log rotation size.
* <<config_dbms.cluster.raft.membership.join_max_lag,dbms.cluster.raft.membership.join_max_lag>>: label:enterprise-edition[Enterprise only]Maximum amount of lag accepted for a new follower to join the Raft group.
* <<config_dbms.cluster.raft.membership.join_timeout,dbms.cluster.raft.membership.join_timeout>>: label:enterprise-edition[Enterprise only]Time out for a new member to catch up.
* <<config_dbms.cluster.store_copy.max_retry_time_per_request,dbms.cluster.store_copy.max_retry_time_per_request>>: label:enterprise-edition[Enterprise only]Maximum retry time per request during store copy.
* <<config_dbms.cypher.forbid_exhaustive_shortestpath,dbms.cypher.forbid_exhaustive_shortestpath>>: This setting is associated with performance optimization.
* <<config_dbms.cypher.forbid_shortestpath_common_nodes,dbms.cypher.forbid_shortestpath_common_nodes>>: This setting is associated with performance optimization.
* <<config_dbms.cypher.hints_error,dbms.cypher.hints_error>>: Set this to specify the behavior when Cypher planner or runtime hints cannot be fulfilled.
* <<config_dbms.cypher.lenient_create_relationship,dbms.cypher.lenient_create_relationship>>: Set this to change the behavior for Cypher create relationship when the start or end node is missing.
* <<config_dbms.cypher.min_replan_interval,dbms.cypher.min_replan_interval>>: The minimum time between possible cypher query replanning events.
* <<config_dbms.cypher.planner,dbms.cypher.planner>>: Set this to specify the default planner for the default language version.
* <<config_dbms.cypher.render_plan_description,dbms.cypher.render_plan_description>>: If set to `true` a textual representation of the plan description will be rendered on the server for all queries running with `EXPLAIN` or `PROFILE`.
* <<config_dbms.cypher.statistics_divergence_threshold,dbms.cypher.statistics_divergence_threshold>>: The threshold for statistics above which a plan is considered stale.
+
If any of the underlying statistics used to create the plan have changed more than this value, the plan will be considered stale and will be replanned.
* <<config_dbms.databases.seed_from_uri_providers,dbms.databases.seed_from_uri_providers>>: label:enterprise-edition[Enterprise only]Databases may be created from an existing 'seed' (a database backup or dump) stored at some source URI.
* <<config_dbms.db.timezone,dbms.db.timezone>>: Database timezone.
* <<config_dbms.kubernetes.address,dbms.kubernetes.address>>: label:enterprise-edition[Enterprise only]Address for Kubernetes API.
* <<config_dbms.kubernetes.ca_crt,dbms.kubernetes.ca_crt>>: label:enterprise-edition[Enterprise only]File location of CA certificate for Kubernetes API.
* <<config_dbms.kubernetes.cluster_domain,dbms.kubernetes.cluster_domain>>: label:enterprise-edition[Enterprise only]Kubernetes cluster domain.
* <<config_dbms.kubernetes.label_selector,dbms.kubernetes.label_selector>>: label:enterprise-edition[Enterprise only]LabelSelector for Kubernetes API.
* <<config_dbms.kubernetes.namespace,dbms.kubernetes.namespace>>: label:enterprise-edition[Enterprise only]File location of namespace for Kubernetes API.
* <<config_dbms.kubernetes.service_port_name,dbms.kubernetes.service_port_name>>: label:enterprise-edition[Enterprise only]Service port name for discovery for Kubernetes API.
* <<config_dbms.kubernetes.token,dbms.kubernetes.token>>: label:enterprise-edition[Enterprise only]File location of token for Kubernetes API.
* <<config_dbms.logs.http.enabled,dbms.logs.http.enabled>>: Enable HTTP request logging.
* <<config_dbms.max_databases,dbms.max_databases>>: label:enterprise-edition[Enterprise only]The maximum number of databases.
* <<config_dbms.memory.tracking.enable,dbms.memory.tracking.enable>>: Enable off heap and on heap memory tracking.
* <<config_dbms.memory.transaction.total.max,dbms.memory.transaction.total.max>>: Limit the amount of memory that all of the running transactions can consume, in bytes (or kilobytes with the 'k' suffix, megabytes with 'm' and gigabytes with 'g').
* <<config_dbms.netty.ssl.provider,dbms.netty.ssl.provider>>: Netty SSL provider.
* <<config_dbms.routing.client_side.enforce_for_domains,dbms.routing.client_side.enforce_for_domains>>: Always use client side routing (regardless of the default router) for neo4j:// protocol connections to these domains.
* <<config_dbms.routing.default_router,dbms.routing.default_router>>: Routing strategy for neo4j:// protocol connections.
Default is `CLIENT`, using client-side routing, with server-side routing as a fallback (if enabled).
When set to `SERVER`, client-side routing is short-circuited, and requests will rely on server-side routing (which must be enabled for proper operation, i.e.
* <<config_dbms.routing.driver.connection.connect_timeout,dbms.routing.driver.connection.connect_timeout>>: Socket connection timeout.
A timeout of zero is treated as an infinite timeout and will be bound by the timeout configured on the
operating system level.
* <<config_dbms.routing.driver.connection.max_lifetime,dbms.routing.driver.connection.max_lifetime>>: Pooled connections older than this threshold will be closed and removed from the pool.
Setting this option to a low value will cause a high connection churn and might result in a performance hit.
It is recommended to set maximum lifetime to a slightly smaller value than the one configured in network
equipment (load balancer, proxy, firewall, etc.
* <<config_dbms.routing.driver.connection.pool.acquisition_timeout,dbms.routing.driver.connection.pool.acquisition_timeout>>: Maximum amount of time spent attempting to acquire a connection from the connection pool.
This timeout only kicks in when all existing connections are being used and no new connections can be created because maximum connection pool size has been reached.
Error is raised when connection can't be acquired within configured time.
Negative values are allowed and result in unlimited acquisition timeout.
* <<config_dbms.routing.driver.connection.pool.idle_test,dbms.routing.driver.connection.pool.idle_test>>: Pooled connections that have been idle in the pool for longer than this timeout will be tested before they are used again, to ensure they are still alive.
If this option is set too low, an additional network call will be incurred when acquiring a connection, which causes a performance hit.
If this is set high, no longer live connections might be used which might lead to errors.
Hence, this parameter tunes a balance between the likelihood of experiencing connection problems and performance
Normally, this parameter should not need tuning.
Value 0 means connections will always be tested for validity.
* <<config_dbms.routing.driver.connection.pool.max_size,dbms.routing.driver.connection.pool.max_size>>: Maximum total number of connections to be managed by a connection pool.
The limit is enforced for a combination of a host and user.
* <<config_dbms.routing.driver.logging.level,dbms.routing.driver.logging.level>>: Sets level for driver internal logging.
* <<config_dbms.routing.enabled,dbms.routing.enabled>>: Enable server-side routing in clusters using an additional bolt connector.
When configured, this allows requests to be forwarded from one cluster member to another, if the requests can't be satisfied by the first member (e.g.
* <<config_dbms.routing.load_balancing.plugin,dbms.routing.load_balancing.plugin>>: label:enterprise-edition[Enterprise only]The load balancing plugin to use.
* <<config_dbms.routing.load_balancing.shuffle_enabled,dbms.routing.load_balancing.shuffle_enabled>>: label:enterprise-edition[Enterprise only]Enables shuffling of the returned load balancing result.
* <<config_dbms.routing.reads_on_primaries_enabled,dbms.routing.reads_on_primaries_enabled>>: label:enterprise-edition[Enterprise only]Configure if the `dbms.routing.getRoutingTable()` procedure should include non-writer primaries as read endpoints or return only secondaries.
* <<config_dbms.routing.reads_on_writers_enabled,dbms.routing.reads_on_writers_enabled>>: label:enterprise-edition[Enterprise only]Configure if the `dbms.routing.getRoutingTable()` procedure should include the writer as read endpoint or return only non-writers (non writer primaries and secondaries) Note: writer is returned as read endpoint if no other member is present all.
* <<config_dbms.routing_ttl,dbms.routing_ttl>>: How long callers should cache the response of the routing procedure `dbms.routing.getRoutingTable()`.
* <<config_dbms.security.allow_csv_import_from_file_urls,dbms.security.allow_csv_import_from_file_urls>>: Determines if Cypher will allow using file URLs when loading data using `LOAD CSV`.
* <<config_dbms.security.auth_cache_max_capacity,dbms.security.auth_cache_max_capacity>>: label:enterprise-edition[Enterprise only]The maximum capacity for authentication and authorization caches (respectively).
* <<config_dbms.security.auth_cache_ttl,dbms.security.auth_cache_ttl>>: label:enterprise-edition[Enterprise only]The time to live (TTL) for cached authentication and authorization info when using external auth providers (LDAP or plugin).
* <<config_dbms.security.auth_cache_use_ttl,dbms.security.auth_cache_use_ttl>>: label:enterprise-edition[Enterprise only]Enable time-based eviction of the authentication and authorization info cache for external auth providers (LDAP or plugin).
* <<config_dbms.security.auth_enabled,dbms.security.auth_enabled>>: Enable auth requirement to access Neo4j.
* <<config_dbms.security.auth_lock_time,dbms.security.auth_lock_time>>: The amount of time user account should be locked after a configured number of unsuccessful authentication attempts.
* <<config_dbms.security.auth_max_failed_attempts,dbms.security.auth_max_failed_attempts>>: The maximum number of unsuccessful authentication attempts before imposing a user lock for  the configured amount of time, as defined by `dbms.security.auth_lock_time`.The locked out user will not be able to log in until the lock period expires, even if correct  credentials are provided.
* <<config_dbms.security.authentication_providers,dbms.security.authentication_providers>>: label:enterprise-edition[Enterprise only]A list of security authentication providers containing the users and roles.
* <<config_dbms.security.authorization_providers,dbms.security.authorization_providers>>: label:enterprise-edition[Enterprise only]A list of security authorization providers containing the users and roles.
* <<config_dbms.security.cluster_status_auth_enabled,dbms.security.cluster_status_auth_enabled>>: label:enterprise-edition[Enterprise only]Require authorization for access to the Causal Clustering status endpoints.
* <<config_dbms.security.http_access_control_allow_origin,dbms.security.http_access_control_allow_origin>>: Value of the Access-Control-Allow-Origin header sent over any HTTP or HTTPS connector.
* <<config_dbms.security.http_auth_allowlist,dbms.security.http_auth_allowlist>>: Defines an allowlist of http paths where Neo4j authentication is not required.
* <<config_dbms.security.http_strict_transport_security,dbms.security.http_strict_transport_security>>: Value of the HTTP Strict-Transport-Security (HSTS) response header.
* <<config_dbms.security.key.name,dbms.security.key.name>>: label:enterprise-edition[Enterprise only]Name of the 256 length AES encryption key, which is used for the symmetric encryption.
* <<config_dbms.security.keystore.password,dbms.security.keystore.password>>: label:enterprise-edition[Enterprise only]Password for accessing the keystore holding a 256 length AES encryption key, which is used for the symmetric encryption.
* <<config_dbms.security.keystore.path,dbms.security.keystore.path>>: label:enterprise-edition[Enterprise only]Location of the keystore holding a 256 length AES encryption key, which is used for the symmetric encryption of secrets held in system database.
* <<config_dbms.security.ldap.authentication.attribute,dbms.security.ldap.authentication.attribute>>: label:enterprise-edition[Enterprise only]The attribute to use when looking up users.
Using this setting requires `dbms.security.ldap.authentication.search_for_attribute` to be true and thus `dbms.security.ldap.authorization.system_username` and `dbms.security.ldap.authorization.system_password` to be configured.
* <<config_dbms.security.ldap.authentication.cache_enabled,dbms.security.ldap.authentication.cache_enabled>>: label:enterprise-edition[Enterprise only]Determines if the result of authentication via the LDAP server should be cached or not.
* <<config_dbms.security.ldap.authentication.mechanism,dbms.security.ldap.authentication.mechanism>>: label:enterprise-edition[Enterprise only]LDAP authentication mechanism.
* <<config_dbms.security.ldap.authentication.search_for_attribute,dbms.security.ldap.authentication.search_for_attribute>>: label:enterprise-edition[Enterprise only]Perform authentication by searching for an unique attribute of a user.
Using this setting requires `dbms.security.ldap.authorization.system_username` and `dbms.security.ldap.authorization.system_password` to be configured.
* <<config_dbms.security.ldap.authentication.user_dn_template,dbms.security.ldap.authentication.user_dn_template>>: label:enterprise-edition[Enterprise only]LDAP user DN template.
* <<config_dbms.security.ldap.authorization.access_permitted_group,dbms.security.ldap.authorization.access_permitted_group>>: label:enterprise-edition[Enterprise only]The LDAP group to which a user must belong to get any access to the system.Set this to restrict access to a subset of LDAP users belonging to a particular group.
* <<config_dbms.security.ldap.authorization.group_membership_attributes,dbms.security.ldap.authorization.group_membership_attributes>>: label:enterprise-edition[Enterprise only]A list of attribute names on a user object that contains groups to be used for mapping to roles when LDAP authorization is enabled.
* <<config_dbms.security.ldap.authorization.group_to_role_mapping,dbms.security.ldap.authorization.group_to_role_mapping>>: label:enterprise-edition[Enterprise only]An authorization mapping from LDAP group names to Neo4j role names.
* <<config_dbms.security.ldap.authorization.nested_groups_enabled,dbms.security.ldap.authorization.nested_groups_enabled>>: label:enterprise-edition[Enterprise only]This setting determines whether multiple LDAP search results will be processed (as is required for the lookup of nested groups).
* <<config_dbms.security.ldap.authorization.nested_groups_search_filter,dbms.security.ldap.authorization.nested_groups_search_filter>>: label:enterprise-edition[Enterprise only]The search template which will be used to find the nested groups which the user is a member of.
* <<config_dbms.security.ldap.authorization.system_password,dbms.security.ldap.authorization.system_password>>: label:enterprise-edition[Enterprise only]An LDAP system account password to use for authorization searches when `dbms.security.ldap.authorization.use_system_account` is `true`.
* <<config_dbms.security.ldap.authorization.system_username,dbms.security.ldap.authorization.system_username>>: label:enterprise-edition[Enterprise only]An LDAP system account username to use for authorization searches when `dbms.security.ldap.authorization.use_system_account` is `true`.
* <<config_dbms.security.ldap.authorization.use_system_account,dbms.security.ldap.authorization.use_system_account>>: label:enterprise-edition[Enterprise only]Perform LDAP search for authorization info using a system account instead of the user's own account.
If this is set to `false` (default), the search for group membership will be performed directly after authentication using the LDAP context bound with the user's own account.
* <<config_dbms.security.ldap.authorization.user_search_base,dbms.security.ldap.authorization.user_search_base>>: label:enterprise-edition[Enterprise only]The name of the base object or named context to search for user objects when LDAP authorization is enabled.
* <<config_dbms.security.ldap.authorization.user_search_filter,dbms.security.ldap.authorization.user_search_filter>>: label:enterprise-edition[Enterprise only]The LDAP search filter to search for a user principal when LDAP authorization is enabled.
* <<config_dbms.security.ldap.connection_timeout,dbms.security.ldap.connection_timeout>>: label:enterprise-edition[Enterprise only]The timeout for establishing an LDAP connection.
* <<config_dbms.security.ldap.host,dbms.security.ldap.host>>: label:enterprise-edition[Enterprise only]URL of LDAP server to use for authentication and authorization.
* <<config_dbms.security.ldap.read_timeout,dbms.security.ldap.read_timeout>>: label:enterprise-edition[Enterprise only]The timeout for an LDAP read request (i.e.
* <<config_dbms.security.ldap.referral,dbms.security.ldap.referral>>: label:enterprise-edition[Enterprise only]The LDAP referral behavior when creating a connection.
* <<config_dbms.security.ldap.use_starttls,dbms.security.ldap.use_starttls>>: label:enterprise-edition[Enterprise only]Use secure communication with the LDAP server using opportunistic TLS.
* <<config_dbms.security.log_successful_authentication,dbms.security.log_successful_authentication>>: label:enterprise-edition[Enterprise only]Set to log successful authentication events to the security log.
* <<config_dbms.security.oidc.-provider-.audience,dbms.security.oidc.<provider>.audience>>: label:enterprise-edition[Enterprise only]Expected values of the Audience (aud) claim in the id token.
* <<config_dbms.security.oidc.-provider-.auth_endpoint,dbms.security.oidc.<provider>.auth_endpoint>>: label:enterprise-edition[Enterprise only]The OIDC authorization endpoint.
* <<config_dbms.security.oidc.-provider-.auth_flow,dbms.security.oidc.<provider>.auth_flow>>: label:enterprise-edition[Enterprise only]The OIDC flow to use.
* <<config_dbms.security.oidc.-provider-.auth_params,dbms.security.oidc.<provider>.auth_params>>: label:enterprise-edition[Enterprise only]Optional additional parameters that the auth endpoint requires.
* <<config_dbms.security.oidc.-provider-.authorization.group_to_role_mapping,dbms.security.oidc.<provider>.authorization.group_to_role_mapping>>: label:enterprise-edition[Enterprise only]An authorization mapping from IdP group names to Neo4j role names.
* <<config_dbms.security.oidc.-provider-.claims.groups,dbms.security.oidc.<provider>.claims.groups>>: label:enterprise-edition[Enterprise only]The claim to use as the list of groups in Neo4j.
* <<config_dbms.security.oidc.-provider-.claims.username,dbms.security.oidc.<provider>.claims.username>>: label:enterprise-edition[Enterprise only]The claim to use as the username in Neo4j.
* <<config_dbms.security.oidc.-provider-.client_id,dbms.security.oidc.<provider>.client_id>>: label:enterprise-edition[Enterprise only]Client id needed if token contains multiple Audience (aud) claims.
* <<config_dbms.security.oidc.-provider-.config,dbms.security.oidc.<provider>.config>>: label:enterprise-edition[Enterprise only]
* <<config_dbms.security.oidc.-provider-.display_name,dbms.security.oidc.<provider>.display_name>>: label:enterprise-edition[Enterprise only]The user-facing name of the provider as provided by the discovery endpoint to clients (Bloom, Browser etc.).
* <<config_dbms.security.oidc.-provider-.get_groups_from_user_info,dbms.security.oidc.<provider>.get_groups_from_user_info>>: label:enterprise-edition[Enterprise only]When turned on, Neo4j gets the groups from the provider user info endpoint.
* <<config_dbms.security.oidc.-provider-.get_username_from_user_info,dbms.security.oidc.<provider>.get_username_from_user_info>>: label:enterprise-edition[Enterprise only]When turned on, Neo4j gets the username from the provider user info endpoint.
* <<config_dbms.security.oidc.-provider-.issuer,dbms.security.oidc.<provider>.issuer>>: label:enterprise-edition[Enterprise only]The expected value of the iss claim in the id token.
* <<config_dbms.security.oidc.-provider-.jwks_uri,dbms.security.oidc.<provider>.jwks_uri>>: label:enterprise-edition[Enterprise only]The location of the JWK public key set for the identity provider.
* <<config_dbms.security.oidc.-provider-.params,dbms.security.oidc.<provider>.params>>: label:enterprise-edition[Enterprise only]The map is a semicolon separated list of key-value pairs.
* <<config_dbms.security.oidc.-provider-.token_endpoint,dbms.security.oidc.<provider>.token_endpoint>>: label:enterprise-edition[Enterprise only]The OIDC token endpoint.
* <<config_dbms.security.oidc.-provider-.token_params,dbms.security.oidc.<provider>.token_params>>: label:enterprise-edition[Enterprise only]Optional query parameters that the token endpoint requires.
* <<config_dbms.security.oidc.-provider-.user_info_uri,dbms.security.oidc.<provider>.user_info_uri>>: label:enterprise-edition[Enterprise only]The identity providers user info uri.
* <<config_dbms.security.oidc.-provider-.well_known_discovery_uri,dbms.security.oidc.<provider>.well_known_discovery_uri>>: label:enterprise-edition[Enterprise only]The 'well known' OpenID Connect Discovery endpoint used to fetch identity provider settings.
* <<config_dbms.security.procedures.allowlist,dbms.security.procedures.allowlist>>: A list of procedures (comma separated) that are to be loaded.
* <<config_dbms.security.procedures.unrestricted,dbms.security.procedures.unrestricted>>: A list of procedures and user defined functions (comma separated) that are allowed full access to the database.
* <<config_initial.dbms.database_allocator,initial.dbms.database_allocator>>: label:enterprise-edition[Enterprise only]Name of the initial database allocator.
* <<config_initial.dbms.default_database,initial.dbms.default_database>>: Name of the default database (aliases are not supported).
* <<config_initial.dbms.default_primaries_count,initial.dbms.default_primaries_count>>: label:enterprise-edition[Enterprise only]Initial default number of primary instances of user databases.
* <<config_initial.dbms.default_secondaries_count,initial.dbms.default_secondaries_count>>: label:enterprise-edition[Enterprise only]Initial default number of secondary instances of user databases.
* <<config_initial.server.allowed_databases,initial.server.allowed_databases>>: label:enterprise-edition[Enterprise only]The names of databases that are allowed on this server - all others are denied.
* <<config_initial.server.denied_databases,initial.server.denied_databases>>: label:enterprise-edition[Enterprise only]The names of databases that are not allowed on this server.
* <<config_initial.server.mode_constraint,initial.server.mode_constraint>>: label:enterprise-edition[Enterprise only]An instance can restrict itself to allow databases to be hosted only as primaries or secondaries.
* <<config_server.backup.enabled,server.backup.enabled>>: label:enterprise-edition[Enterprise only]Enable support for running online backups.
* <<config_server.backup.listen_address,server.backup.listen_address>>: label:enterprise-edition[Enterprise only]Network interface and port for the backup server to listen on.
* <<config_server.backup.store_copy_max_retry_time_per_request,server.backup.store_copy_max_retry_time_per_request>>: label:enterprise-edition[Enterprise only]Maximum retry time per request during store copy.
* <<config_server.bolt.advertised_address,server.bolt.advertised_address>>: Advertised address for this connector.
* <<config_server.bolt.connection_keep_alive,server.bolt.connection_keep_alive>>: The maximum time to wait before sending a NOOP on connections waiting for responses from active ongoing queries.The minimum value is 1 millisecond.
* <<config_server.bolt.connection_keep_alive_for_requests,server.bolt.connection_keep_alive_for_requests>>: The type of messages to enable keep-alive messages for (ALL, STREAMING or OFF).
* <<config_server.bolt.connection_keep_alive_probes,server.bolt.connection_keep_alive_probes>>: The total amount of probes to be missed before a connection is considered stale.The minimum for this value is 1.
* <<config_server.bolt.connection_keep_alive_streaming_scheduling_interval,server.bolt.connection_keep_alive_streaming_scheduling_interval>>: The interval between every scheduled keep-alive check on all connections with active queries.
* <<config_server.bolt.enabled,server.bolt.enabled>>: Enable the bolt connector.
* <<config_server.bolt.listen_address,server.bolt.listen_address>>: Address the connector should bind to.
* <<config_server.bolt.ocsp_stapling_enabled,server.bolt.ocsp_stapling_enabled>>: Enable server OCSP stapling for bolt and http connectors.
* <<config_server.bolt.thread_pool_keep_alive,server.bolt.thread_pool_keep_alive>>: The maximum time an idle thread in the thread pool bound to this connector will wait for new tasks.
* <<config_server.bolt.thread_pool_max_size,server.bolt.thread_pool_max_size>>: The maximum number of threads allowed in the thread pool bound to this connector.
* <<config_server.bolt.thread_pool_min_size,server.bolt.thread_pool_min_size>>: The number of threads to keep in the thread pool bound to this connector, even if they are idle.
* <<config_server.bolt.tls_level,server.bolt.tls_level>>: Encryption level to require this connector to use.
* <<config_server.cluster.advertised_address,server.cluster.advertised_address>>: label:enterprise-edition[Enterprise only]Advertised hostname/IP address and port for the transaction shipping server.
* <<config_server.cluster.catchup.connect_randomly_to_server_group,server.cluster.catchup.connect_randomly_to_server_group>>: label:enterprise-edition[Enterprise only]Comma separated list of groups to be used by the connect-randomly-to-server-group selection strategy.
* <<config_server.cluster.catchup.upstream_strategy,server.cluster.catchup.upstream_strategy>>: label:enterprise-edition[Enterprise only]An ordered list in descending preference of the strategy which secondaries use to choose the upstream server from which to pull transactional updates.
* <<config_server.cluster.catchup.user_defined_upstream_strategy,server.cluster.catchup.user_defined_upstream_strategy>>: label:enterprise-edition[Enterprise only]Configuration of a user-defined upstream selection strategy.
* <<config_server.cluster.listen_address,server.cluster.listen_address>>: label:enterprise-edition[Enterprise only]Network interface and port for the transaction shipping server to listen on.
* <<config_server.cluster.network.native_transport_enabled,server.cluster.network.native_transport_enabled>>: label:enterprise-edition[Enterprise only]Use native transport if available.
* <<config_server.cluster.raft.advertised_address,server.cluster.raft.advertised_address>>: label:enterprise-edition[Enterprise only]Advertised hostname/IP address and port for the RAFT server.
* <<config_server.cluster.raft.listen_address,server.cluster.raft.listen_address>>: label:enterprise-edition[Enterprise only]Network interface and port for the RAFT server to listen on.
* <<config_server.cluster.system_database_mode,server.cluster.system_database_mode>>: label:enterprise-edition[Enterprise only]Users must manually specify the mode for the system database on each instance.
* <<config_server.config.strict_validation.enabled,server.config.strict_validation.enabled>>: A strict configuration validation will prevent the database from starting up if unknown configuration options are specified in the neo4j settings namespace (such as dbms., cypher., etc) or if settings are declared multiple times.
* <<config_server.databases.default_to_read_only,server.databases.default_to_read_only>>: Whether or not any database on this instance are read_only by default.
* <<config_server.databases.read_only,server.databases.read_only>>: List of databases for which to prevent write queries.
* <<config_server.databases.writable,server.databases.writable>>: List of databases for which to allow write queries.
* <<config_server.db.query_cache_size,server.db.query_cache_size>>: The number of cached Cypher query execution plans per database.
* <<config_server.default_advertised_address,server.default_advertised_address>>: Default hostname or IP address the server uses to advertise itself.
* <<config_server.default_listen_address,server.default_listen_address>>: Default network interface to listen for incoming connections.
* <<config_server.directories.cluster_state,server.directories.cluster_state>>: label:enterprise-edition[Enterprise only]Directory to hold cluster state including Raft log.
* <<config_server.directories.data,server.directories.data>>: Path of the data directory.
* <<config_server.directories.dumps.root,server.directories.dumps.root>>: Root location where Neo4j will store database dumps optionally produced when dropping said databases.
* <<config_server.directories.import,server.directories.import>>: Sets the root directory for file URLs used with the Cypher `LOAD CSV` clause.
* <<config_server.directories.lib,server.directories.lib>>: Path of the lib directory.
* <<config_server.directories.licenses,server.directories.licenses>>: Path of the licenses directory.
* <<config_server.directories.logs,server.directories.logs>>: Path of the logs directory.
* <<config_server.directories.metrics,server.directories.metrics>>: label:enterprise-edition[Enterprise only]The target location of the CSV files: a path to a directory wherein a CSV file per reported field  will be written.
* <<config_server.directories.neo4j_home,server.directories.neo4j_home>>: Root relative to which directory settings are resolved.
* <<config_server.directories.plugins,server.directories.plugins>>: Location of the database plugin directory.
* <<config_server.directories.run,server.directories.run>>: Path of the run directory.
* <<config_server.directories.script.root,server.directories.script.root>>: Root location where Neo4j will store scripts for configured databases.
* <<config_server.directories.transaction.logs.root,server.directories.transaction.logs.root>>: Root location where Neo4j will store transaction logs for configured databases.
* <<config_server.discovery.advertised_address,server.discovery.advertised_address>>: label:enterprise-edition[Enterprise only]Advertised cluster member discovery management communication.
* <<config_server.discovery.listen_address,server.discovery.listen_address>>: label:enterprise-edition[Enterprise only]Host and port to bind the cluster member discovery management communication.
* <<config_server.dynamic.setting.allowlist,server.dynamic.setting.allowlist>>: label:enterprise-edition[Enterprise only]A list of setting name patterns (comma separated) that are allowed to be dynamically changed.
* <<config_server.groups,server.groups>>: label:enterprise-edition[Enterprise only]A list of tag names for the server used when configuring load balancing and replication policies.
* <<config_server.http.advertised_address,server.http.advertised_address>>: Advertised address for this connector.
* <<config_server.http.enabled,server.http.enabled>>: Enable the http connector.
* <<config_server.http.listen_address,server.http.listen_address>>: Address the connector should bind to.
* <<config_server.http_enabled_modules,server.http_enabled_modules>>: Defines the set of modules loaded into the Neo4j web server.
* <<config_server.https.advertised_address,server.https.advertised_address>>: Advertised address for this connector.
* <<config_server.https.enabled,server.https.enabled>>: Enable the https connector.
* <<config_server.https.listen_address,server.https.listen_address>>: Address the connector should bind to.
* <<config_server.jvm.additional,server.jvm.additional>>: Additional JVM arguments.
* <<config_server.logs.config,server.logs.config>>: Path to the logging configuration for debug, query, http and security logs.
* <<config_server.logs.debug.enabled,server.logs.debug.enabled>>: Enable the debug log.
* <<config_server.logs.gc.enabled,server.logs.gc.enabled>>: Enable GC Logging.
* <<config_server.logs.gc.options,server.logs.gc.options>>: GC Logging Options.
* <<config_server.logs.gc.rotation.keep_number,server.logs.gc.rotation.keep_number>>: Number of GC logs to keep.
* <<config_server.logs.gc.rotation.size,server.logs.gc.rotation.size>>: Size of each GC log that is kept.
* <<config_server.logs.user.config,server.logs.user.config>>: Path to the logging configuration of user logs.
* <<config_server.max_databases,server.max_databases>>: label:enterprise-edition[Enterprise only]The maximum number of databases. 
This setting will be deprecated in favour of <<config_dbms.max_databases,`dbms.max_databases`>> in a future version.
* <<config_server.memory.heap.initial_size,server.memory.heap.initial_size>>: Initial heap size.
* <<config_server.memory.heap.max_size,server.memory.heap.max_size>>: Maximum heap size.
* <<config_server.memory.off_heap.block_cache_size,server.memory.off_heap.block_cache_size>>: Defines the size of the off-heap memory blocks cache.
* <<config_server.memory.off_heap.max_cacheable_block_size,server.memory.off_heap.max_cacheable_block_size>>: Defines the maximum size of an off-heap memory block that can be cached to speed up allocations.
* <<config_server.memory.off_heap.max_size,server.memory.off_heap.max_size>>: The maximum amount of off-heap memory that can be used to store transaction state data; it's a total amount of memory shared across all active transactions.
* <<config_server.memory.pagecache.directio,server.memory.pagecache.directio>>: Use direct I/O for page cache.
* <<config_server.memory.pagecache.flush.buffer.enabled,server.memory.pagecache.flush.buffer.enabled>>: Page cache can be configured to use a temporal buffer for flushing purposes.
* <<config_server.memory.pagecache.flush.buffer.size_in_pages,server.memory.pagecache.flush.buffer.size_in_pages>>: Page cache can be configured to use a temporal buffer for flushing purposes.
* <<config_server.memory.pagecache.scan.prefetchers,server.memory.pagecache.scan.prefetchers>>: The maximum number of worker threads to use for pre-fetching data when doing sequential scans.
* <<config_server.memory.pagecache.size,server.memory.pagecache.size>>: The amount of memory to use for mapping the store files.
* <<config_server.metrics.csv.enabled,server.metrics.csv.enabled>>: label:enterprise-edition[Enterprise only]Set to `true` to enable exporting metrics to CSV files.
* <<config_server.metrics.csv.interval,server.metrics.csv.interval>>: label:enterprise-edition[Enterprise only]The reporting interval for the CSV files.
* <<config_server.metrics.csv.rotation.compression,server.metrics.csv.rotation.compression>>: label:enterprise-edition[Enterprise only]Decides what compression to use for the csv history files.
* <<config_server.metrics.csv.rotation.keep_number,server.metrics.csv.rotation.keep_number>>: label:enterprise-edition[Enterprise only]Maximum number of history files for the csv files.
* <<config_server.metrics.csv.rotation.size,server.metrics.csv.rotation.size>>: label:enterprise-edition[Enterprise only]The file size in bytes at which the csv files will auto-rotate.
* <<config_server.metrics.enabled,server.metrics.enabled>>: label:enterprise-edition[Enterprise only]Enable metrics.
* <<config_server.metrics.filter,server.metrics.filter>>: label:enterprise-edition[Enterprise only]Specifies which metrics should be enabled by using a comma separated list of globbing patterns.
* <<config_server.metrics.graphite.enabled,server.metrics.graphite.enabled>>: label:enterprise-edition[Enterprise only]Set to `true` to enable exporting metrics to Graphite.
* <<config_server.metrics.graphite.interval,server.metrics.graphite.interval>>: label:enterprise-edition[Enterprise only]The reporting interval for Graphite.
* <<config_server.metrics.graphite.server,server.metrics.graphite.server>>: label:enterprise-edition[Enterprise only]The hostname or IP address of the Graphite server.
* <<config_server.metrics.jmx.enabled,server.metrics.jmx.enabled>>: label:enterprise-edition[Enterprise only]Set to `true` to enable the JMX metrics endpoint.
* <<config_server.metrics.prefix,server.metrics.prefix>>: label:enterprise-edition[Enterprise only]A common prefix for the reported metrics field names.
* <<config_server.metrics.prometheus.enabled,server.metrics.prometheus.enabled>>: label:enterprise-edition[Enterprise only]Set to `true` to enable the Prometheus endpoint.
* <<config_server.metrics.prometheus.endpoint,server.metrics.prometheus.endpoint>>: label:enterprise-edition[Enterprise only]The hostname and port to use as Prometheus endpoint.
* <<config_server.panic.shutdown_on_panic,server.panic.shutdown_on_panic>>: label:enterprise-edition[Enterprise only]If there is a Database Management System Panic (an irrecoverable error) should the neo4j process shut down or continue running.
* <<config_server.routing.advertised_address,server.routing.advertised_address>>: label:enterprise-edition[Enterprise only]The advertised address for the intra-cluster routing connector.
* <<config_server.routing.listen_address,server.routing.listen_address>>: The address the routing connector should bind to.
* <<config_server.threads.worker_count,server.threads.worker_count>>: Number of Neo4j worker threads.
* <<config_server.unmanaged_extension_classes,server.unmanaged_extension_classes>>: Comma-separated list of <classname>=<mount point> for unmanaged extensions.
* <<config_server.windows_service_name,server.windows_service_name>>: Name of the Windows Service managing Neo4j when installed using `neo4j install-service`.
endif::nonhtmloutput[]


// end::settings-reference-all-settings[]

[[config_browser.allow_outgoing_connections]]
.browser.allow_outgoing_connections
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Configure the policy for outgoing Neo4j Browser connections.
|Valid values
a|browser.allow_outgoing_connections, a boolean
|Default value
m|+++true+++
|===

[[config_browser.credential_timeout]]
.browser.credential_timeout
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Configure the Neo4j Browser to time out logged in users after this idle period. Setting this to 0 indicates no limit.
|Valid values
a|browser.credential_timeout, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++0s+++
|===

[[config_browser.post_connect_cmd]]
.browser.post_connect_cmd
[cols="<1s,<4"]
|===
|Description
a|Commands to be run when Neo4j Browser successfully connects to this server. Separate multiple commands with semi-colon.
|Valid values
a|browser.post_connect_cmd, a string
|Default value
m|++++++
|===

[[config_browser.remote_content_hostname_whitelist]]
.browser.remote_content_hostname_whitelist
[cols="<1s,<4"]
|===
|Description
a|Whitelist of hosts for the Neo4j Browser to be allowed to fetch content from.
|Valid values
a|browser.remote_content_hostname_whitelist, a string
|Default value
m|+++guides.neo4j.com,localhost+++
|===

[[config_browser.retain_connection_credentials]]
.browser.retain_connection_credentials
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Configure the Neo4j Browser to store or not store user credentials.
|Valid values
a|browser.retain_connection_credentials, a boolean
|Default value
m|+++true+++
|===

[[config_browser.retain_editor_history]]
.browser.retain_editor_history
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Configure the Neo4j Browser to store or not store user editor history.
|Valid values
a|browser.retain_editor_history, a boolean
|Default value
m|+++true+++
|===

[[config_client.allow_telemetry]]
.client.allow_telemetry
[cols="<1s,<4"]
|===
|Description
a|Configure client applications such as Browser and Bloom to send Product Analytics data.
|Valid values
a|client.allow_telemetry, a boolean
|Default value
m|+++true+++
|===

[[config_db.checkpoint]]
.db.checkpoint
[cols="<1s,<4"]
|===
|Description
a|Configures the general policy for when check-points should occur. The default policy is the 'periodic' check-point policy, as specified by the '<<config_db.checkpoint.interval.tx,db.checkpoint.interval.tx>>' and '<<config_db.checkpoint.interval.time,db.checkpoint.interval.time>>' settings. The Neo4j Enterprise Edition provides two alternative policies: The first is the 'continuous' check-point policy, which will ignore those settings and run the check-point process all the time. The second is the 'volumetric' check-point policy, which makes a best-effort at check-pointing often enough so that the database doesn't get too far behind on deleting old transaction logs in accordance with the '<<config_db.tx_log.rotation.retention_policy,db.tx_log.rotation.retention_policy>>' setting.
|Valid values
a|db.checkpoint, one of [PERIODIC, CONTINUOUS, VOLUME, VOLUMETRIC]
|Default value
m|+++PERIODIC+++
|===

[[config_db.checkpoint.interval.time]]
.db.checkpoint.interval.time
[cols="<1s,<4"]
|===
|Description
a|Configures the time interval between check-points. The database will not check-point more often than this (unless check pointing is triggered by a different event), but might check-point less often than this interval, if performing a check-point takes longer time than the configured interval. A check-point is a point in the transaction logs, which recovery would start from. Longer check-point intervals typically mean that recovery will take longer to complete in case of a crash. On the other hand, a longer check-point interval can also reduce the I/O load that the database places on the system, as each check-point implies a flushing and forcing of all the store files.
|Valid values
a|db.checkpoint.interval.time, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++15m+++
|===

[[config_db.checkpoint.interval.tx]]
.db.checkpoint.interval.tx
[cols="<1s,<4"]
|===
|Description
a|Configures the transaction interval between check-points. The database will not check-point more often  than this (unless check pointing is triggered by a different event), but might check-point less often than this interval, if performing a check-point takes longer time than the configured interval. A check-point is a point in the transaction logs, which recovery would start from. Longer check-point intervals typically mean that recovery will take longer to complete in case of a crash. On the other hand, a longer check-point interval can also reduce the I/O load that the database places on the system, as each check-point implies a flushing and forcing of all the store files.  The default is '100000' for a check-point every 100000 transactions.
|Valid values
a|db.checkpoint.interval.tx, an integer which is minimum `1`
|Default value
m|+++100000+++
|===

[[config_db.checkpoint.interval.volume]]
.db.checkpoint.interval.volume
[cols="<1s,<4"]
|===
|Description
a|Configures the volume of transaction logs between check-points. The database will not check-point more often than this (unless check pointing is triggered by a different event), but might check-point less often than this interval, if performing a check-point takes longer time than the configured interval. A check-point is a point in the transaction logs, which recovery would start from. Longer check-point intervals typically mean that recovery will take longer to complete in case of a crash. On the other hand, a longer check-point interval can also reduce the I/O load that the database places on the system, as each check-point implies a flushing and forcing of all the store files.
|Valid values
a|db.checkpoint.interval.volume, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`) which is minimum `1.00KiB`
|Default value
m|+++250.00MiB+++
|===

[[config_db.checkpoint.iops.limit]]
.db.checkpoint.iops.limit
[cols="<1s,<4"]
|===
|Description
a|Limit the number of IOs the background checkpoint process will consume per second. This setting is advisory, is ignored in Neo4j Community Edition, and is followed to best effort in Enterprise Edition. An IO is in this case a 8 KiB (mostly sequential) write. Limiting the write IO in this way will leave more bandwidth in the IO subsystem to service random-read IOs, which is important for the response time of queries when the database cannot fit entirely in memory. The only drawback of this setting is that longer checkpoint times may lead to slightly longer recovery times in case of a database or system crash. A lower number means lower IO pressure, and consequently longer checkpoint times. Set this to -1 to disable the IOPS limit and remove the limitation entirely; this will let the checkpointer flush data as fast as the hardware will go. Removing the setting, or commenting it out, will set the default value of 600.
|Valid values
a|db.checkpoint.iops.limit, an integer
|Dynamic a|true
|Default value
m|+++600+++
|===

[[config_db.cluster.catchup.pull_interval]]
.db.cluster.catchup.pull_interval
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Interval of pulling updates from cores.
|Valid values
a|db.cluster.catchup.pull_interval, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++1s+++
|===

[[config_db.cluster.raft.apply.buffer.max_bytes]]
.db.cluster.raft.apply.buffer.max_bytes
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The maximum number of bytes in the apply buffer. This parameter limits the amount of memory that can be consumed by the apply buffer. If the bytes limit is reached, buffer size will be limited even if max_entries is not exceeded.
|Valid values
a|db.cluster.raft.apply.buffer.max_bytes, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`)
|Default value
m|+++1.00GiB+++
|===

[[config_db.cluster.raft.apply.buffer.max_entries]]
.db.cluster.raft.apply.buffer.max_entries
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The maximum number of entries in the raft log entry prefetch buffer.
|Valid values
a|db.cluster.raft.apply.buffer.max_entries, an integer
|Default value
m|+++1024+++
|===

[[config_db.cluster.raft.in_queue.batch.max_bytes]]
.db.cluster.raft.in_queue.batch.max_bytes
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Largest batch processed by RAFT in bytes.
|Valid values
a|db.cluster.raft.in_queue.batch.max_bytes, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`)
|Default value
m|+++8.00MiB+++
|===

[[config_db.cluster.raft.in_queue.max_bytes]]
.db.cluster.raft.in_queue.max_bytes
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Maximum number of bytes in the RAFT in-queue.
|Valid values
a|db.cluster.raft.in_queue.max_bytes, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`)
|Default value
m|+++2.00GiB+++
|===

[[config_db.cluster.raft.leader_transfer.priority_group]]
.db.cluster.raft.leader_transfer.priority_group
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The name of a server_group whose members should be prioritized as leaders. This does not guarantee that members of this group will be leader at all times, but the cluster will attempt to transfer leadership to such a member when possible. If a database is specified using `db.cluster.raft.leader_transfer.priority_group`.<database> the specified priority group will apply to that database only. If no database is specified that group will be the default and apply to all databases which have no priority group explicitly set. Using this setting will disable leadership balancing.
|Valid values
a|db.cluster.raft.leader_transfer.priority_group, a string identifying a Server Tag
|Default value
m|++++++
|===

[[config_db.cluster.raft.log.prune_strategy]]
.db.cluster.raft.log.prune_strategy
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]RAFT log pruning strategy that determines which logs are to be pruned. Neo4j only prunes log entries up to the last applied index, which guarantees that logs are only marked for pruning once the transactions within are safely copied over to the local transaction logs and safely committed by a majority of cluster members. Possible values are a byte size or a number of transactions (e.g., 200K txs).
|Valid values
a|db.cluster.raft.log.prune_strategy, a string
|Default value
m|+++1g size+++
|===

[[config_db.cluster.raft.log_shipping.buffer.max_bytes]]
.db.cluster.raft.log_shipping.buffer.max_bytes
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The maximum number of bytes in the in-flight cache. This parameter limits the amount of memory that can be consumed by cache. If the bytes limit is reached, cache size will be limited even if max_entries is not exceeded.
|Valid values
a|db.cluster.raft.log_shipping.buffer.max_bytes, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`)
|Default value
m|+++1.00GiB+++
|===

[[config_db.cluster.raft.log_shipping.buffer.max_entries]]
.db.cluster.raft.log_shipping.buffer.max_entries
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The maximum number of entries in the in-flight cache. Increasing size will require more memory but might improve performance in high load situations.
|Valid values
a|db.cluster.raft.log_shipping.buffer.max_entries, an integer
|Default value
m|+++1024+++
|===

[[config_db.filewatcher.enabled]]
.db.filewatcher.enabled
[cols="<1s,<4"]
|===
|Description
a|Allows the enabling or disabling of the file watcher service. This is an auxiliary service but should be left enabled in almost all cases.
|Valid values
a|db.filewatcher.enabled, a boolean
|Default value
m|+++true+++
|===

[[config_db.format]]
.db.format
[cols="<1s,<4"]
|===
|Description
a|Database format. This is the format that will be used for new databases. Valid values are `standard`, `aligned`, or `high_limit`.The `aligned` format is essentially the `standard` format with some minimal padding at the end of pages such that a single record will never cross a page boundary. The `high_limit` format is available for Enterprise Edition only. It is required if you have a graph that is larger than 34 billion nodes, 34 billion relationships, or 68 billion properties.
|Valid values
a|db.format, a string
|Dynamic a|true
|Default value
m|+++aligned+++
|===

[[config_db.import.csv.buffer_size]]
.db.import.csv.buffer_size
[cols="<1s,<4"]
|===
|Description
a|The size of the internal buffer in bytes used by `LOAD CSV`. If the csv file contains huge fields this value may have to be increased.
|Valid values
a|db.import.csv.buffer_size, a long which is minimum `1`
|Default value
m|+++2097152+++
|===

[[config_db.import.csv.legacy_quote_escaping]]
.db.import.csv.legacy_quote_escaping
[cols="<1s,<4"]
|===
|Description
a|Selects whether to conform to the standard https://tools.ietf.org/html/rfc4180 for interpreting escaped quotation characters in CSV files loaded using `LOAD CSV`. Setting this to `false` will use the standard, interpreting repeated quotes '""' as a single in-lined quote, while `true` will use the legacy convention originally supported in Neo4j 3.0 and 3.1, allowing a backslash to include quotes in-lined in fields.
|Valid values
a|db.import.csv.legacy_quote_escaping, a boolean
|Default value
m|+++true+++
|===

[[config_db.index.fulltext.default_analyzer]]
.db.index.fulltext.default_analyzer
[cols="<1s,<4"]
|===
|Description
a|The name of the analyzer that the fulltext indexes should use by default.
|Valid values
a|db.index.fulltext.default_analyzer, a string
|Default value
m|+++standard-no-stop-words+++
|===

[[config_db.index.fulltext.eventually_consistent]]
.db.index.fulltext.eventually_consistent
[cols="<1s,<4"]
|===
|Description
a|Whether or not fulltext indexes should be eventually consistent by default or not.
|Valid values
a|db.index.fulltext.eventually_consistent, a boolean
|Default value
m|+++false+++
|===

[[config_db.index.fulltext.eventually_consistent_index_update_queue_max_length]]
.db.index.fulltext.eventually_consistent_index_update_queue_max_length
[cols="<1s,<4"]
|===
|Description
a|The eventually_consistent mode of the fulltext indexes works by queueing up index updates to be applied later in a background thread. This newBuilder sets an upper bound on how many index updates are allowed to be in this queue at any one point in time. When it is reached, the commit process will slow down and wait for the index update applier thread to make some more room in the queue.
|Valid values
a|db.index.fulltext.eventually_consistent_index_update_queue_max_length, an integer which is in the range `1` to `50000000`
|Default value
m|+++10000+++
|===

[[config_db.index_sampling.background_enabled]]
.db.index_sampling.background_enabled
[cols="<1s,<4"]
|===
|Description
a|Enable or disable background index sampling.
|Valid values
a|db.index_sampling.background_enabled, a boolean
|Default value
m|+++true+++
|===

[[config_db.index_sampling.sample_size_limit]]
.db.index_sampling.sample_size_limit
[cols="<1s,<4"]
|===
|Description
a|Index sampling chunk size limit.
|Valid values
a|db.index_sampling.sample_size_limit, an integer which is in the range `1048576` to `2147483647`
|Default value
m|+++8388608+++
|===

[[config_db.index_sampling.update_percentage]]
.db.index_sampling.update_percentage
[cols="<1s,<4"]
|===
|Description
a|Percentage of index updates of total index size required before sampling of a given index is triggered.
|Valid values
a|db.index_sampling.update_percentage, an integer which is minimum `0`
|Default value
m|+++5+++
|===

[[config_db.lock.acquisition.timeout]]
.db.lock.acquisition.timeout
[cols="<1s,<4"]
|===
|Description
a|The maximum time interval within which lock should be acquired. Zero (default) means timeout is disabled.
|Valid values
a|db.lock.acquisition.timeout, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Dynamic a|true
|Default value
m|+++0s+++
|===

[[config_db.logs.query.early_raw_logging_enabled]]
.db.logs.query.early_raw_logging_enabled
[cols="<1s,<4"]
|===
|Description
a|Log query text and parameters without obfuscating passwords. This allows queries to be logged earlier before parsing starts.
|Valid values
a|db.logs.query.early_raw_logging_enabled, a boolean
|Dynamic a|true
|Default value
m|+++false+++
|===

[[config_db.logs.query.enabled]]
.db.logs.query.enabled
[cols="<1s,<4"]
|===
|Description
a|Log executed queries. Valid values are `OFF`, `INFO`, or `VERBOSE`.

`OFF`::  no logging.
`INFO`:: log queries at the end of execution, that take longer than the configured threshold, `<<config_db.logs.query.threshold,db.logs.query.threshold>>`.
`VERBOSE`:: log queries at the start and end of execution, regardless of `<<config_db.logs.query.threshold,db.logs.query.threshold>>`.

Log entries are written to the query log.

This feature is available in the Neo4j Enterprise Edition.
|Valid values
a|db.logs.query.enabled, one of [OFF, INFO, VERBOSE]
|Dynamic a|true
|Default value
m|+++VERBOSE+++
|===

[[config_db.logs.query.max_parameter_length]]
.db.logs.query.max_parameter_length
[cols="<1s,<4"]
|===
|Description
a|Sets a maximum character length use for each parameter in the log. This only takes effect if `<<config_db.logs.query.parameter_logging_enabled,db.logs.query.parameter_logging_enabled>> = true`.
|Valid values
a|db.logs.query.max_parameter_length, an integer
|Dynamic a|true
|Default value
m|+++2147483647+++
|===

[[config_db.logs.query.obfuscate_literals]]
.db.logs.query.obfuscate_literals
[cols="<1s,<4"]
|===
|Description
a|Obfuscates all literals of the query before writing to the log. Note that node labels, relationship types and map property keys are still shown. Changing the setting will not affect queries that are cached. So, if you want the switch to have immediate effect, you must also call `CALL db.clearQueryCaches()`.
|Valid values
a|db.logs.query.obfuscate_literals, a boolean
|Dynamic a|true
|Default value
m|+++false+++
|===

[[config_db.logs.query.parameter_logging_enabled]]
.db.logs.query.parameter_logging_enabled
[cols="<1s,<4"]
|===
|Description
a|Log parameters for the executed queries being logged.
|Valid values
a|db.logs.query.parameter_logging_enabled, a boolean
|Dynamic a|true
|Default value
m|+++true+++
|===

[[config_db.logs.query.plan_description_enabled]]
.db.logs.query.plan_description_enabled
[cols="<1s,<4"]
|===
|Description
a|Log query plan description table, useful for debugging purposes.
|Valid values
a|db.logs.query.plan_description_enabled, a boolean
|Dynamic a|true
|Default value
m|false
|===

[[config_db.logs.query.threshold]]
.db.logs.query.threshold
[cols="<1s,<4"]
|===
|Description
a|If the execution of query takes more time than this threshold, the query is logged once completed - provided query logging is set to INFO. Defaults to 0 seconds, that is all queries are logged.
|Valid values
a|db.logs.query.threshold, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Dynamic a|true
|Default value
m|+++0s+++
|===

[[config_db.logs.query.transaction.enabled]]
.db.logs.query.transaction.enabled
[cols="<1s,<4"]
|===
|Description
a|Log the start and end of a transaction. Valid values are 'OFF', 'INFO', or 'VERBOSE'.
OFF:  no logging.
INFO: log start and end of transactions that take longer than the configured threshold, <<config_db.logs.query.transaction.threshold,db.logs.query.transaction.threshold>>.
VERBOSE: log start and end of all transactions.
Log entries are written to the query log.
This feature is available in the Neo4j Enterprise Edition.
|Valid values
a|db.logs.query.transaction.enabled, one of [OFF, INFO, VERBOSE]
|Dynamic a|true
|Default value
m|+++OFF+++
|===

[[config_db.logs.query.transaction.threshold]]
.db.logs.query.transaction.threshold
[cols="<1s,<4"]
|===
|Description
a|If the transaction is open for more time than this threshold, the transaction is logged once completed - provided transaction logging (<<config_db.logs.query.transaction.enabled,db.logs.query.transaction.enabled>>) is set to `INFO`. Defaults to 0 seconds (all transactions are logged).
|Valid values
a|db.logs.query.transaction.threshold, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Dynamic a|true
|Default value
m|+++0s+++
|===

[[config_db.memory.pagecache.warmup.enable]]
.db.memory.pagecache.warmup.enable
[cols="<1s,<4"]
|===
|Description
a|Page cache can be configured to perform usage sampling of loaded pages that can be used to construct active load profile. According to that profile pages can be reloaded on the restart, replication, etc. This setting allows disabling that behavior.
This feature is available in Neo4j Enterprise Edition.
|Valid values
a|db.memory.pagecache.warmup.enable, a boolean
|Default value
m|+++true+++
|===

[[config_db.memory.pagecache.warmup.preload]]
.db.memory.pagecache.warmup.preload
[cols="<1s,<4"]
|===
|Description
a|Page cache warmup can be configured to prefetch files, preferably when cache size is bigger than store size. Files to be prefetched can be filtered by 'dbms.memory.pagecache.warmup.preload.allowlist'. Enabling this disables warmup by profile.
|Valid values
a|db.memory.pagecache.warmup.preload, a boolean
|Default value
m|+++false+++
|===

[[config_db.memory.pagecache.warmup.preload.allowlist]]
.db.memory.pagecache.warmup.preload.allowlist
[cols="<1s,<4"]
|===
|Description
a|Page cache warmup prefetch file allowlist regex. By default matches all files.
|Valid values
a|db.memory.pagecache.warmup.preload.allowlist, a string
|Default value
m|+++.*+++
|===

[[config_db.memory.pagecache.warmup.profile.interval]]
.db.memory.pagecache.warmup.profile.interval
[cols="<1s,<4"]
|===
|Description
a|The profiling frequency for the page cache. Accurate profiles allow the page cache to do active warmup after a restart, reducing the mean time to performance.
This feature is available in Neo4j Enterprise Edition.
|Valid values
a|db.memory.pagecache.warmup.profile.interval, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++1m+++
|===

[[config_db.memory.transaction.max]]
.db.memory.transaction.max
[cols="<1s,<4"]
|===
|Description
a|Limit the amount of memory that a single transaction can consume, in bytes (or kilobytes with the 'k' suffix, megabytes with 'm' and gigabytes with 'g'). Zero means 'largest possible value'.
|Valid values
a|db.memory.transaction.max, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`) which is minimum `1.00MiB` or is `0B`
|Dynamic a|true
|Default value
m|+++0B+++
|===

[[config_db.memory.transaction.total.max]]
.db.memory.transaction.total.max
[cols="<1s,<4"]
|===
|Description
a|Limit the amount of memory that all transactions in one database can consume, in bytes (or kilobytes with the 'k' suffix, megabytes with 'm' and gigabytes with 'g'). Zero means 'unlimited'.
|Valid values
a|db.memory.transaction.total.max, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`) which is minimum `10.00MiB` or is `0B`
|Dynamic a|true
|Default value
m|+++0B+++
|===

[[config_db.recovery.fail_on_missing_files]]
.db.recovery.fail_on_missing_files
[cols="<1s,<4"]
|===
|Description
a|If `true`, Neo4j will abort recovery if transaction log files are missing. Setting this to `false` will allow Neo4j to create new empty missing files for the already existing  database, but the integrity of the database might be compromised.
|Valid values
a|db.recovery.fail_on_missing_files, a boolean
|Default value
m|+++true+++
|===

[[config_db.relationship_grouping_threshold]]
.db.relationship_grouping_threshold
[cols="<1s,<4"]
|===
|Description
a|Relationship count threshold for considering a node to be dense.
|Valid values
a|db.relationship_grouping_threshold, an integer which is minimum `1`
|Default value
m|+++50+++
|===

[[config_db.shutdown_transaction_end_timeout]]
.db.shutdown_transaction_end_timeout
[cols="<1s,<4"]
|===
|Description
a|The maximum amount of time to wait for running transactions to complete before allowing initiated database shutdown to continue.
|Valid values
a|db.shutdown_transaction_end_timeout, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10s+++
|===

[[config_db.store.files.preallocate]]
.db.store.files.preallocate
[cols="<1s,<4"]
|===
|Description
a|Specify if Neo4j should try to preallocate store files as they grow.
|Valid values
a|db.store.files.preallocate, a boolean
|Default value
m|+++true+++
|===

[[config_db.temporal.timezone]]
.db.temporal.timezone
[cols="<1s,<4"]
|===
|Description
a|Database timezone for temporal functions. All Time and DateTime values that are created without an explicit timezone will use this configured default timezone.
|Valid values
a|db.temporal.timezone, a string describing a timezone, either described by offset (e.g. `+02:00`) or by name (e.g. `Europe/Stockholm`)
|Default value
m|+++Z+++
|===

[[config_db.track_query_cpu_time]]
.db.track_query_cpu_time
[cols="<1s,<4"]
|===
|Description
a|Enables or disables tracking of how much time a query spends actively executing on the CPU. Calling `SHOW TRANSACTIONS` will display the time, but not in the _query.log_. +
If you want the CPU time to be logged in the _query.log_, set `db.track_query_cpu_time=true` and `db.logs.query.time_logging_enabled=true` label:Enterprise[].
|Valid values
a|db.track_query_cpu_time, a boolean
|Dynamic a|true
|Default value
m|+++false+++
|===

[[config_db.transaction.bookmark_ready_timeout]]
.db.transaction.bookmark_ready_timeout
[cols="<1s,<4"]
|===
|Description
a|The maximum amount of time to wait for the database state represented by the bookmark.
|Valid values
a|db.transaction.bookmark_ready_timeout, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`) which is minimum `1s`
|Dynamic a|true
|Default value
m|+++30s+++
|===

[[config_db.transaction.concurrent.maximum]]
.db.transaction.concurrent.maximum
[cols="<1s,<4"]
|===
|Description
a|The maximum number of concurrently running transactions. If set to 0, limit is disabled.
|Valid values
a|db.transaction.concurrent.maximum, an integer
|Dynamic a|true
|Default value
m|+++1000+++
|===

[[config_db.transaction.monitor.check.interval]]
.db.transaction.monitor.check.interval
[cols="<1s,<4"]
|===
|Description
a|Configures the time interval between transaction monitor checks. Determines how often monitor thread will check transaction for timeout.
|Valid values
a|db.transaction.monitor.check.interval, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++2s+++
|===

[[config_db.transaction.sampling.percentage]]
.db.transaction.sampling.percentage
[cols="<1s,<4"]
|===
|Description
a|Transaction sampling percentage.
|Valid values
a|db.transaction.sampling.percentage, an integer which is in the range `1` to `100`
|Dynamic a|true
|Default value
m|+++5+++
|===

[[config_db.transaction.timeout]]
.db.transaction.timeout
[cols="<1s,<4"]
|===
|Description
a|The maximum time interval of a transaction within which it should be completed.
|Valid values
a|db.transaction.timeout, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Dynamic a|true
|Default value
m|+++0s+++
|===

[[config_db.transaction.tracing.level]]
.db.transaction.tracing.level
[cols="<1s,<4"]
|===
|Description
a|Transaction creation tracing level.
|Valid values
a|db.transaction.tracing.level, one of [DISABLED, SAMPLE, ALL]
|Dynamic a|true
|Default value
m|+++DISABLED+++
|===

[[config_db.tx_log.buffer.size]]
.db.tx_log.buffer.size
[cols="<1s,<4"]
|===
|Description
a|On serialization of transaction logs, they will be temporary stored in the byte buffer that will be flushed at the end of the transaction or at any moment when buffer will be full.
|Valid values
a|db.tx_log.buffer.size, a long which is minimum `131072`
|Default value
m|By default the size of byte buffer is based on number of available cpu's with minimal buffer size of 512KB. Every another 4 cpu's will add another 512KB into the buffer size. Maximal buffer size in this default scheme is 4MB taking into account that we can have one transaction log writer per database in multi-database env.For example, runtime with 4 cpus will have buffer size of 1MB; runtime with 8 cpus will have buffer size of 1MB 512KB; runtime with 12 cpus will have buffer size of 2MB.
|===

[[config_db.tx_log.preallocate]]
.db.tx_log.preallocate
[cols="<1s,<4"]
|===
|Description
a|Specify if Neo4j should try to preallocate the logical log file in advance. 
It optimizes filesystem by ensuring there is room to accommodate newly generated files and avoid file-level fragmentation.
|Valid values
a|db.tx_log.preallocate, a boolean
|Dynamic a|true
|Default value
m|+++true+++
|===

[[config_db.tx_log.rotation.retention_policy]]
.db.tx_log.rotation.retention_policy
[cols="<1s,<4"]
|===
|Description
a|Tell Neo4j how long logical transaction logs should be kept to backup the database.For example, "10 days" will prune logical logs that only contain transactions older than 10 days.Alternatively, "100k txs" will keep the 100k latest transactions from each database and prune any older transactions.
|Valid values
a|db.tx_log.rotation.retention_policy, a string which matches the pattern `^(true{vbar}keep_all{vbar}false{vbar}keep_none{vbar}(\d+[KkMmGg]?( (files{vbar}size{vbar}txs{vbar}entries{vbar}hours{vbar}days))))$` (Must be `true` or `keep_all`, `false` or `keep_none`, or of format `<number><optional unit> <type>`. Valid units are `K`, `M` and `G`. Valid types are `files`, `size`, `txs`, `entries`, `hours` and `days`. For example, `100M size` will limit logical log space on disk to 100MB per database,and `200K txs` will limit the number of transactions kept to 200 000 per database.)
|Dynamic a|true
|Default value
m|+++2 days+++
|===

[[config_db.tx_log.rotation.size]]
.db.tx_log.rotation.size
[cols="<1s,<4"]
|===
|Description
a|Specifies at which file size the logical log will auto-rotate. Minimum accepted value is 128 KiB.
|Valid values
a|db.tx_log.rotation.size, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`) which is minimum `128.00KiB`
|Dynamic a|true
|Default value
m|+++256.00MiB+++
|===

[[config_db.tx_state.memory_allocation]]
.db.tx_state.memory_allocation
[cols="<1s,<4"]
|===
|Description
a|Defines whether memory for transaction state should be allocated on- or off-heap. Note that for small transactions you can gain up to 25% write speed by setting it to `ON_HEAP`.
|Valid values
a|db.tx_state.memory_allocation, one of [ON_HEAP, OFF_HEAP]
|Default value
m|+++ON_HEAP+++
|===

[[config_dbms.cluster.catchup.client_inactivity_timeout]]
.dbms.cluster.catchup.client_inactivity_timeout
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The catch up protocol times out if the given duration elapses with no network activity. Every message received by the client from the server extends the time out duration.
|Valid values
a|dbms.cluster.catchup.client_inactivity_timeout, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10m+++
|===

[[config_dbms.cluster.discovery.endpoints]]
.dbms.cluster.discovery.endpoints
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]A comma-separated list of endpoints which a server should contact in order to discover other cluster members.
|Valid values
a|dbms.cluster.discovery.endpoints, a ',' separated list with elements of type 'a socket address in the format 'hostname:port', 'hostname' or ':port''.
|===

[[config_dbms.cluster.discovery.log_level]]
.dbms.cluster.discovery.log_level
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The level of middleware logging.
|Valid values
a|dbms.cluster.discovery.log_level, one of [DEBUG, INFO, WARN, ERROR, NONE]
|Default value
m|+++WARN+++
|===

[[config_dbms.cluster.discovery.type]]
.dbms.cluster.discovery.type
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Configure the discovery type used for cluster name resolution.
|Valid values
a|dbms.cluster.discovery.type, one of [DNS, LIST, SRV, K8S] which may require different settings depending on the discovery type: `DNS requires [dbms.cluster.discovery.endpoints], LIST requires [], SRV requires [dbms.cluster.discovery.endpoints], K8S requires [dbms.kubernetes.label_selector, dbms.kubernetes.service_port_name]`
|Default value
m|+++LIST+++
|===

[[config_dbms.cluster.minimum_initial_system_primaries_count]]
.dbms.cluster.minimum_initial_system_primaries_count
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Minimum number of machines initially required to form a clustered DBMS. The cluster is considered formed when at least this many members have discovered each other, bound together and bootstrapped a highly available system database. As a result, at least this many of the cluster's initial machines must have '<<config_server.cluster.system_database_mode,server.cluster.system_database_mode>>' set to 'PRIMARY'.NOTE: If '<<config_dbms.cluster.discovery.type,dbms.cluster.discovery.type>>' is set to 'LIST' and '<<config_dbms.cluster.discovery.endpoints,dbms.cluster.discovery.endpoints>>' is empty then the user is assumed to be deploying a standalone DBMS, and the value of this setting is ignored.
|Valid values
a|dbms.cluster.minimum_initial_system_primaries_count, an integer which is minimum `1`
|Default value
m|+++3+++
|===

[[config_dbms.cluster.network.handshake_timeout]]
.dbms.cluster.network.handshake_timeout
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Time out for protocol negotiation handshake.
|Valid values
a|dbms.cluster.network.handshake_timeout, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++20s+++
|===

[[config_dbms.cluster.network.max_chunk_size]]
.dbms.cluster.network.max_chunk_size
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Maximum chunk size allowable across network by clustering machinery.
|Valid values
a|dbms.cluster.network.max_chunk_size, an integer which is in the range `4096` to `10485760`
|Default value
m|+++32768+++
|===

[[config_dbms.cluster.network.supported_compression_algos]]
.dbms.cluster.network.supported_compression_algos
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Network compression algorithms that this instance will allow in negotiation as a comma-separated list. Listed in descending order of preference for incoming connections. An empty list implies no compression. For outgoing connections this merely specifies the allowed set of algorithms and the preference of the remote peer will be used for making the decision. Allowable values: [Gzip, Snappy, Snappy_validating, LZ4, LZ4_high_compression, LZ_validating, LZ4_high_compression_validating]
|Valid values
a|dbms.cluster.network.supported_compression_algos, a ',' separated list with elements of type 'a string'.
|Default value
m|++++++
|===

[[config_dbms.cluster.raft.binding_timeout]]
.dbms.cluster.raft.binding_timeout
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The time allowed for a database on a Neo4j server to either join a cluster or form a new cluster with the other Neo4j Servers provided by `<<config_dbms.cluster.discovery.endpoints,dbms.cluster.discovery.endpoints>>`.
|Valid values
a|dbms.cluster.raft.binding_timeout, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10m+++
|===

[[config_dbms.cluster.raft.client.max_channels]]
.dbms.cluster.raft.client.max_channels
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The maximum number of TCP channels between two nodes to operate the raft protocol. Each database gets allocated one channel, but a single channel can be used by more than one database.
|Valid values
a|dbms.cluster.raft.client.max_channels, an integer
|Default value
m|+++8+++
|===

[[config_dbms.cluster.raft.election_failure_detection_window]]
.dbms.cluster.raft.election_failure_detection_window
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The rate at which leader elections happen. Note that due to election conflicts it might take several attempts to find a leader. The window should be significantly larger than typical communication delays to make conflicts unlikely.
|Valid values
a|dbms.cluster.raft.election_failure_detection_window, a duration-range <min-max> (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++3s-6s+++
|===

[[config_dbms.cluster.raft.leader_failure_detection_window]]
.dbms.cluster.raft.leader_failure_detection_window
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The time window within which the loss of the leader is detected and the first re-election attempt is held. The window should be significantly larger than typical communication delays to make conflicts unlikely.
|Valid values
a|dbms.cluster.raft.leader_failure_detection_window, a duration-range <min-max> (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++20s-23s+++
|===

[[config_dbms.cluster.raft.leader_transfer.balancing_strategy]]
.dbms.cluster.raft.leader_transfer.balancing_strategy
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Which strategy to use when transferring database leaderships around a cluster. This can be one of `equal_balancing` or `no_balancing`. `equal_balancing` automatically ensures that each Core server holds the leader role for an equal number of databases.`no_balancing` prevents any automatic balancing of the leader role. Note that if a `leadership_priority_group` is specified for a given database, the value of this setting will be ignored for that database.
|Valid values
a|dbms.cluster.raft.leader_transfer.balancing_strategy, one of [NO_BALANCING, EQUAL_BALANCING]
|Default value
m|+++EQUAL_BALANCING+++
|===

[[config_dbms.cluster.raft.log.pruning_frequency]]
.dbms.cluster.raft.log.pruning_frequency
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]RAFT log pruning frequency.
|Valid values
a|dbms.cluster.raft.log.pruning_frequency, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10m+++
|===

[[config_dbms.cluster.raft.log.reader_pool_size]]
.dbms.cluster.raft.log.reader_pool_size
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]RAFT log reader pool size.
|Valid values
a|dbms.cluster.raft.log.reader_pool_size, an integer
|Default value
m|+++8+++
|===

[[config_dbms.cluster.raft.log.rotation_size]]
.dbms.cluster.raft.log.rotation_size
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]RAFT log rotation size.
|Valid values
a|dbms.cluster.raft.log.rotation_size, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`) which is minimum `1.00KiB`
|Default value
m|+++250.00MiB+++
|===

[[config_dbms.cluster.raft.membership.join_max_lag]]
.dbms.cluster.raft.membership.join_max_lag
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Maximum amount of lag accepted for a new follower to join the Raft group.
|Valid values
a|dbms.cluster.raft.membership.join_max_lag, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10s+++
|===

[[config_dbms.cluster.raft.membership.join_timeout]]
.dbms.cluster.raft.membership.join_timeout
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Time out for a new member to catch up.
|Valid values
a|dbms.cluster.raft.membership.join_timeout, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10m+++
|===

[[config_dbms.cluster.store_copy.max_retry_time_per_request]]
.dbms.cluster.store_copy.max_retry_time_per_request
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Maximum retry time per request during store copy. Regular store files and indexes are downloaded in separate requests during store copy. This configures the maximum time failed requests are allowed to resend.
|Valid values
a|dbms.cluster.store_copy.max_retry_time_per_request, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++20m+++
|===

[[config_dbms.cypher.forbid_exhaustive_shortestpath]]
.dbms.cypher.forbid_exhaustive_shortestpath
[cols="<1s,<4"]
|===
|Description
a|This setting is associated with performance optimization. Set this to `true` in situations where it is preferable to have any queries using the 'shortestPath' function terminate as soon as possible with no answer, rather than potentially running for a long time attempting to find an answer (even if there is no path to be found). For most queries, the 'shortestPath' algorithm will return the correct answer very quickly. However there are some cases where it is possible that the fast bidirectional breadth-first search algorithm will find no results even if they exist. This can happen when the predicates in the `WHERE` clause applied to 'shortestPath' cannot be applied to each step of the traversal, and can only be applied to the entire path. When the query planner detects these special cases, it will plan to perform an exhaustive depth-first search if the fast algorithm finds no paths. However, the exhaustive search may be orders of magnitude slower than the fast algorithm. If it is critical that queries terminate as soon as possible, it is recommended that this option be set to `true`, which means that Neo4j will never consider using the exhaustive search for shortestPath queries. However, please note that if no paths are found, an error will be thrown at run time, which will need to be handled by the application.
|Valid values
a|dbms.cypher.forbid_exhaustive_shortestpath, a boolean
|Default value
m|+++false+++
|===

[[config_dbms.cypher.forbid_shortestpath_common_nodes]]
.dbms.cypher.forbid_shortestpath_common_nodes
[cols="<1s,<4"]
|===
|Description
a|This setting is associated with performance optimization. The shortest path algorithm does not work when the start and end nodes are the same. With this setting set to `false` no path will be returned when that happens. The default value of `true` will instead throw an exception. This can happen if you perform a shortestPath search after a cartesian product that might have the same start and end nodes for some of the rows passed to shortestPath. If it is preferable to not experience this exception, and acceptable for results to be missing for those rows, then set this to `false`. If you cannot accept missing results, and really want the shortestPath between two common nodes, then re-write the query using a standard Cypher variable length pattern expression followed by ordering by path length and limiting to one result.
|Valid values
a|dbms.cypher.forbid_shortestpath_common_nodes, a boolean
|Default value
m|+++true+++
|===

[[config_dbms.cypher.hints_error]]
.dbms.cypher.hints_error
[cols="<1s,<4"]
|===
|Description
a|Set this to specify the behavior when Cypher planner or runtime hints cannot be fulfilled. If true, then non-conformance will result in an error, otherwise only a warning is generated.
|Valid values
a|dbms.cypher.hints_error, a boolean
|Default value
m|+++false+++
|===

[[config_dbms.cypher.lenient_create_relationship]]
.dbms.cypher.lenient_create_relationship
[cols="<1s,<4"]
|===
|Description
a|Set this to change the behavior for Cypher create relationship when the start or end node is missing. By default this fails the query and stops execution, but by setting this flag the create operation is simply not performed and execution continues.
|Valid values
a|dbms.cypher.lenient_create_relationship, a boolean
|Default value
m|+++false+++
|===

[[config_dbms.cypher.min_replan_interval]]
.dbms.cypher.min_replan_interval
[cols="<1s,<4"]
|===
|Description
a|The minimum time between possible cypher query replanning events. After this time, the graph statistics will be evaluated, and if they have changed by more than the value set by <<config_dbms.cypher.statistics_divergence_threshold,dbms.cypher.statistics_divergence_threshold>>, the query will be replanned. If the statistics have not changed sufficiently, the same interval will need to pass before the statistics will be evaluated again. Each time they are evaluated, the divergence threshold will be reduced slightly until it reaches 10% after 7h, so that even moderately changing databases will see query replanning after a sufficiently long time interval.
|Valid values
a|dbms.cypher.min_replan_interval, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10s+++
|===

[[config_dbms.cypher.planner]]
.dbms.cypher.planner
[cols="<1s,<4"]
|===
|Description
a|Set this to specify the default planner for the default language version.
|Valid values
a|dbms.cypher.planner, one of [DEFAULT, COST]
|Default value
m|+++DEFAULT+++
|===

[[config_dbms.cypher.render_plan_description]]
.dbms.cypher.render_plan_description
[cols="<1s,<4"]
|===
|Description
a|If set to `true` a textual representation of the plan description will be rendered on the server for all queries running with `EXPLAIN` or `PROFILE`. This allows clients such as the neo4j browser and Cypher shell to show a more detailed plan description.
|Valid values
a|dbms.cypher.render_plan_description, a boolean
|Dynamic a|true
|Default value
m|+++false+++
|===

[[config_dbms.cypher.statistics_divergence_threshold]]
.dbms.cypher.statistics_divergence_threshold
[cols="<1s,<4"]
|===
|Description
a|The threshold for statistics above which a plan is considered stale.

If any of the underlying statistics used to create the plan have changed more than this value, the plan will be considered stale and will be replanned. Change is calculated as `abs(a-b)/max(a,b)`.

This means that a value of `0.75` requires the database to quadruple in size before query replanning. A value of `0` means that the query will be replanned as soon as there is any change in statistics and the replan interval has elapsed.

This interval is defined by `<<config_dbms.cypher.min_replan_interval,dbms.cypher.min_replan_interval>>` and defaults to 10s. After this interval, the divergence threshold will slowly start to decline, reaching 10% after about 7h. This will ensure that long running databases will still get query replanning on even modest changes, while not replanning frequently unless the changes are very large.
|Valid values
a|dbms.cypher.statistics_divergence_threshold, a double which is in the range `0.0` to `1.0`
|Default value
m|+++0.75+++
|===

[[config_dbms.databases.seed_from_uri_providers]]
.dbms.databases.seed_from_uri_providers
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Databases may be created from an existing 'seed' (a database backup or dump) stored at some source URI. Different types of seed source are supported by different implementations of `com.neo4j.dbms.seeding.SeedProvider`. For example, seeds stored at 's3://' and 'https://' URIs are supported by the builtin `S3SeedProvider` and `URLConnectionSeedProvider` respectively. This list specifies enabled seed providers. If a seed source (URI scheme) is supported by multiple providers in the list, the first matching provider will be used. If the list is set to empty, the seed from uri functionality is effectively disabled.
|Valid values
a|dbms.databases.seed_from_uri_providers, a ',' separated list with elements of type 'a string'.
|Default value
m|+++S3SeedProvider+++
|===

[[config_dbms.db.timezone]]
.dbms.db.timezone
[cols="<1s,<4"]
|===
|Description
a|Database timezone. Among other things, this setting influences the monitoring procedures.
|Valid values
a|dbms.db.timezone, one of [UTC, SYSTEM]
|Default value
m|+++UTC+++
|===

[[config_dbms.kubernetes.address]]
.dbms.kubernetes.address
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Address for Kubernetes API.
|Valid values
a|dbms.kubernetes.address, a socket address in the format 'hostname:port', 'hostname' or ':port'
|Default value
m|+++kubernetes.default.svc:443+++
|===

[[config_dbms.kubernetes.ca_crt]]
.dbms.kubernetes.ca_crt
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]File location of CA certificate for Kubernetes API.
|Valid values
a|dbms.kubernetes.ca_crt, a path
|Default value
m|+++/var/run/secrets/kubernetes.io/serviceaccount/ca.crt+++
|===

[[config_dbms.kubernetes.cluster_domain]]
.dbms.kubernetes.cluster_domain
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Kubernetes cluster domain.
|Valid values
a|dbms.kubernetes.cluster_domain, a string
|Default value
m|+++cluster.local+++
|===

[[config_dbms.kubernetes.label_selector]]
.dbms.kubernetes.label_selector
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]LabelSelector for Kubernetes API.
|Valid values
a|dbms.kubernetes.label_selector, a string
|===

[[config_dbms.kubernetes.namespace]]
.dbms.kubernetes.namespace
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]File location of namespace for Kubernetes API.
|Valid values
a|dbms.kubernetes.namespace, a path
|Default value
m|+++/var/run/secrets/kubernetes.io/serviceaccount/namespace+++
|===

[[config_dbms.kubernetes.service_port_name]]
.dbms.kubernetes.service_port_name
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Service port name for discovery for Kubernetes API.
|Valid values
a|dbms.kubernetes.service_port_name, a string
|===

[[config_dbms.kubernetes.token]]
.dbms.kubernetes.token
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]File location of token for Kubernetes API.
|Valid values
a|dbms.kubernetes.token, a path
|Default value
m|+++/var/run/secrets/kubernetes.io/serviceaccount/token+++
|===

[[config_dbms.logs.http.enabled]]
.dbms.logs.http.enabled
[cols="<1s,<4"]
|===
|Description
a|Enable HTTP request logging.
|Valid values
a|dbms.logs.http.enabled, a boolean
|Default value
m|+++false+++
|===

[[config_dbms.max_databases]]
.dbms.max_databases
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The maximum number of databases.
|Valid values
a|dbms.max_databases, a long which is minimum `2`
|Default value
m|+++100+++
|===

[[config_dbms.memory.tracking.enable]]
.dbms.memory.tracking.enable
[cols="<1s,<4"]
|===
|Description
a|Enable off heap and on heap memory tracking. Should not be set to `false` for clusters.
|Valid values
a|dbms.memory.tracking.enable, a boolean
|Default value
m|+++true+++
|===

[[config_dbms.memory.transaction.total.max]]
.dbms.memory.transaction.total.max
[cols="<1s,<4"]
|===
|Description
a|Limit the amount of memory that all of the running transactions can consume, in bytes (or kilobytes with the 'k' suffix, megabytes with 'm' and gigabytes with 'g'). Zero means 'unlimited'.
|Valid values
a|dbms.memory.transaction.total.max, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`) which is minimum `10.00MiB` or is `0B`
|Dynamic a|true
|Default value
m|+++0B+++
|===

[[config_dbms.netty.ssl.provider]]
.dbms.netty.ssl.provider
[cols="<1s,<4"]
|===
|Description
a|Netty SSL provider.
|Valid values
a|dbms.netty.ssl.provider, one of [JDK, OPENSSL, OPENSSL_REFCNT]
|Default value
m|+++JDK+++
|===

[[config_dbms.routing.client_side.enforce_for_domains]]
.dbms.routing.client_side.enforce_for_domains
[cols="<1s,<4"]
|===
|Description
a|Always use client side routing (regardless of the default router) for neo4j:// protocol connections to these domains. A comma separated list of domains. Wildcards (*) are supported.
|Valid values
a|dbms.routing.client_side.enforce_for_domains, a ',' separated set with elements of type 'a string'.
|Dynamic a|true
|Default value
m|++++++
|===

[[config_dbms.routing.default_router]]
.dbms.routing.default_router
[cols="<1s,<4"]
|===
|Description
a|Routing strategy for neo4j:// protocol connections.
Default is `CLIENT`, using client-side routing, with server-side routing as a fallback (if enabled).
When set to `SERVER`, client-side routing is short-circuited, and requests will rely on server-side routing (which must be enabled for proper operation, i.e. `<<config_dbms.routing.enabled,dbms.routing.enabled>>=true`).
Can be overridden by `<<config_dbms.routing.client_side.enforce_for_domains,dbms.routing.client_side.enforce_for_domains>>`.
|Valid values
a|dbms.routing.default_router, one of [SERVER, CLIENT]
|Default value
m|+++CLIENT+++
|===

[[config_dbms.routing.driver.connection.connect_timeout]]
.dbms.routing.driver.connection.connect_timeout
[cols="<1s,<4"]
|===
|Description
a|Socket connection timeout.
A timeout of zero is treated as an infinite timeout and will be bound by the timeout configured on the
operating system level.
|Valid values
a|dbms.routing.driver.connection.connect_timeout, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++5s+++
|===

[[config_dbms.routing.driver.connection.max_lifetime]]
.dbms.routing.driver.connection.max_lifetime
[cols="<1s,<4"]
|===
|Description
a|Pooled connections older than this threshold will be closed and removed from the pool.
Setting this option to a low value will cause a high connection churn and might result in a performance hit.
It is recommended to set maximum lifetime to a slightly smaller value than the one configured in network
equipment (load balancer, proxy, firewall, etc. can also limit maximum connection lifetime).
Zero and negative values result in lifetime not being checked.
|Valid values
a|dbms.routing.driver.connection.max_lifetime, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++1h+++
|===

[[config_dbms.routing.driver.connection.pool.acquisition_timeout]]
.dbms.routing.driver.connection.pool.acquisition_timeout
[cols="<1s,<4"]
|===
|Description
a|Maximum amount of time spent attempting to acquire a connection from the connection pool.
This timeout only kicks in when all existing connections are being used and no new connections can be created because maximum connection pool size has been reached.
Error is raised when connection can't be acquired within configured time.
Negative values are allowed and result in unlimited acquisition timeout. Value of 0 is allowed and results in no timeout and immediate failure when connection is unavailable.
|Valid values
a|dbms.routing.driver.connection.pool.acquisition_timeout, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++1m+++
|===

[[config_dbms.routing.driver.connection.pool.idle_test]]
.dbms.routing.driver.connection.pool.idle_test
[cols="<1s,<4"]
|===
|Description
a|Pooled connections that have been idle in the pool for longer than this timeout will be tested before they are used again, to ensure they are still alive.
If this option is set too low, an additional network call will be incurred when acquiring a connection, which causes a performance hit.
If this is set high, no longer live connections might be used which might lead to errors.
Hence, this parameter tunes a balance between the likelihood of experiencing connection problems and performance
Normally, this parameter should not need tuning.
Value 0 means connections will always be tested for validity.
|Valid values
a|dbms.routing.driver.connection.pool.idle_test, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|No connection liveliness check is done by default.
|===

[[config_dbms.routing.driver.connection.pool.max_size]]
.dbms.routing.driver.connection.pool.max_size
[cols="<1s,<4"]
|===
|Description
a|Maximum total number of connections to be managed by a connection pool.
The limit is enforced for a combination of a host and user. Negative values are allowed and result in unlimited pool. Value of 0is not allowed.
|Valid values
a|dbms.routing.driver.connection.pool.max_size, an integer
|Default value
m|Unlimited
|===

[[config_dbms.routing.driver.logging.level]]
.dbms.routing.driver.logging.level
[cols="<1s,<4"]
|===
|Description
a|Sets level for driver internal logging.
|Valid values
a|dbms.routing.driver.logging.level, one of [DEBUG, INFO, WARN, ERROR, NONE]
|Default value
m|+++INFO+++
|===

[[config_dbms.routing.enabled]]
.dbms.routing.enabled
[cols="<1s,<4"]
|===
|Description
a|Enable server-side routing in clusters using an additional bolt connector.
When configured, this allows requests to be forwarded from one cluster member to another, if the requests can't be satisfied by the first member (e.g. write requests received by a non-leader).
|Valid values
a|dbms.routing.enabled, a boolean
|Default value
m|+++true+++
|===

[[config_dbms.routing.load_balancing.plugin]]
.dbms.routing.load_balancing.plugin
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The load balancing plugin to use.
|Valid values
a|dbms.routing.load_balancing.plugin, a string which specified load balancer plugin exist.
|Default value
m|+++server_policies+++
|===

[[config_dbms.routing.load_balancing.shuffle_enabled]]
.dbms.routing.load_balancing.shuffle_enabled
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Enables shuffling of the returned load balancing result.
|Valid values
a|dbms.routing.load_balancing.shuffle_enabled, a boolean
|Default value
m|+++true+++
|===

[[config_dbms.routing.reads_on_primaries_enabled]]
.dbms.routing.reads_on_primaries_enabled
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Configure if the `dbms.routing.getRoutingTable()` procedure should include non-writer primaries as read endpoints or return only secondaries. Note: if there are no secondaries for the given database primaries are returned as read end points regardless the value of this setting. Defaults to true so that non-writer primaries are available for read-only queries in a typical heterogeneous setup.
|Valid values
a|dbms.routing.reads_on_primaries_enabled, a boolean
|Default value
m|+++true+++
|===

[[config_dbms.routing.reads_on_writers_enabled]]
.dbms.routing.reads_on_writers_enabled
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Configure if the `dbms.routing.getRoutingTable()` procedure should include the writer as read endpoint or return only non-writers (non writer primaries and secondaries) Note: writer is returned as read endpoint if no other member is present all.
|Valid values
a|dbms.routing.reads_on_writers_enabled, a boolean
|Dynamic a|true
|Default value
m|+++false+++
|===

[[config_dbms.routing_ttl]]
.dbms.routing_ttl
[cols="<1s,<4"]
|===
|Description
a|How long callers should cache the response of the routing procedure `dbms.routing.getRoutingTable()`
|Valid values
a|dbms.routing_ttl, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`) which is minimum `1s`
|Default value
m|+++5m+++
|===

[[config_dbms.security.allow_csv_import_from_file_urls]]
.dbms.security.allow_csv_import_from_file_urls
[cols="<1s,<4"]
|===
|Description
a|Determines if Cypher will allow using file URLs when loading data using `LOAD CSV`. Setting this value to `false` will cause Neo4j to fail `LOAD CSV` clauses that load data from the file system.
|Valid values
a|dbms.security.allow_csv_import_from_file_urls, a boolean
|Default value
m|+++true+++
|===

[[config_dbms.security.auth_cache_max_capacity]]
.dbms.security.auth_cache_max_capacity
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The maximum capacity for authentication and authorization caches (respectively).
|Valid values
a|dbms.security.auth_cache_max_capacity, an integer
|Default value
m|+++10000+++
|===

[[config_dbms.security.auth_cache_ttl]]
.dbms.security.auth_cache_ttl
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The time to live (TTL) for cached authentication and authorization info when using external auth providers (LDAP or plugin). Setting the TTL to 0 will disable auth caching. Disabling caching while using the LDAP auth provider requires the use of an LDAP system account for resolving authorization information.
|Valid values
a|dbms.security.auth_cache_ttl, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10m+++
|===

[[config_dbms.security.auth_cache_use_ttl]]
.dbms.security.auth_cache_use_ttl
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Enable time-based eviction of the authentication and authorization info cache for external auth providers (LDAP or plugin). Disabling this setting will make the cache live forever and only be evicted when `<<config_dbms.security.auth_cache_max_capacity,dbms.security.auth_cache_max_capacity>>` is exceeded.
|Valid values
a|dbms.security.auth_cache_use_ttl, a boolean
|Default value
m|+++true+++
|===

[[config_dbms.security.auth_enabled]]
.dbms.security.auth_enabled
[cols="<1s,<4"]
|===
|Description
a|Enable auth requirement to access Neo4j.
|Valid values
a|dbms.security.auth_enabled, a boolean
|Default value
m|true
|===

[[config_config_dbms.security.auth_minimum_password_length]]
.dbms.security.auth_minimum_password_length
[cols="<1s,<4"]
|===
|Description
a|label:version-number[Neo4j v5.3]The minimum number of characters required in a password.
|Valid values
a|dbms.security.auth_minimum_password_length, an integer
|Default value
m|+++8+++
|===

[[config_dbms.security.auth_lock_time]]
.dbms.security.auth_lock_time
[cols="<1s,<4"]
|===
|Description
a|The amount of time user account should be locked after a configured number of unsuccessful authentication attempts. The locked out user will not be able to log in until the lock period expires, even if correct credentials are provided. Setting this configuration option to a low value is not recommended because it might make it easier for an attacker to brute force the password.
|Valid values
a|dbms.security.auth_lock_time, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`) which is minimum `0s`
|Default value
m|+++5s+++
|===

[[config_dbms.security.auth_max_failed_attempts]]
.dbms.security.auth_max_failed_attempts
[cols="<1s,<4"]
|===
|Description
a|The maximum number of unsuccessful authentication attempts before imposing a user lock for  the configured amount of time, as defined by `<<config_dbms.security.auth_lock_time,dbms.security.auth_lock_time>>`.The locked out user will not be able to log in until the lock period expires, even if correct  credentials are provided. Setting this configuration option to values less than 3 is not recommended because it might make  it easier for an attacker to brute force the password.
|Valid values
a|dbms.security.auth_max_failed_attempts, an integer which is minimum `0`
|Default value
m|+++3+++
|===

[[config_dbms.security.authentication_providers]]
.dbms.security.authentication_providers
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]A list of security authentication providers containing the users and roles. This can be any of the built-in `native` or `ldap` providers, or it can be an externally provided plugin, with a custom name prefixed by `plugin-`, i.e. `plugin-<AUTH_PROVIDER_NAME>`. They will be queried in the given order when login is attempted.
|Valid values
a|dbms.security.authentication_providers, a ',' separated list with elements of type 'a string'.
|Default value
m|+++native+++
|===

[[config_dbms.security.authorization_providers]]
.dbms.security.authorization_providers
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]A list of security authorization providers containing the users and roles. This can be any of the built-in `native` or `ldap` providers, or it can be an externally provided plugin, with a custom name prefixed by `plugin-`, i.e. `plugin-<AUTH_PROVIDER_NAME>`. They will be queried in the given order when login is attempted.
|Valid values
a|dbms.security.authorization_providers, a ',' separated list with elements of type 'a string'.
|Default value
m|+++native+++
|===

[[config_dbms.security.cluster_status_auth_enabled]]
.dbms.security.cluster_status_auth_enabled
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Require authorization for access to the Causal Clustering status endpoints.
|Valid values
a|dbms.security.cluster_status_auth_enabled, a boolean
|Default value
m|+++true+++
|===

[[config_dbms.security.http_access_control_allow_origin]]
.dbms.security.http_access_control_allow_origin
[cols="<1s,<4"]
|===
|Description
a|Value of the Access-Control-Allow-Origin header sent over any HTTP or HTTPS connector. This defaults to '*', which allows broadest compatibility. Note that any URI provided here limits HTTP/HTTPS access to that URI only.
|Valid values
a|dbms.security.http_access_control_allow_origin, a string
|Default value
m|+++*+++
|===

[[config_dbms.security.http_auth_allowlist]]
.dbms.security.http_auth_allowlist
[cols="<1s,<4"]
|===
|Description
a|Defines an allowlist of http paths where Neo4j authentication is not required.
|Valid values
a|dbms.security.http_auth_allowlist, a ',' separated list with elements of type 'a string'.
|Default value
m|+++/,/browser.*+++
|===

[[config_dbms.security.http_strict_transport_security]]
.dbms.security.http_strict_transport_security
[cols="<1s,<4"]
|===
|Description
a|Value of the HTTP Strict-Transport-Security (HSTS) response header. This header tells browsers that a webpage should only be accessed using HTTPS instead of HTTP. It is attached to every HTTPS response. Setting is not set by default so 'Strict-Transport-Security' header is not sent. Value is expected to contain directives like 'max-age', 'includeSubDomains' and 'preload'.
|Valid values
a|dbms.security.http_strict_transport_security, a string
|===

[[config_dbms.security.key.name]]
.dbms.security.key.name
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Name of the 256 length AES encryption key, which is used for the symmetric encryption.
|Valid values
a|dbms.security.key.name, a string
|Dynamic a|true
|Default value
m|+++aesKey+++
|===

[[config_dbms.security.keystore.password]]
.dbms.security.keystore.password
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Password for accessing the keystore holding a 256 length AES encryption key, which is used for the symmetric encryption.
|Valid values
a|dbms.security.keystore.password, a secure string
|Dynamic a|true
|===

[[config_dbms.security.keystore.path]]
.dbms.security.keystore.path
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Location of the keystore holding a 256 length AES encryption key, which is used for the symmetric encryption of secrets held in system database.
|Valid values
a|dbms.security.keystore.path, a path
|Dynamic a|true
|===

[[config_dbms.security.ldap.authentication.attribute]]
.dbms.security.ldap.authentication.attribute
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The attribute to use when looking up users.
Using this setting requires `<<config_dbms.security.ldap.authentication.search_for_attribute,dbms.security.ldap.authentication.search_for_attribute>>` to be true and thus `<<config_dbms.security.ldap.authorization.system_username,dbms.security.ldap.authorization.system_username>>` and `<<config_dbms.security.ldap.authorization.system_password,dbms.security.ldap.authorization.system_password>>` to be configured.
|Valid values
a|dbms.security.ldap.authentication.attribute, a string which matches the pattern `[A-Za-z0-9-]*` (has to be a valid LDAP attribute name, only containing letters [A-Za-z], digits [0-9] and hyphens [-].)
|Dynamic a|true
|Default value
m|+++samaccountname+++
|===

[[config_dbms.security.ldap.authentication.cache_enabled]]
.dbms.security.ldap.authentication.cache_enabled
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Determines if the result of authentication via the LDAP server should be cached or not. Caching is used to limit the number of LDAP requests that have to be made over the network for users that have already been authenticated successfully. A user can be authenticated against an existing cache entry (instead of via an LDAP server) as long as it is alive (see `<<config_dbms.security.auth_cache_ttl,dbms.security.auth_cache_ttl>>`).
An important consequence of setting this to `true` is that Neo4j then needs to cache a hashed version of the credentials in order to perform credentials matching. This hashing is done using a cryptographic hash function together with a random salt. Preferably a conscious decision should be made if this method is considered acceptable by the security standards of the organization in which this Neo4j instance is deployed.
|Valid values
a|dbms.security.ldap.authentication.cache_enabled, a boolean
|Default value
m|+++true+++
|===

[[config_dbms.security.ldap.authentication.mechanism]]
.dbms.security.ldap.authentication.mechanism
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]LDAP authentication mechanism. This is one of `simple` or a SASL mechanism supported by JNDI, for example `DIGEST-MD5`. `simple` is basic username and password authentication and SASL is used for more advanced mechanisms. See RFC 2251 LDAPv3 documentation for more details.
|Valid values
a|dbms.security.ldap.authentication.mechanism, a string
|Default value
m|+++simple+++
|===

[[config_dbms.security.ldap.authentication.search_for_attribute]]
.dbms.security.ldap.authentication.search_for_attribute
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Perform authentication by searching for an unique attribute of a user.
Using this setting requires `<<config_dbms.security.ldap.authorization.system_username,dbms.security.ldap.authorization.system_username>>` and `<<config_dbms.security.ldap.authorization.system_password,dbms.security.ldap.authorization.system_password>>` to be configured.
|Valid values
a|dbms.security.ldap.authentication.search_for_attribute, a boolean
|Default value
m|+++false+++
|===

[[config_dbms.security.ldap.authentication.user_dn_template]]
.dbms.security.ldap.authentication.user_dn_template
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]LDAP user DN template. An LDAP object is referenced by its distinguished name (DN), and a user DN is an LDAP fully-qualified unique user identifier. This setting is used to generate an LDAP DN that conforms with the LDAP directory's schema from the user principal that is submitted with the authentication token when logging in. The special token {0} is a placeholder where the user principal will be substituted into the DN string.
|Valid values
a|dbms.security.ldap.authentication.user_dn_template, a string which Must be a string containing '{0}' to understand where to insert the runtime authentication principal.
|Dynamic a|true
|Default value
m|+++uid={0},ou=users,dc=example,dc=com+++
|===

[[config_dbms.security.ldap.authorization.access_permitted_group]]
.dbms.security.ldap.authorization.access_permitted_group
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The LDAP group to which a user must belong to get any access to the system.Set this to restrict access to a subset of LDAP users belonging to a particular group. If this is not set, any user to successfully authenticate via LDAP will have access to the PUBLIC role and any other roles assigned to them via <<config_dbms.security.ldap.authorization.group_to_role_mapping,dbms.security.ldap.authorization.group_to_role_mapping>>.
|Valid values
a|dbms.security.ldap.authorization.access_permitted_group, a string
|Dynamic a|true
|Default value
m|++++++
|===

[[config_dbms.security.ldap.authorization.group_membership_attributes]]
.dbms.security.ldap.authorization.group_membership_attributes
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]A list of attribute names on a user object that contains groups to be used for mapping to roles when LDAP authorization is enabled. This setting is ignored when `dbms.ldap_authorization_nested_groups_enabled` is `true`.
|Valid values
a|dbms.security.ldap.authorization.group_membership_attributes, a ',' separated list with elements of type 'a string'. which Can not be empty
|Dynamic a|true
|Default value
m|+++memberOf+++
|===

[[config_dbms.security.ldap.authorization.group_to_role_mapping]]
.dbms.security.ldap.authorization.group_to_role_mapping
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]An authorization mapping from LDAP group names to Neo4j role names. The map should be formatted as a semicolon separated list of key-value pairs, where the key is the LDAP group name and the value is a comma separated list of corresponding role names. For example: group1=role1;group2=role2;group3=role3,role4,role5
You could also use whitespaces and quotes around group names to make this mapping more readable, for example: 
----
`dbms.security.ldap.authorization.group_to_role_mapping`=\
         "cn=Neo4j Read Only,cn=users,dc=example,dc=com"      = reader;    \
         "cn=Neo4j Read-Write,cn=users,dc=example,dc=com"     = publisher; \
         "cn=Neo4j Schema Manager,cn=users,dc=example,dc=com" = architect; \
         "cn=Neo4j Administrator,cn=users,dc=example,dc=com"  = admin
----
|Valid values
a|dbms.security.ldap.authorization.group_to_role_mapping, a string which must be semicolon separated list of key-value pairs or empty
|Dynamic a|true
|Default value
m|++++++
|===

[[config_dbms.security.ldap.authorization.nested_groups_enabled]]
.dbms.security.ldap.authorization.nested_groups_enabled
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]This setting determines whether multiple LDAP search results will be processed (as is required for the lookup of nested groups). If set to `true` then instead of using attributes on the user object to determine group membership (as specified by `<<config_dbms.security.ldap.authorization.group_membership_attributes,dbms.security.ldap.authorization.group_membership_attributes>>`), the `user` object will only be used to determine the user's Distinguished Name, which will subsequently be used with  `<<config_dbms.security.ldap.authorization.user_search_filter,dbms.security.ldap.authorization.user_search_filter>>` in order to perform a nested group search. The Distinguished Names of the resultant group search results will be used to determine roles.
|Valid values
a|dbms.security.ldap.authorization.nested_groups_enabled, a boolean
|Dynamic a|true
|Default value
m|+++false+++
|===

[[config_dbms.security.ldap.authorization.nested_groups_search_filter]]
.dbms.security.ldap.authorization.nested_groups_search_filter
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The search template which will be used to find the nested groups which the user is a member of. The filter should contain the placeholder token `{0}` which will be substituted with the user's Distinguished Name (which is found for the specified user principle using `<<config_dbms.security.ldap.authorization.user_search_filter,dbms.security.ldap.authorization.user_search_filter>>`). The default value specifies Active Directory's LDAP_MATCHING_RULE_IN_CHAIN (aka 1.2.840.113556.1.4.1941) implementation which will walk the ancestry of group membership for the specified user.
|Valid values
a|dbms.security.ldap.authorization.nested_groups_search_filter, a string
|Dynamic a|true
|Default value
m|+++(&(objectclass=group)(member:1.2.840.113556.1.4.1941:={0}))+++
|===

[[config_dbms.security.ldap.authorization.system_password]]
.dbms.security.ldap.authorization.system_password
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]An LDAP system account password to use for authorization searches when `<<config_dbms.security.ldap.authorization.use_system_account,dbms.security.ldap.authorization.use_system_account>>` is `true`.
|Valid values
a|dbms.security.ldap.authorization.system_password, a secure string
|===

[[config_dbms.security.ldap.authorization.system_username]]
.dbms.security.ldap.authorization.system_username
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]An LDAP system account username to use for authorization searches when `<<config_dbms.security.ldap.authorization.use_system_account,dbms.security.ldap.authorization.use_system_account>>` is `true`. Note that the `<<config_dbms.security.ldap.authentication.user_dn_template,dbms.security.ldap.authentication.user_dn_template>>` will not be applied to this username, so you may have to specify a full DN.
|Valid values
a|dbms.security.ldap.authorization.system_username, a string
|===

[[config_dbms.security.ldap.authorization.use_system_account]]
.dbms.security.ldap.authorization.use_system_account
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Perform LDAP search for authorization info using a system account instead of the user's own account.
If this is set to `false` (default), the search for group membership will be performed directly after authentication using the LDAP context bound with the user's own account. The mapped roles will be cached for the duration of `<<config_dbms.security.auth_cache_ttl,dbms.security.auth_cache_ttl>>`, and then expire, requiring re-authentication. To avoid frequently having to re-authenticate sessions you may want to set a relatively long auth cache expiration time together with this option. NOTE: This option will only work if the users are permitted to search for their own group membership attributes in the directory.
If this is set to `true`, the search will be performed using a special system account user with read access to all the users in the directory. You need to specify the username and password using the settings `<<config_dbms.security.ldap.authorization.system_username,dbms.security.ldap.authorization.system_username>>` and `<<config_dbms.security.ldap.authorization.system_password,dbms.security.ldap.authorization.system_password>>` with this option. Note that this account only needs read access to the relevant parts of the LDAP directory and does not need to have access rights to Neo4j, or any other systems.
|Valid values
a|dbms.security.ldap.authorization.use_system_account, a boolean
|Default value
m|+++false+++
|===

[[config_dbms.security.ldap.authorization.user_search_base]]
.dbms.security.ldap.authorization.user_search_base
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The name of the base object or named context to search for user objects when LDAP authorization is enabled. A common case is that this matches the last part of `<<config_dbms.security.ldap.authentication.user_dn_template,dbms.security.ldap.authentication.user_dn_template>>`.
|Valid values
a|dbms.security.ldap.authorization.user_search_base, a string which Can not be empty
|Dynamic a|true
|Default value
m|+++ou=users,dc=example,dc=com+++
|===

[[config_dbms.security.ldap.authorization.user_search_filter]]
.dbms.security.ldap.authorization.user_search_filter
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The LDAP search filter to search for a user principal when LDAP authorization is enabled. The filter should contain the placeholder token {0} which will be substituted for the user principal.
|Valid values
a|dbms.security.ldap.authorization.user_search_filter, a string
|Dynamic a|true
|Default value
m|+++(&(objectClass=*)(uid={0}))+++
|===

[[config_dbms.security.ldap.connection_timeout]]
.dbms.security.ldap.connection_timeout
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The timeout for establishing an LDAP connection. If a connection with the LDAP server cannot be established within the given time the attempt is aborted. A value of 0 means to use the network protocol's (i.e., TCP's) timeout value.
|Valid values
a|dbms.security.ldap.connection_timeout, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++30s+++
|===

[[config_dbms.security.ldap.host]]
.dbms.security.ldap.host
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]URL of LDAP server to use for authentication and authorization. The format of the setting is `<protocol>://<hostname>:<port>`, where hostname is the only required field. The supported values for protocol are `ldap` (default) and `ldaps`. The default port for `ldap` is 389 and for `ldaps` 636. For example: `ldaps://ldap.example.com:10389`.
You may want to consider using STARTTLS (`<<config_dbms.security.ldap.use_starttls,dbms.security.ldap.use_starttls>>`) instead of LDAPS for secure connections, in which case the correct protocol is `ldap`.
|Valid values
a|dbms.security.ldap.host, a string
|Default value
m|+++localhost+++
|===

[[config_dbms.security.ldap.read_timeout]]
.dbms.security.ldap.read_timeout
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The timeout for an LDAP read request (i.e. search). If the LDAP server does not respond within the given time the request will be aborted. A value of 0 means wait for a response indefinitely.
|Valid values
a|dbms.security.ldap.read_timeout, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++30s+++
|===

[[config_dbms.security.ldap.referral]]
.dbms.security.ldap.referral
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The LDAP referral behavior when creating a connection. This is one of `follow`, `ignore` or `throw`.
* `follow` automatically follows any referrals
* `ignore` ignores any referrals
* `throw` throws an exception, which will lead to authentication failure.
|Valid values
a|dbms.security.ldap.referral, a string
|Default value
m|+++follow+++
|===

[[config_dbms.security.ldap.use_starttls]]
.dbms.security.ldap.use_starttls
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Use secure communication with the LDAP server using opportunistic TLS. First an initial insecure connection will be made with the LDAP server, and a STARTTLS command will be issued to negotiate an upgrade of the connection to TLS before initiating authentication.
|Valid values
a|dbms.security.ldap.use_starttls, a boolean
|Default value
m|+++false+++
|===

[[config_dbms.security.log_successful_authentication]]
.dbms.security.log_successful_authentication
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Set to log successful authentication events to the security log. If this is set to `false` only failed authentication events will be logged, which could be useful if you find that the successful events spam the logs too much, and you do not require full auditing capability.
|Valid values
a|dbms.security.log_successful_authentication, a boolean
|Default value
m|+++true+++
|===

[[config_dbms.security.oidc.-provider-.audience]]
.dbms.security.oidc.<provider>.audience
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Expected values of the Audience (aud) claim in the id token.
|Valid values
a|dbms.security.oidc.<provider>.audience, a ',' separated list with elements of type 'a string'. which Can not be empty
|Dynamic a|true
|===

[[config_dbms.security.oidc.-provider-.auth_endpoint]]
.dbms.security.oidc.<provider>.auth_endpoint
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The OIDC authorization endpoint. If this is not supplied Neo4j will attempt to discover it from the well_known_discovery_uri.
|Valid values
a|dbms.security.oidc.<provider>.auth_endpoint, a URI
|Dynamic a|true
|===

[[config_dbms.security.oidc.-provider-.auth_flow]]
.dbms.security.oidc.<provider>.auth_flow
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The OIDC flow to use. This is exposed to clients via the discovery endpoint. Supported values are `pkce` and `implicit`
|Valid values
a|dbms.security.oidc.<provider>.auth_flow, one of [PKCE, IMPLICIT]
|Dynamic a|true
|Default value
m|+++PKCE+++
|===

[[config_dbms.security.oidc.-provider-.auth_params]]
.dbms.security.oidc.<provider>.auth_params
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Optional additional parameters that the auth endpoint requires. Please use params instead. The map is a semicolon separated list of key-value pairs. For example: `k1=v1;k2=v2`.
|Valid values
a|dbms.security.oidc.<provider>.auth_params, A simple key value map pattern `k1=v1;k2=v2`.
|Dynamic a|true
|Default value
m|+++{}+++
|Deprecated
a|The `dbms.security.oidc.<provider>.auth_params` configuration setting has been deprecated.
|===

[[config_dbms.security.oidc.-provider-.authorization.group_to_role_mapping]]
.dbms.security.oidc.<provider>.authorization.group_to_role_mapping
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]An authorization mapping from IdP group names to Neo4j role names. The map should be formatted as a semicolon separated list of key-value pairs, where the key is the IdP group name and the value is a comma separated list of corresponding role names. For example: group1=role1;group2=role2;group3=role3,role4,role5
You could also use whitespaces and quotes around group names to make this mapping more readable, for example: 
----
dbms.security.oidc.<provider>.authorization.group_to_role_mapping=\
         "Neo4j Read Only"      = reader;    \
         "Neo4j Read-Write"     = publisher; \
         "Neo4j Schema Manager" = architect; \
         "Neo4j Administrator"  = admin
----
|Valid values
a|dbms.security.oidc.<provider>.authorization.group_to_role_mapping, a string which must be semicolon separated list of key-value pairs or empty
|Dynamic a|true
|===

[[config_dbms.security.oidc.-provider-.claims.groups]]
.dbms.security.oidc.<provider>.claims.groups
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The claim to use as the list of groups in Neo4j. These could be Neo4J roles directly, or can be mapped using dbms.security.oidc.<provider>.authorization.group_to_role_mapping.
|Valid values
a|dbms.security.oidc.<provider>.claims.groups, a string
|Dynamic a|true
|===

[[config_dbms.security.oidc.-provider-.claims.username]]
.dbms.security.oidc.<provider>.claims.username
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The claim to use as the username in Neo4j. This would typically be sub, but in some situations it may be be desirable to use something else such as email.
|Valid values
a|dbms.security.oidc.<provider>.claims.username, a string
|Dynamic a|true
|Default value
m|+++sub+++
|===

[[config_dbms.security.oidc.-provider-.client_id]]
.dbms.security.oidc.<provider>.client_id
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Client id needed if token contains multiple Audience (aud) claims.
|Valid values
a|dbms.security.oidc.<provider>.client_id, a string
|Dynamic a|true
|===

[[config_dbms.security.oidc.-provider-.config]]
.dbms.security.oidc.<provider>.config
[cols="<1s,<4a"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The accepted values (all optional) are:

* `principal`: in which JWT claim the user's email address is specified, email is the default. This is the value that will be shown in browser.
* `code_challenge_method`: default is `S256` and it's the only supported method at this moment. This setting applies only for pkce auth flow
* `token_type_principal`: the options are almost always either `access_token`, which is the default, or `id_token`.
* `token_type_authentication`: the options are almost always either `access_token`, which is the default, or `id_token`.
* `implicit_flow_requires_nonce`: true or false. Defaults to false.

|Valid values
a|dbms.security.oidc.<provider>.config, A simple key value map pattern `k1=v1;k2=v2`. Valid key options are: `[implicit_flow_requires_nonce, token_type_authentication, token_type_principal, principal, code_challenge_method]`.
|Dynamic a|true
|Default value
m|+++{}+++
|===

[[config_dbms.security.logs.oidc.jwt_claims_at_debug_level_enabled]]
.dbms.security.logs.oidc.jwt_claims_at_debug_level_enabled
[cols="<1s,<4"]
|===
|Description
a|When set to `true`, it logs the claims from the JWT. This will only take effect when the security log level is set to `DEBUG`. +
WARNING: It is strongly advised that this is set to `false` when running in a production environment in order to prevent logging of sensitive information. Also note that the contents of the JWT claims set can change over time because they are dependent entirely upon the ID provider.
|Valid values
a|dbms.security.logs.oidc.jwt_claims_at_debug_level_enabled, a boolean
|Default value
m|+++false+++
|===


[[config_dbms.security.oidc.-provider-.display_name]]
.dbms.security.oidc.<provider>.display_name
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The user-facing name of the provider as provided by the discovery endpoint to clients (Bloom, Browser etc.).
|Valid values
a|dbms.security.oidc.<provider>.display_name, a string
|===

[[config_dbms.security.oidc.-provider-.get_groups_from_user_info]]
.dbms.security.oidc.<provider>.get_groups_from_user_info
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]When turned on, Neo4j gets the groups from the provider user info endpoint.
|Valid values
a|dbms.security.oidc.<provider>.get_groups_from_user_info, a boolean
|Dynamic a|true
|Default value
m|+++false+++
|===

[[config_dbms.security.oidc.-provider-.get_username_from_user_info]]
.dbms.security.oidc.<provider>.get_username_from_user_info
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]When turned on, Neo4j gets the username from the provider user info endpoint.
|Valid values
a|dbms.security.oidc.<provider>.get_username_from_user_info, a boolean
|Dynamic a|true
|Default value
m|+++false+++
|===

[[config_dbms.security.oidc.-provider-.issuer]]
.dbms.security.oidc.<provider>.issuer
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The expected value of the iss claim in the id token. If this is not supplied Neo4j will attempt to discover it from the well_known_discovery_uri.
|Valid values
a|dbms.security.oidc.<provider>.issuer, a string
|Dynamic a|true
|===

[[config_dbms.security.oidc.-provider-.jwks_uri]]
.dbms.security.oidc.<provider>.jwks_uri
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The location of the JWK public key set for the identity provider. If this is not supplied Neo4j will attempt to discover it from the well_known_discovery_uri.
|Valid values
a|dbms.security.oidc.<provider>.jwks_uri, a URI
|Dynamic a|true
|===

[[config_dbms.security.oidc.-provider-.params]]
.dbms.security.oidc.<provider>.params
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The map is a semicolon separated list of key-value pairs. For example: `k1=v1;k2=v2`.
The user should at least provide:
----
  client_id: the SSO Idp client idenfifier.
  response_type: code if auth_flow is pkce or token for implicit auth_flow.
  scope: often containing a subset of 'email profile openid groups'.
----
For example: `client_id=my-client-id;response_type=code;scope=openid profile email`.
|Valid values
a|dbms.security.oidc.<provider>.params, A simple key value map pattern `k1=v1;k2=v2`. Required key options are: `[scope, client_id, response_type]`.
|Dynamic a|true
|Default value
m|+++{}+++
|===

[[config_dbms.security.oidc.-provider-.token_endpoint]]
.dbms.security.oidc.<provider>.token_endpoint
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The OIDC token endpoint. If this is not supplied Neo4j will attempt to discover it from the well_known_discovery_uri.
|Valid values
a|dbms.security.oidc.<provider>.token_endpoint, a URI
|Dynamic a|true
|===

[[config_dbms.security.oidc.-provider-.token_params]]
.dbms.security.oidc.<provider>.token_params
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Optional query parameters that the token endpoint requires. The map is a semicolon separated list of key-value pairs. For example: `k1=v1;k2=v2`.If the token endpoint requires a client_secret then this parameter should contain `client_secret=super-secret`
|Valid values
a|dbms.security.oidc.<provider>.token_params, A simple key value map pattern `k1=v1;k2=v2`.
|Dynamic a|true
|Default value
m|+++{}+++
|===

[[config_dbms.security.oidc.-provider-.user_info_uri]]
.dbms.security.oidc.<provider>.user_info_uri
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The identity providers user info uri.
|Valid values
a|dbms.security.oidc.<provider>.user_info_uri, a URI
|Dynamic a|true
|===

[[config_dbms.security.oidc.-provider-.well_known_discovery_uri]]
.dbms.security.oidc.<provider>.well_known_discovery_uri
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The 'well known' OpenID Connect Discovery endpoint used to fetch identity provider settings. If not provided, `issuer`, `jwks_uri`, `auth_endpoint` should be present. If the auth_flow is pkce, `token_endpoint` should also be provided.
|Valid values
a|dbms.security.oidc.<provider>.well_known_discovery_uri, a URI
|Dynamic a|true
|===

[[config_dbms.security.procedures.allowlist]]
.dbms.security.procedures.allowlist
[cols="<1s,<4"]
|===
|Description
a|A list of procedures (comma separated) that are to be loaded. The list may contain both fully-qualified procedure names, and partial names with the wildcard '*'. If this setting is left empty no procedures will be loaded.
|Valid values
a|dbms.security.procedures.allowlist, a ',' separated list with elements of type 'a string'.
|Default value
m|+++*+++
|===

[[config_dbms.security.procedures.unrestricted]]
.dbms.security.procedures.unrestricted
[cols="<1s,<4"]
|===
|Description
a|A list of procedures and user defined functions (comma separated) that are allowed full access to the database. The list may contain both fully-qualified procedure names, and partial names with the wildcard '*'. Note that this enables these procedures to bypass security. Use with caution.
|Valid values
a|dbms.security.procedures.unrestricted, a ',' separated list with elements of type 'a string'.
|Default value
m|++++++
|===

[[config_initial.dbms.database_allocator]]
.initial.dbms.database_allocator
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Name of the initial database allocator. After the creation of the dbms it can be set with the 'dbms.setDatabaseAllocator' procedure.
|Valid values
a|initial.dbms.database_allocator, a string
|Default value
m|+++EQUAL_NUMBERS+++
|===

[[config_initial.dbms.default_database]]
.initial.dbms.default_database
[cols="<1s,<4"]
|===
|Description
a|Name of the default database (aliases are not supported).
|Valid values
a|initial.dbms.default_database, A valid database name containing only alphabetic characters, numbers, dots and dashes with a length between 3 and 63 characters, starting with an alphabetic character but not with the name 'system'
|Default value
m|+++neo4j+++
|===

[[config_initial.dbms.default_primaries_count]]
.initial.dbms.default_primaries_count
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Initial default number of primary instances of user databases. If the user does not specify the number of primaries in 'CREATE DATABASE', this value will be used, unless it is overwritten with the 'dbms.setDefaultAllocationNumbers' procedure.
|Valid values
a|initial.dbms.default_primaries_count, an integer which is minimum `1` and is maximum `11`.
The same value applies to runtime max number.
|Default value
m|+++1+++
|===

[[config_initial.dbms.default_secondaries_count]]
.initial.dbms.default_secondaries_count
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Initial default number of secondary instances of user databases. If the user does not specify the number of secondaries in 'CREATE DATABASE', this value will be used, unless it is overwritten with the 'dbms.setDefaultAllocationNumbers' procedure.
|Valid values
a|initial.dbms.default_secondaries_count, an integer which is minimum `0` and is maximum `20`.
The same value applies to runtime max number.
|Default value
m|+++0+++
|===

[[config_initial.server.allowed_databases]]
.initial.server.allowed_databases
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The names of databases that are allowed on this server - all others are denied. Empty means all are allowed. Can be overridden when enabling the server, or altered at runtime, without changing this setting. Exclusive with 'server.initial_denied_databases'
|Valid values
a|initial.server.allowed_databases, a ',' separated set with elements of type 'a string'.
|Default value
m|++++++
|===

[[config_initial.server.denied_databases]]
.initial.server.denied_databases
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The names of databases that are not allowed on this server. Empty means nothing is denied. Can be overridden when enabling the server, or altered at runtime, without changing this setting. Exclusive with 'server.initial_allowed_databases'
|Valid values
a|initial.server.denied_databases, a ',' separated set with elements of type 'a string'.
|Default value
m|++++++
|===

[[config_initial.server.mode_constraint]]
.initial.server.mode_constraint
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]An instance can restrict itself to allow databases to be hosted only as primaries or secondaries. This setting is the default input for the `ENABLE SERVER` command - the user can overwrite it when executing the procedure.
|Valid values
a|initial.server.mode_constraint, one of [PRIMARY, SECONDARY, NONE]
|Default value
m|+++NONE+++
|===

[[config_server.backup.enabled]]
.server.backup.enabled
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Enable support for running online backups.
|Valid values
a|server.backup.enabled, a boolean
|Default value
m|+++true+++
|===

[[config_server.backup.listen_address]]
.server.backup.listen_address
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Network interface and port for the backup server to listen on.
|Valid values
a|server.backup.listen_address, a socket address in the format 'hostname:port', 'hostname' or ':port'
|Default value
m|+++127.0.0.1:6362+++
|===

[[config_server.backup.store_copy_max_retry_time_per_request]]
.server.backup.store_copy_max_retry_time_per_request
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Maximum retry time per request during store copy. Regular store files and indexes are downloaded in separate requests during store copy. This configures the maximum time failed requests are allowed to resend.
|Valid values
a|server.backup.store_copy_max_retry_time_per_request, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++20m+++
|===

[[config_server.bolt.advertised_address]]
.server.bolt.advertised_address
[cols="<1s,<4"]
|===
|Description
a|Advertised address for this connector.
|Valid values
a|server.bolt.advertised_address, a socket address in the format 'hostname:port', 'hostname' or ':port' which accessible address. If missing port or hostname it is acquired from server.default_advertised_address
|Default value
m|+++:7687+++
|===

[[config_server.bolt.connection_keep_alive]]
.server.bolt.connection_keep_alive
[cols="<1s,<4"]
|===
|Description
a|The maximum time to wait before sending a NOOP on connections waiting for responses from active ongoing queries.The minimum value is 1 millisecond.
|Valid values
a|server.bolt.connection_keep_alive, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`) which is minimum `1ms`
|Default value
m|1m
|===

[[config_server.bolt.connection_keep_alive_for_requests]]
.server.bolt.connection_keep_alive_for_requests
[cols="<1s,<4"]
|===
|Description
a|The type of messages to enable keep-alive messages for (ALL, STREAMING or OFF)
|Valid values
a|server.bolt.connection_keep_alive_for_requests, one of [ALL, STREAMING, OFF]
|Default value
m|STREAMING
|===

[[config_server.bolt.connection_keep_alive_probes]]
.server.bolt.connection_keep_alive_probes
[cols="<1s,<4"]
|===
|Description
a|The total amount of probes to be missed before a connection is considered stale.The minimum for this value is 1.
|Valid values
a|server.bolt.connection_keep_alive_probes, an integer which is minimum `1`
|Default value
m|2
|===

[[config_server.bolt.connection_keep_alive_streaming_scheduling_interval]]
.server.bolt.connection_keep_alive_streaming_scheduling_interval
[cols="<1s,<4"]
|===
|Description
a|The interval between every scheduled keep-alive check on all connections with active queries. Zero duration turns off keep-alive service.
|Valid values
a|server.bolt.connection_keep_alive_streaming_scheduling_interval, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`) which is minimum `0s`
|Default value
m|1m
|===

[[config_server.bolt.enabled]]
.server.bolt.enabled
[cols="<1s,<4"]
|===
|Description
a|Enable the bolt connector.
|Valid values
a|server.bolt.enabled, a boolean
|Default value
m|true
|===

[[config_server.bolt.listen_address]]
.server.bolt.listen_address
[cols="<1s,<4"]
|===
|Description
a|Address the connector should bind to.
|Valid values
a|server.bolt.listen_address, a socket address in the format 'hostname:port', 'hostname' or ':port'. If missing port or hostname it is acquired from server.default_listen_address
|Default value
m|+++:7687+++
|===

[[config_server.bolt.ocsp_stapling_enabled]]
.server.bolt.ocsp_stapling_enabled
[cols="<1s,<4"]
|===
|Description
a|Enable server OCSP stapling for bolt and http connectors.
|Valid values
a|server.bolt.ocsp_stapling_enabled, a boolean
|Default value
m|false
|===

[[config_server.bolt.thread_pool_keep_alive]]
.server.bolt.thread_pool_keep_alive
[cols="<1s,<4"]
|===
|Description
a|The maximum time an idle thread in the thread pool bound to this connector will wait for new tasks.
|Valid values
a|server.bolt.thread_pool_keep_alive, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++5m+++
|===

[[config_server.bolt.thread_pool_max_size]]
.server.bolt.thread_pool_max_size
[cols="<1s,<4"]
|===
|Description
a|The maximum number of threads allowed in the thread pool bound to this connector.
|Valid values
a|server.bolt.thread_pool_max_size, an integer
|Default value
m|+++400+++
|===

[[config_server.bolt.thread_pool_min_size]]
.server.bolt.thread_pool_min_size
[cols="<1s,<4"]
|===
|Description
a|The number of threads to keep in the thread pool bound to this connector, even if they are idle.
|Valid values
a|server.bolt.thread_pool_min_size, an integer
|Default value
m|+++5+++
|===

[[config_server.bolt.tls_level]]
.server.bolt.tls_level
[cols="<1s,<4"]
|===
|Description
a|Encryption level to require this connector to use.
|Valid values
a|server.bolt.tls_level, one of [REQUIRED, OPTIONAL, DISABLED]
|Default value
m|+++DISABLED+++
|===

[[config_server.cluster.advertised_address]]
.server.cluster.advertised_address
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Advertised hostname/IP address and port for the transaction shipping server.
|Valid values
a|server.cluster.advertised_address, a socket address in the format 'hostname:port', 'hostname' or ':port' which accessible address. If missing port or hostname it is acquired from server.default_advertised_address
|Default value
m|+++:6000+++
|===

[[config_server.cluster.catchup.connect_randomly_to_server_group]]
.server.cluster.catchup.connect_randomly_to_server_group
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Comma separated list of groups to be used by the connect-randomly-to-server-group selection strategy. The connect-randomly-to-server-group strategy is used if the list of strategies (`<<config_server.cluster.catchup.upstream_strategy,server.cluster.catchup.upstream_strategy>>`) includes the value `connect-randomly-to-server-group`.
|Valid values
a|server.cluster.catchup.connect_randomly_to_server_group, a ',' separated list with elements of type 'a string identifying a Server Tag'.
|Dynamic a|true
|Default value
m|++++++
|===

[[config_server.cluster.catchup.upstream_strategy]]
.server.cluster.catchup.upstream_strategy
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]An ordered list in descending preference of the strategy which secondaries use to choose the upstream server from which to pull transactional updates. If none are valid or the list is empty, there is a default strategy of `typically-connect-to-random-secondary`.
|Valid values
a|server.cluster.catchup.upstream_strategy, a ',' separated list with elements of type 'a string'.
|Default value
m|++++++
|===

[[config_server.cluster.catchup.user_defined_upstream_strategy]]
.server.cluster.catchup.user_defined_upstream_strategy
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Configuration of a user-defined upstream selection strategy. The user-defined strategy is used if the list of strategies (`<<config_server.cluster.catchup.upstream_strategy,server.cluster.catchup.upstream_strategy>>`) includes the value `user_defined`.
|Valid values
a|server.cluster.catchup.user_defined_upstream_strategy, a string
|Default value
m|++++++
|===

[[config_server.cluster.listen_address]]
.server.cluster.listen_address
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Network interface and port for the transaction shipping server to listen on. Please note that it is also possible to run the backup client against this port so always limit access to it via the firewall and configure an ssl policy.
|Valid values
a|server.cluster.listen_address, a socket address in the format 'hostname:port', 'hostname' or ':port'. If missing port or hostname it is acquired from server.default_listen_address
|Default value
m|+++:6000+++
|===

[[config_server.cluster.network.native_transport_enabled]]
.server.cluster.network.native_transport_enabled
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Use native transport if available. Epoll for Linux or Kqueue for MacOS/BSD. If this setting is set to false, or if native transport is not available, Nio transport will be used.
|Valid values
a|server.cluster.network.native_transport_enabled, a boolean
|Default value
m|+++true+++
|===

[[config_server.cluster.raft.advertised_address]]
.server.cluster.raft.advertised_address
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Advertised hostname/IP address and port for the RAFT server.
|Valid values
a|server.cluster.raft.advertised_address, a socket address in the format 'hostname:port', 'hostname' or ':port' which accessible address. If missing port or hostname it is acquired from server.default_advertised_address
|Default value
m|+++:7000+++
|===

[[config_server.cluster.raft.listen_address]]
.server.cluster.raft.listen_address
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Network interface and port for the RAFT server to listen on.
|Valid values
a|server.cluster.raft.listen_address, a socket address in the format 'hostname:port', 'hostname' or ':port'. If missing port or hostname it is acquired from server.default_listen_address
|Default value
m|+++:7000+++
|===

[[config_server.cluster.system_database_mode]]
.server.cluster.system_database_mode
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Users must manually specify the mode for the system database on each instance.
|Valid values
a|server.cluster.system_database_mode, one of [PRIMARY, SECONDARY]
|Default value
m|+++PRIMARY+++
|===

[[config_server.config.strict_validation.enabled]]
.server.config.strict_validation.enabled
[cols="<1s,<4"]
|===
|Description
a|A strict configuration validation will prevent the database from starting up if unknown configuration options are specified in the neo4j settings namespace (such as dbms., cypher., etc) or if settings are declared multiple times.
|Valid values
a|server.config.strict_validation.enabled, a boolean
|Default value
m|+++true+++
|===

[[config_server.databases.default_to_read_only]]
.server.databases.default_to_read_only
[cols="<1s,<4"]
|===
|Description
a|Whether or not any database on this instance are read_only by default. If false, individual databases may be marked as read_only using server.database.read_only. If true, individual databases may be marked as writable using <<config_server.databases.writable,server.databases.writable>>.
|Valid values
a|server.databases.default_to_read_only, a boolean
|Dynamic a|true
|Default value
m|+++false+++
|===

[[config_server.databases.read_only]]
.server.databases.read_only
[cols="<1s,<4"]
|===
|Description
a|List of databases for which to prevent write queries. Databases not included in this list maybe read_only anyway depending upon the value of <<config_server.databases.default_to_read_only,server.databases.default_to_read_only>>.
|Valid values
a|server.databases.read_only, a ',' separated set with elements of type 'A valid database name containing only alphabetic characters, numbers, dots and dashes with a length between 3 and 63 characters, starting with an alphabetic character but not with the name 'system''. which Value 'system' can't be included in read only databases collection!
|Dynamic a|true
|Default value
m|++++++
|===

[[config_server.databases.writable]]
.server.databases.writable
[cols="<1s,<4"]
|===
|Description
a|List of databases for which to allow write queries. Databases not included in this list will allow write queries anyway, unless <<config_server.databases.default_to_read_only,server.databases.default_to_read_only>> is set to true.
|Valid values
a|server.databases.writable, a ',' separated set with elements of type 'A valid database name containing only alphabetic characters, numbers, dots and dashes with a length between 3 and 63 characters, starting with an alphabetic character but not with the name 'system''.
|Dynamic a|true
|Default value
m|++++++
|===

[[config_server.db.query_cache_size]]
.server.db.query_cache_size
[cols="<1s,<4"]
|===
|Description
a|The number of cached Cypher query execution plans per database. The max number of query plans that can be kept in cache is the `number of databases` * ``server.db.query_cache_size``. With 10 databases and ``server.db.query_cache_size``=1000, the caches can keep 10000 plans in total on the instance, assuming that each DB receives queries that fill up its cache.
|Valid values
a|server.db.query_cache_size, an integer which is minimum `0`
|Default value
m|+++1000+++
|===

[[config_server.default_advertised_address]]
.server.default_advertised_address
[cols="<1s,<4"]
|===
|Description
a|Default hostname or IP address the server uses to advertise itself.
|Valid values
a|server.default_advertised_address, a socket address in the format 'hostname:port', 'hostname' or ':port' which has no specified port and accessible address
|Default value
m|+++localhost+++
|===

[[config_server.default_listen_address]]
.server.default_listen_address
[cols="<1s,<4"]
|===
|Description
a|Default network interface to listen for incoming connections. To listen for connections on all interfaces, use "0.0.0.0".
|Valid values
a|server.default_listen_address, a socket address in the format 'hostname:port', 'hostname' or ':port' which has no specified port
|Default value
m|+++localhost+++
|===

[[config_server.directories.cluster_state]]
.server.directories.cluster_state
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Directory to hold cluster state including Raft log.
|Valid values
a|server.directories.cluster_state, a path. If relative it is resolved from server.directories.data
|Default value
m|+++cluster-state+++
|===

[[config_server.directories.data]]
.server.directories.data
[cols="<1s,<4"]
|===
|Description
a|Path of the data directory. You must not configure more than one Neo4j installation to use the same data directory.
|Valid values
a|server.directories.data, a path. If relative it is resolved from server.directories.neo4j_home
|Default value
m|+++data+++
|===

[[config_server.directories.dumps.root]]
.server.directories.dumps.root
[cols="<1s,<4"]
|===
|Description
a|Root location where Neo4j will store database dumps optionally produced when dropping said databases.
|Valid values
a|server.directories.dumps.root, a path. If relative it is resolved from server.directories.data
|Default value
m|+++dumps+++
|===

[[config_server.directories.import]]
.server.directories.import
[cols="<1s,<4"]
|===
|Description
a|Sets the root directory for file URLs used with the Cypher `LOAD CSV` clause. This should be set to a directory relative to the Neo4j installation path, restricting access to only those files within that directory and its subdirectories. For example the value "import" will only enable access to files within the 'import' folder. Removing this setting will disable the security feature, allowing all files in the local system to be imported. Setting this to an empty field will allow access to all files within the Neo4j installation folder.
|Valid values
a|server.directories.import, a path. If relative it is resolved from server.directories.neo4j_home
|===

[[config_server.directories.lib]]
.server.directories.lib
[cols="<1s,<4"]
|===
|Description
a|Path of the lib directory.
|Valid values
a|server.directories.lib, a path. If relative it is resolved from server.directories.neo4j_home
|Default value
m|+++lib+++
|===

[[config_server.directories.licenses]]
.server.directories.licenses
[cols="<1s,<4"]
|===
|Description
a|Path of the licenses directory.
|Valid values
a|server.directories.licenses, a path. If relative it is resolved from server.directories.neo4j_home
|Default value
m|+++licenses+++
|===

[[config_server.directories.logs]]
.server.directories.logs
[cols="<1s,<4"]
|===
|Description
a|Path of the logs directory.
|Valid values
a|server.directories.logs, a path. If relative it is resolved from server.directories.neo4j_home
|Default value
m|+++logs+++
|===

[[config_server.directories.metrics]]
.server.directories.metrics
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The target location of the CSV files: a path to a directory wherein a CSV file per reported field  will be written.
|Valid values
a|server.directories.metrics, a path. If relative it is resolved from server.directories.neo4j_home
|Default value
m|+++metrics+++
|===

[[config_server.directories.neo4j_home]]
.server.directories.neo4j_home
[cols="<1s,<4"]
|===
|Description
a|Root relative to which directory settings are resolved. Calculated and set by the server on startup.
|Valid values
a|server.directories.neo4j_home, a path which is absolute
|Default value
m|Defaults to current working directory
|===

[[config_server.directories.plugins]]
.server.directories.plugins
[cols="<1s,<4"]
|===
|Description
a|Location of the database plugin directory. Compiled Java JAR files that contain database procedures will be loaded if they are placed in this directory.
|Valid values
a|server.directories.plugins, a path. If relative it is resolved from server.directories.neo4j_home
|Default value
m|+++plugins+++
|===

[[config_server.directories.run]]
.server.directories.run
[cols="<1s,<4"]
|===
|Description
a|Path of the run directory. This directory holds Neo4j's runtime state, such as a pidfile when it is running in the background. The pidfile is created when starting neo4j and removed when stopping it. It may be placed on an in-memory filesystem such as tmpfs.
|Valid values
a|server.directories.run, a path. If relative it is resolved from server.directories.neo4j_home
|Default value
m|+++run+++
|===

[[config_server.directories.script.root]]
.server.directories.script.root
[cols="<1s,<4"]
|===
|Description
a|Root location where Neo4j will store scripts for configured databases.
|Valid values
a|server.directories.script.root, a path. If relative it is resolved from server.directories.data
|Default value
m|+++scripts+++
|===

[[config_server.directories.transaction.logs.root]]
.server.directories.transaction.logs.root
[cols="<1s,<4"]
|===
|Description
a|Root location where Neo4j will store transaction logs for configured databases.
|Valid values
a|server.directories.transaction.logs.root, a path. If relative it is resolved from server.directories.data
|Default value
m|+++transactions+++
|===

[[config_server.discovery.advertised_address]]
.server.discovery.advertised_address
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Advertised cluster member discovery management communication.
|Valid values
a|server.discovery.advertised_address, a socket address in the format 'hostname:port', 'hostname' or ':port' which accessible address. If missing port or hostname it is acquired from server.default_advertised_address
|Default value
m|+++:5000+++
|===

[[config_server.discovery.listen_address]]
.server.discovery.listen_address
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Host and port to bind the cluster member discovery management communication.
|Valid values
a|server.discovery.listen_address, a socket address in the format 'hostname:port', 'hostname' or ':port'. If missing port or hostname it is acquired from server.default_listen_address
|Default value
m|+++:5000+++
|===

[[config_server.dynamic.setting.allowlist]]
.server.dynamic.setting.allowlist
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]A list of setting name patterns (comma separated) that are allowed to be dynamically changed. The list may contain both full setting names, and partial names with the wildcard '*'. If this setting is left empty all dynamic settings updates will be blocked.
|Valid values
a|server.dynamic.setting.allowlist, a ',' separated list with elements of type 'a string'.
|Default value
m|+++*+++
|===

[[config_server.groups]]
.server.groups
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]A list of tag names for the server used when configuring load balancing and replication policies.
|Valid values
a|server.groups, a ',' separated list with elements of type 'a string identifying a Server Tag'.
|Dynamic a|true
|Default value
m|++++++
|===

[[config_server.http.advertised_address]]
.server.http.advertised_address
[cols="<1s,<4"]
|===
|Description
a|Advertised address for this connector.
|Valid values
a|server.http.advertised_address, a socket address in the format 'hostname:port', 'hostname' or ':port' which accessible address. If missing port or hostname it is acquired from server.default_advertised_address
|Default value
m|+++:7474+++
|===

[[config_server.http.enabled]]
.server.http.enabled
[cols="<1s,<4"]
|===
|Description
a|Enable the http connector.
|Valid values
a|server.http.enabled, a boolean
|Default value
m|true
|===

[[config_server.http.listen_address]]
.server.http.listen_address
[cols="<1s,<4"]
|===
|Description
a|Address the connector should bind to.
|Valid values
a|server.http.listen_address, a socket address in the format 'hostname:port', 'hostname' or ':port'. If missing port or hostname it is acquired from server.default_listen_address
|Default value
m|+++:7474+++
|===

[[config_server.http_enabled_modules]]
.server.http_enabled_modules
[cols="<1s,<4"]
|===
|Description
a|Defines the set of modules loaded into the Neo4j web server. Options include TRANSACTIONAL_ENDPOINTS, BROWSER, UNMANAGED_EXTENSIONS and ENTERPRISE_MANAGEMENT_ENDPOINTS (if applicable).
|Valid values
a|server.http_enabled_modules, a ',' separated set with elements of type 'one of [TRANSACTIONAL_ENDPOINTS, UNMANAGED_EXTENSIONS, BROWSER, ENTERPRISE_MANAGEMENT_ENDPOINTS]'.
|Default value
m|+++TRANSACTIONAL_ENDPOINTS,UNMANAGED_EXTENSIONS,BROWSER,ENTERPRISE_MANAGEMENT_ENDPOINTS+++
|===

[[config_server.https.advertised_address]]
.server.https.advertised_address
[cols="<1s,<4"]
|===
|Description
a|Advertised address for this connector.
|Valid values
a|server.https.advertised_address, a socket address in the format 'hostname:port', 'hostname' or ':port' which accessible address. If missing port or hostname it is acquired from server.default_advertised_address
|Default value
m|+++:7473+++
|===

[[config_server.https.enabled]]
.server.https.enabled
[cols="<1s,<4"]
|===
|Description
a|Enable the https connector.
|Valid values
a|server.https.enabled, a boolean
|Default value
m|+++false+++
|===

[[config_server.https.listen_address]]
.server.https.listen_address
[cols="<1s,<4"]
|===
|Description
a|Address the connector should bind to.
|Valid values
a|server.https.listen_address, a socket address in the format 'hostname:port', 'hostname' or ':port'. If missing port or hostname it is acquired from server.default_listen_address
|Default value
m|+++:7473+++
|===

[[config_server.jvm.additional]]
.server.jvm.additional
[cols="<1s,<4"]
|===
|Description
a|Additional JVM arguments. Argument order can be significant. To use a Java commercial feature, the argument to unlock commercial features must precede the argument to enable the specific feature in the config value string. For example, to use Flight Recorder, `-XX:+UnlockCommercialFeatures` must come before `-XX:+FlightRecorder`.
|Valid values
a|server.jvm.additional, one or more jvm arguments
|===

[[config_server.logs.config]]
.server.logs.config
[cols="<1s,<4"]
|===
|Description
a|Path to the logging configuration for debug, query, http and security logs.
|Valid values
a|server.logs.config, a path. If relative it is resolved from server.directories.neo4j_home
|Default value
m|+++conf/server-logs.xml+++
|===

[[config_server.logs.debug.enabled]]
.server.logs.debug.enabled
[cols="<1s,<4"]
|===
|Description
a|Enable the debug log.
|Valid values
a|server.logs.debug.enabled, a boolean
|Default value
m|+++true+++
|===

[[config_server.logs.gc.enabled]]
.server.logs.gc.enabled
[cols="<1s,<4"]
|===
|Description
a|Enable GC Logging.
|Valid values
a|server.logs.gc.enabled, a boolean
|Default value
m|+++false+++
|===

[[config_server.logs.gc.options]]
.server.logs.gc.options
[cols="<1s,<4"]
|===
|Description
a|GC Logging Options.
|Valid values
a|server.logs.gc.options, a string
|Default value
m|+++-Xlog:gc*,safepoint,age*=trace+++
|===

[[config_server.logs.gc.rotation.keep_number]]
.server.logs.gc.rotation.keep_number
[cols="<1s,<4"]
|===
|Description
a|Number of GC logs to keep.
|Valid values
a|server.logs.gc.rotation.keep_number, an integer
|Default value
m|+++5+++
|===

[[config_server.logs.gc.rotation.size]]
.server.logs.gc.rotation.size
[cols="<1s,<4"]
|===
|Description
a|Size of each GC log that is kept.
|Valid values
a|server.logs.gc.rotation.size, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`)
|Default value
m|+++20.00MiB+++
|===

[[config_server.logs.user.config]]
.server.logs.user.config
[cols="<1s,<4"]
|===
|Description
a|Path to the logging configuration of user logs.
|Valid values
a|server.logs.user.config, a path. If relative it is resolved from server.directories.neo4j_home
|Default value
m|+++conf/user-logs.xml+++
|===

[[config_server.max_databases]]
.server.max_databases
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The maximum number of databases.
|Valid values
a|server.max_databases, a long which is minimum `2`
|Default value
m|+++100+++
|Deprecated
a|The `server.max_databases` configuration setting will be deprecated in favour of <<config_dbms.max_databases,`dbms.max_databases`>> in a future version.
|===

[[config_server.memory.heap.initial_size]]
.server.memory.heap.initial_size
[cols="<1s,<4"]
|===
|Description
a|Initial heap size. By default it is calculated based on available system resources.
|Valid values
a|server.memory.heap.initial_size, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`)
|===

[[config_server.memory.heap.max_size]]
.server.memory.heap.max_size
[cols="<1s,<4"]
|===
|Description
a|Maximum heap size. By default it is calculated based on available system resources.
|Valid values
a|server.memory.heap.max_size, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`)
|===

[[config_server.memory.off_heap.block_cache_size]]
.server.memory.off_heap.block_cache_size
[cols="<1s,<4"]
|===
|Description
a|Defines the size of the off-heap memory blocks cache. The cache will contain this number of blocks for each block size that is power of two. Thus, maximum amount of memory used by blocks cache can be calculated as 2 * <<config_server.memory.off_heap.max_cacheable_block_size,server.memory.off_heap.max_cacheable_block_size>> * `server.memory.off_heap.block_cache_size`
|Valid values
a|server.memory.off_heap.block_cache_size, an integer which is minimum `16`
|Default value
m|+++128+++
|===

[[config_server.memory.off_heap.max_cacheable_block_size]]
.server.memory.off_heap.max_cacheable_block_size
[cols="<1s,<4"]
|===
|Description
a|Defines the maximum size of an off-heap memory block that can be cached to speed up allocations. The value must be a power of 2.
|Valid values
a|server.memory.off_heap.max_cacheable_block_size, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`) which is minimum `4.00KiB` and is power of 2
|Default value
m|+++512.00KiB+++
|===

[[config_server.memory.off_heap.max_size]]
.server.memory.off_heap.max_size
[cols="<1s,<4"]
|===
|Description
a|The maximum amount of off-heap memory that can be used to store transaction state data; it's a total amount of memory shared across all active transactions. Zero means 'unlimited'. Used when <<config_db.tx_state.memory_allocation,db.tx_state.memory_allocation>> is set to 'OFF_HEAP'.
|Valid values
a|server.memory.off_heap.max_size, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`) which is minimum `0B`
|Default value
m|+++2.00GiB+++
|===

[[config_server.memory.pagecache.directio]]
.server.memory.pagecache.directio
[cols="<1s,<4"]
|===
|Description
a|Use direct I/O for page cache. Setting is supported only on Linux and only for a subset of record formats that use platform aligned page size.
|Valid values
a|server.memory.pagecache.directio, a boolean
|Default value
m|+++false+++
|===

[[config_server.memory.pagecache.flush.buffer.enabled]]
.server.memory.pagecache.flush.buffer.enabled
[cols="<1s,<4"]
|===
|Description
a|Page cache can be configured to use a temporal buffer for flushing purposes. It is used to combine, if possible, sequence of several cache pages into one bigger buffer to minimize the number of individual IOPS performed and better utilization of available I/O resources, especially when those are restricted.
|Valid values
a|server.memory.pagecache.flush.buffer.enabled, a boolean
|Dynamic a|true
|Default value
m|+++false+++
|===

[[config_server.memory.pagecache.flush.buffer.size_in_pages]]
.server.memory.pagecache.flush.buffer.size_in_pages
[cols="<1s,<4"]
|===
|Description
a|Page cache can be configured to use a temporal buffer for flushing purposes. It is used to combine, if possible, sequence of several cache pages into one bigger buffer to minimize the number of individual IOPS performed and better utilization of available I/O resources, especially when those are restricted. Use this setting to configure individual file flush buffer size in pages (8KiB). To be able to utilize this buffer during page cache flushing, buffered flush should be enabled.
|Valid values
a|server.memory.pagecache.flush.buffer.size_in_pages, an integer which is in the range `1` to `512`
|Dynamic a|true
|Default value
m|+++128+++
|===

[[config_server.memory.pagecache.scan.prefetchers]]
.server.memory.pagecache.scan.prefetchers
[cols="<1s,<4"]
|===
|Description
a|The maximum number of worker threads to use for pre-fetching data when doing sequential scans. Set to '0' to disable pre-fetching for scans.
|Valid values
a|server.memory.pagecache.scan.prefetchers, an integer which is in the range `0` to `255`
|Default value
m|+++4+++
|===

[[config_server.memory.pagecache.size]]
.server.memory.pagecache.size
[cols="<1s,<4"]
|===
|Description
a|The amount of memory to use for mapping the store files. If Neo4j is running on a dedicated server, then it is generally recommended to leave about 2-4 gigabytes for the operating system, give the JVM enough heap to hold all your transaction state and query context, and then leave the rest for the page cache. If no page cache memory is configured, then a heuristic setting is computed based on available system resources.
|Valid values
a|server.memory.pagecache.size, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`)
|Default value
m|By default the size of page cache will be 50% och available RAM minus the max heap size.The size of the page cache will also not be larger than 70x the max heap size (due to some overhead of the page cache in the heap.
|===

[[config_server.metrics.csv.enabled]]
.server.metrics.csv.enabled
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Set to `true` to enable exporting metrics to CSV files.
|Valid values
a|server.metrics.csv.enabled, a boolean
|Default value
m|+++true+++
|===

[[config_server.metrics.csv.interval]]
.server.metrics.csv.interval
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The reporting interval for the CSV files. That is, how often new rows with numbers are appended to the CSV files.
|Valid values
a|server.metrics.csv.interval, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`) which is minimum `1ms`
|Default value
m|+++30s+++
|===

[[config_server.metrics.csv.rotation.compression]]
.server.metrics.csv.rotation.compression
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Decides what compression to use for the csv history files.
|Valid values
a|server.metrics.csv.rotation.compression, one of [NONE, ZIP, GZ]
|Default value
m|+++NONE+++
|===

[[config_server.metrics.csv.rotation.keep_number]]
.server.metrics.csv.rotation.keep_number
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Maximum number of history files for the csv files.
|Valid values
a|server.metrics.csv.rotation.keep_number, an integer which is minimum `1`
|Default value
m|+++7+++
|===

[[config_server.metrics.csv.rotation.size]]
.server.metrics.csv.rotation.size
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The file size in bytes at which the csv files will auto-rotate. If set to zero then no rotation will occur. Accepts a binary suffix `k`, `m` or `g`.
|Valid values
a|server.metrics.csv.rotation.size, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`) which is in the range `0B` to `8388608.00TiB`
|Default value
m|+++10.00MiB+++
|===

[[config_server.metrics.enabled]]
.server.metrics.enabled
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Enable metrics. Setting this to `false` will to turn off all metrics.
|Valid values
a|server.metrics.enabled, a boolean
|Default value
m|+++true+++
|===

[[config_server.metrics.filter]]
.server.metrics.filter
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Specifies which metrics should be enabled by using a comma separated list of globbing patterns. Only the metrics matching the filter will be enabled. For example `\*check_point*,neo4j.page_cache.evictions` will enable any checkpoint metrics and the pagecache eviction metric.
|Valid values
a|server.metrics.filter, a ',' separated list with elements of type 'A simple globbing pattern that can use `*` and `?`.'.
|Default value
m|+++*bolt.connections*,*bolt.messages_received*,*bolt.messages_started*,*dbms.pool.bolt.free,*dbms.pool.bolt.total_size,*dbms.pool.bolt.total_used,*dbms.pool.bolt.used_heap,*cluster.core.is_leader,*cluster.core.last_leader_message,*cluster.core.replication_attempt,*cluster.core.replication_fail,*cluster.core.last_applied,*cluster.core.last_appended,*check_point.duration,*check_point.total_time,*cypher.replan_events,*ids_in_use*,*pool.transaction.*.total_used,*pool.transaction.*.used_heap,*pool.transaction.*.used_native,*store.size*,*transaction.active_read,*transaction.active_write,*transaction.committed*,*transaction.last_committed_tx_id,*transaction.peak_concurrent,*transaction.rollbacks*,*page_cache.hit*,*page_cache.page_faults,*page_cache.usage_ratio,*vm.file.descriptors.count,*vm.gc.time.*,*vm.heap.used,*vm.memory.buffer.direct.used,*vm.memory.pool.g1_eden_space,*vm.memory.pool.g1_old_gen,*vm.pause_time,*vm.thread*,*db.query.execution*+++
|===

[[config_server.metrics.graphite.enabled]]
.server.metrics.graphite.enabled
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Set to `true` to enable exporting metrics to Graphite.
|Valid values
a|server.metrics.graphite.enabled, a boolean
|Default value
m|+++false+++
|===

[[config_server.metrics.graphite.interval]]
.server.metrics.graphite.interval
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The reporting interval for Graphite. That is, how often to send updated metrics to Graphite.
|Valid values
a|server.metrics.graphite.interval, a duration (Valid units are: `ns`, `μs`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++30s+++
|===

[[config_server.metrics.graphite.server]]
.server.metrics.graphite.server
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The hostname or IP address of the Graphite server.
|Valid values
a|server.metrics.graphite.server, a socket address in the format 'hostname:port', 'hostname' or ':port'. If missing port or hostname it is acquired from server.default_listen_address
|Default value
m|+++:2003+++
|===

[[config_server.metrics.jmx.enabled]]
.server.metrics.jmx.enabled
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Set to `true` to enable the JMX metrics endpoint.
|Valid values
a|server.metrics.jmx.enabled, a boolean
|Default value
m|+++true+++
|===

[[config_server.metrics.prefix]]
.server.metrics.prefix
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]A common prefix for the reported metrics field names.
|Valid values
a|server.metrics.prefix, a string
|Default value
m|+++neo4j+++
|===

[[config_server.metrics.prometheus.enabled]]
.server.metrics.prometheus.enabled
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]Set to `true` to enable the Prometheus endpoint.
|Valid values
a|server.metrics.prometheus.enabled, a boolean
|Default value
m|+++false+++
|===

[[config_server.metrics.prometheus.endpoint]]
.server.metrics.prometheus.endpoint
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The hostname and port to use as Prometheus endpoint.
|Valid values
a|server.metrics.prometheus.endpoint, a socket address in the format 'hostname:port', 'hostname' or ':port'. If missing port or hostname it is acquired from server.default_listen_address
|Default value
m|+++localhost:2004+++
|===

[[config_server.panic.shutdown_on_panic]]
.server.panic.shutdown_on_panic
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]If there is a Database Management System Panic (an irrecoverable error) should the neo4j process shut down or continue running. Following a DbMS panic it is likely that a significant amount of functionality will be lost. Recovering full functionality will require a Neo4j restart. This feature is available in Neo4j Enterprise Edition.
|Valid values
a|server.panic.shutdown_on_panic, a boolean
|Default value
m|`false` except for Neo4j Enterprise Edition deployments running on Kubernetes where it is `true`.
|===

[[config_server.routing.advertised_address]]
.server.routing.advertised_address
[cols="<1s,<4"]
|===
|Description
a|label:enterprise-edition[Enterprise only]The advertised address for the intra-cluster routing connector.
|Valid values
a|server.routing.advertised_address, a socket address in the format 'hostname:port', 'hostname' or ':port' which accessible address. If missing port or hostname it is acquired from server.default_advertised_address
|Default value
m|+++:7688+++
|===

[[config_server.routing.listen_address]]
.server.routing.listen_address
[cols="<1s,<4"]
|===
|Description
a|The address the routing connector should bind to.
|Valid values
a|server.routing.listen_address, a socket address in the format 'hostname:port', 'hostname' or ':port'. If missing port or hostname it is acquired from server.default_listen_address
|Default value
m|+++:7688+++
|===

[[config_server.threads.worker_count]]
.server.threads.worker_count
[cols="<1s,<4"]
|===
|Description
a|Number of Neo4j worker threads. This setting is only valid for REST, and does not influence bolt-server. It sets the amount of worker threads for the Jetty server used by neo4j-server. This option can be tuned when you plan to execute multiple, concurrent REST requests, with the aim of getting more throughput from the database. Your OS might enforce a lower limit than the maximum value specified here.
|Valid values
a|server.threads.worker_count, an integer which is in the range `1` to `44738`
|Default value
m|Number of available processors, or 500 for machines which have more than 500 processors.
|===

[[config_server.unmanaged_extension_classes]]
.server.unmanaged_extension_classes
[cols="<1s,<4"]
|===
|Description
a|Comma-separated list of <classname>=<mount point> for unmanaged extensions.
|Valid values
a|server.unmanaged_extension_classes, a ',' separated list with elements of type '<classname>=<mount point> string'.
|Default value
m|++++++
|===

[[config_server.windows_service_name]]
.server.windows_service_name
[cols="<1s,<4"]
|===
|Description
a|Name of the Windows Service managing Neo4j when installed using `neo4j install-service`. Only applicable on Windows OS. Note: This must be unique for each individual installation.
|Valid values
a|server.windows_service_name, a string
|Default value
m|+++neo4j+++
|===
