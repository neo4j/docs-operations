// tag::settings-reference-internal-settings[]
[[settings-reference-internal-settings]]
.Internal settings
ifndef::nonhtmloutput[]
[options="header"]
|===
|Name|Description
|<<internal_causal_clustering.akka_actor_system_restarter.initial_delay,causal_clustering.akka_actor_system_restarter.initial_delay>>|Initial retry interval for akka restarter (which uses exponential backoff if it fails).
|<<internal_causal_clustering.akka_actor_system_restarter.max_acceptable_failures,causal_clustering.akka_actor_system_restarter.max_acceptable_failures>>|Maximum number of akka restart attempts before we panic the DBMS.
|<<internal_causal_clustering.akka_actor_system_restarter.max_delay,causal_clustering.akka_actor_system_restarter.max_delay>>|Maximum retry interval for akka restarter (which uses exponential backoff if it fails).
|<<internal_causal_clustering.cluster_binding_retry_timeout,causal_clustering.cluster_binding_retry_timeout>>|Configures the time after which we retry binding to a cluster.
|<<internal_causal_clustering.cluster_id_publish_timeout,causal_clustering.cluster_id_publish_timeout>>|Configures the time taken attempting to publish a cluster id to the discovery service before potentially retrying.
|<<internal_causal_clustering.cluster_info_polling_max_wait,causal_clustering.cluster_info_polling_max_wait>>|Maximum time a polling request in the DatabaseInfoService will try before giving up.
|<<internal_causal_clustering.discovery_resolution_retry_interval,causal_clustering.discovery_resolution_retry_interval>>|The polling interval when attempting to resolve initial_discovery_members from DNS and SRV records.
|<<internal_causal_clustering.discovery_resolution_timeout,causal_clustering.discovery_resolution_timeout>>|Configures the time after which we give up trying to resolve a DNS/SRV record into a list of initial discovery members.
|<<internal_causal_clustering.enable_seed_validation,causal_clustering.enable_seed_validation>>|Enable validation of seeds.
|<<internal_causal_clustering.leader_transfer_interval,causal_clustering.leader_transfer_interval>>|The frequency with which a leader will try and transfer leadership to another member.
|<<internal_causal_clustering.leader_transfer_member_backoff,causal_clustering.leader_transfer_member_backoff>>|The amount of time we should wait before repeating an attempt to transfer the leadership of a given database to a member after that member rejects a previous transfer.
|<<internal_causal_clustering.leader_transfer_timeout,causal_clustering.leader_transfer_timeout>>|The time limit within which a leadership transfer request should be completed, otherwise the leader will resume accepting writes.
|<<internal_causal_clustering.max_commits_delay_id_reuse,causal_clustering.max_commits_delay_id_reuse>>|Maximum number of transactions to delay reuse of a deleted ID.
|<<internal_causal_clustering.max_time_delay_id_reuse,causal_clustering.max_time_delay_id_reuse>>|Maximum time to delay reuse of a deleted ID.
|<<internal_causal_clustering.middleware.akka.allow_any_core_to_bootstrap,causal_clustering.middleware.akka.allow_any_core_to_bootstrap>>|If the initial seed node cannot be found attempt to bootstrap with other cores.
|<<internal_causal_clustering.middleware.akka.bind_timeout,causal_clustering.middleware.akka.bind_timeout>>|Timeout for Akka socket binding.
|<<internal_causal_clustering.middleware.akka.cluster.min_nr_of_members,causal_clustering.middleware.akka.cluster.min_nr_of_members>>|Number of cores required for initial Akka cluster formation.
|<<internal_causal_clustering.middleware.akka.cluster.seed_node_timeout,causal_clustering.middleware.akka.cluster.seed_node_timeout>>|Time that seed nodes will spend trying to find an existing cluster before forming a new cluster.
|<<internal_causal_clustering.middleware.akka.cluster.seed_node_timeout_on_first_start,causal_clustering.middleware.akka.cluster.seed_node_timeout_on_first_start>>|Time that seed nodes will spend trying to find an existing cluster before forming a new cluster, when Neo4j is started for the first time.
|<<internal_causal_clustering.middleware.akka.connection_timeout,causal_clustering.middleware.akka.connection_timeout>>|Timeout for Akka connection.
|<<internal_causal_clustering.middleware.akka.default_parallelism,causal_clustering.middleware.akka.default_parallelism>>|Parallelism level of default dispatcher used by Akka based cluster topology discovery, including cluster, replicator, and discovery actors.
|<<internal_causal_clustering.middleware.akka.down_unreachable_on_new_joiner,causal_clustering.middleware.akka.down_unreachable_on_new_joiner>>|Allows a core to down all unreachable members if it needs to do that to allow a new core to join.
|<<internal_causal_clustering.middleware.akka.external_config,causal_clustering.middleware.akka.external_config>>|External config file for Akka.
|<<internal_causal_clustering.middleware.akka.failure_detector.acceptable_heartbeat_pause,causal_clustering.middleware.akka.failure_detector.acceptable_heartbeat_pause>>|Akka cluster phi accrual failure detector.
|<<internal_causal_clustering.middleware.akka.failure_detector.expected_response_after,causal_clustering.middleware.akka.failure_detector.expected_response_after>>|Akka cluster phi accrual failure detector.
|<<internal_causal_clustering.middleware.akka.failure_detector.heartbeat_interval,causal_clustering.middleware.akka.failure_detector.heartbeat_interval>>|Akka cluster phi accrual failure detector.
|<<internal_causal_clustering.middleware.akka.failure_detector.max_sample_size,causal_clustering.middleware.akka.failure_detector.max_sample_size>>|Akka cluster phi accrual failure detector.
|<<internal_causal_clustering.middleware.akka.failure_detector.min_std_deviation,causal_clustering.middleware.akka.failure_detector.min_std_deviation>>|Akka cluster phi accrual failure detector.
|<<internal_causal_clustering.middleware.akka.failure_detector.monitored_by_nr_of_members,causal_clustering.middleware.akka.failure_detector.monitored_by_nr_of_members>>|Akka cluster phi accrual failure detector.
|<<internal_causal_clustering.middleware.akka.failure_detector.threshold,causal_clustering.middleware.akka.failure_detector.threshold>>|Akka cluster phi accrual failure detector.
|<<internal_causal_clustering.middleware.akka.handshake_timeout,causal_clustering.middleware.akka.handshake_timeout>>|Timeout for Akka handshake.
|<<internal_causal_clustering.middleware.akka.shutdown_timeout,causal_clustering.middleware.akka.shutdown_timeout>>|Maximum timeout for akka shutdown.
|<<internal_causal_clustering.middleware.akka.sink_parallelism,causal_clustering.middleware.akka.sink_parallelism>>|Parallelism level of dispatcher used for communication from Akka based cluster topology discovery.
|<<internal_causal_clustering.min_time_delay_id_reuse,causal_clustering.min_time_delay_id_reuse>>|Minimum time to delay reuse of a deleted ID.
|<<internal_causal_clustering.raft_group_graveyard_state_size,causal_clustering.raft_group_graveyard_state_size>>|The maximum file size before the raft group graveyard state file is rotated (in unit of entries).
|<<internal_causal_clustering.raft_in_queue_max_batch,causal_clustering.raft_in_queue_max_batch>>|Largest batch processed by RAFT in number of entries.
|<<internal_causal_clustering.raft_in_queue_size,causal_clustering.raft_in_queue_size>>|Maximum number of entries in the RAFT in-queue.
|<<internal_causal_clustering.raft_messages_log_enable,causal_clustering.raft_messages_log_enable>>|Enable or disable the dump of all network messages pertaining to the RAFT protocol.
|<<internal_causal_clustering.raft_messages_log_path,causal_clustering.raft_messages_log_path>>|Path to RAFT messages log.
|<<internal_causal_clustering.read_replica_transaction_applier_batch_size,causal_clustering.read_replica_transaction_applier_batch_size>>|Threshold in Mb for when a downloaded batch of transactions for a read replicas should be incrementally applied.
|<<internal_causal_clustering.read_replica_transaction_applier_max_queue_size,causal_clustering.read_replica_transaction_applier_max_queue_size>>|Maximum queued size of transactions in Mb to be applied.
|<<internal_causal_clustering.seed_validation_timeout,causal_clustering.seed_validation_timeout>>|Specifies how long the seeding validation is allowed to keep trying to validate against remote before giving up.
|<<internal_causal_clustering.store_copy_backoff_max_wait,causal_clustering.store_copy_backoff_max_wait>>|Maximum backoff timeout for store copy requests.
|<<internal_causal_clustering.store_size_service_cache_timeout,causal_clustering.store_size_service_cache_timeout>>|Timeout for database store size values stored in the cache.
|<<internal_causal_clustering.temporary_database.extension_package_names,causal_clustering.temporary_database.extension_package_names>>|Once temporary database is created, this parameter defines what extensions are loaded based on the package names.
|<<internal_causal_clustering.topology_graph.default_num_primaries,causal_clustering.topology_graph.default_num_primaries>>|Default number of primaries in Large Cluster.
|<<internal_causal_clustering.topology_graph.default_num_secondaries,causal_clustering.topology_graph.default_num_secondaries>>|Default number of secondaries in Large Cluster.
|<<internal_causal_clustering.use_native_transport,causal_clustering.use_native_transport>>|Use native transport if available.
|<<internal_dbms.capabilities.blocked,dbms.capabilities.blocked>>|List of capabilities to block access from capabilities API or procedures.
|<<internal_dbms.connector.bolt.tcp_keep_alive,dbms.connector.bolt.tcp_keep_alive>>|Enable TCP keep alive probes on this connector.
|<<internal_dbms.connector.bolt.unsupported_thread_pool_queue_size,dbms.connector.bolt.unsupported_thread_pool_queue_size>>|The queue size of the thread pool bound to this connector (-1 for unbounded, 0 for direct handoff, > 0 for bounded).
|<<internal_dbms.connector.bolt.unsupported_unauth_connection_timeout,dbms.connector.bolt.unsupported_unauth_connection_timeout>>|The maximum time to wait for a user to finish authentication before closing the connection.
|<<internal_dbms.connector.bolt.unsupported_unauth_max_inbound_bytes,dbms.connector.bolt.unsupported_unauth_max_inbound_bytes>>|The maximum inbound message size in bytes are allowed before a connection is authenticated.
|<<internal_dbms.directories.tx_log,dbms.directories.tx_log>>|Location where Neo4j keeps the logical transaction logs.
|<<internal_dbms.init_file,dbms.init_file>>|Name of file containing commands to be run during initialization of the system database.
|<<internal_dbms.log_inconsistent_data_deletion,dbms.log_inconsistent_data_deletion>>|Whether or not to log contents of data that is inconsistent when deleting it.
|<<internal_dbms.routing.driver.event_loop_count,dbms.routing.driver.event_loop_count>>|Number of event loops used by drivers.
|<<internal_dbms.routing.driver.idle_check_interval,dbms.routing.driver.idle_check_interval>>|Time interval between driver idleness check.
|<<internal_dbms.routing.driver.logging.leaked_sessions,dbms.routing.driver.logging.leaked_sessions>>|Enables logging of leaked driver session.
|<<internal_dbms.routing.driver.timeout,dbms.routing.driver.timeout>>|Time interval of inactivity after which a driver will be closed.
|<<internal_dbms.security.property_level.blacklist,dbms.security.property_level.blacklist>>|This can be achieved with `DENY READ {property} ON GRAPH * ELEMENTS * TO role`.
|<<internal_dbms.security.property_level.enabled,dbms.security.property_level.enabled>>|This has been replaced by privilege management on roles.
|<<internal_fabric.driver.event_loop_count,fabric.driver.event_loop_count>>|Number of event loops used by drivers.
|<<internal_fabric.driver.idle_check_interval,fabric.driver.idle_check_interval>>|Time interval between driver idleness check.
|<<internal_fabric.driver.logging.leaked_sessions,fabric.driver.logging.leaked_sessions>>|Enables logging of leaked driver session.
|<<internal_fabric.driver.timeout,fabric.driver.timeout>>|Time interval of inactivity after which a driver will be closed.
|<<internal_fabric.enabled_by_default,fabric.enabled_by_default>>|Toggle if fabric is enabled by default.
|<<internal_fabric.stream.batch_size,fabric.stream.batch_size>>|Batch size used when requesting records from local Cypher engine.
|<<internal_unsupported.causal_clustering.cluster_status_request_maximum_wait,unsupported.causal_clustering.cluster_status_request_maximum_wait>>|Maximum timeout for cluster status request execution.
|<<internal_unsupported.causal_clustering.experimental_catchup_protocol_enabled,unsupported.causal_clustering.experimental_catchup_protocol_enabled>>|Usage of an experimental catchup protocol.
|<<internal_unsupported.causal_clustering.experimental_raft_protocol_enabled,unsupported.causal_clustering.experimental_raft_protocol_enabled>>|Usage of an experimental raft protocol.
|<<internal_unsupported.causal_clustering.inbound_connection_initialization_logging_enabled,unsupported.causal_clustering.inbound_connection_initialization_logging_enabled>>|Enable logging for inbound connection initialization.
|<<internal_unsupported.consistency_checker.fail_fast_threshold,unsupported.consistency_checker.fail_fast_threshold>>|Specifies if the consistency checker should stop when number of observed inconsistencies exceed the threshold.
|<<internal_unsupported.consistency_checker.memory_limit_factor,unsupported.consistency_checker.memory_limit_factor>>|Limits the maximum amount of off-heap memory the consistency checker will allocate.
|<<internal_unsupported.cypher.compiler_tracing,unsupported.cypher.compiler_tracing>>|Enable tracing of compilation in cypher.
|<<internal_unsupported.cypher.enable_extra_semantic_features,unsupported.cypher.enable_extra_semantic_features>>|Enables extra SemanticFeature:s during cypher semantic checking.
|<<internal_unsupported.cypher.enable_runtime_monitors,unsupported.cypher.enable_runtime_monitors>>|Set this to enable monitors in the Cypher runtime.
|<<internal_unsupported.cypher.expression_engine,unsupported.cypher.expression_engine>>|Choose the expression engine.
|<<internal_unsupported.cypher.expression_recompilation_limit,unsupported.cypher.expression_recompilation_limit>>|Number of uses before an expression is considered for compilation.
|<<internal_unsupported.cypher.idp_solver_duration_threshold,unsupported.cypher.idp_solver_duration_threshold>>|To improve IDP query planning time, we can restrict the internal planning loop duration, triggering more frequent compaction of candidate plans.
|<<internal_unsupported.cypher.idp_solver_table_threshold,unsupported.cypher.idp_solver_table_threshold>>|To improve IDP query planning time, we can restrict the internal planning table size, triggering compaction of candidate plans.
|<<internal_unsupported.cypher.non_indexed_label_warning_threshold,unsupported.cypher.non_indexed_label_warning_threshold>>|The threshold when a warning is generated if a label scan is done after a load csv where the label has no index.
|<<internal_unsupported.cypher.number_of_workers,unsupported.cypher.number_of_workers>>|Number of threads to allocate to Cypher worker threads for the parallel runtime.
|<<internal_unsupported.cypher.parser,unsupported.cypher.parser>>|The parser implementation to use for parsing cypher queries.
|<<internal_unsupported.cypher.pipelined.batch_size_big,unsupported.cypher.pipelined.batch_size_big>>|The size of batches in the pipelined runtime for queries which work with many rows.
|<<internal_unsupported.cypher.pipelined.batch_size_small,unsupported.cypher.pipelined.batch_size_small>>|The size of batches in the pipelined runtime for queries which work with few rows.
|<<internal_unsupported.cypher.pipelined.enable_runtime_trace,unsupported.cypher.pipelined.enable_runtime_trace>>|Enable tracing of pipelined runtime scheduler.
|<<internal_unsupported.cypher.pipelined.operator_engine,unsupported.cypher.pipelined.operator_engine>>|For compiled execution, specialized code is generated and then executed.
|<<internal_unsupported.cypher.pipelined.operator_fusion_over_pipeline_limit,unsupported.cypher.pipelined.operator_fusion_over_pipeline_limit>>|The maximum number of operator fusions over pipelines (i.e.
|<<internal_unsupported.cypher.pipelined.runtime_trace_path,unsupported.cypher.pipelined.runtime_trace_path>>|Path to the pipelined runtime scheduler trace.
|<<internal_unsupported.cypher.pipelined_interpreted_pipes_fallback,unsupported.cypher.pipelined_interpreted_pipes_fallback>>|Use interpreted pipes as a fallback for operators that do not have a specialized implementation in the pipelined runtime.
|<<internal_unsupported.cypher.planning_point_indexes_enabled,unsupported.cypher.planning_point_indexes_enabled>>|Feature flag to enable/disable planning use of point indexes.
|<<internal_unsupported.cypher.planning_range_indexes_enabled,unsupported.cypher.planning_range_indexes_enabled>>|Feature flag to enable/disable planning use of range indexes.
|<<internal_unsupported.cypher.planning_text_indexes_enabled,unsupported.cypher.planning_text_indexes_enabled>>|Feature flag to enable/disable planning use of text indexes.
|<<internal_unsupported.cypher.predicates_as_union_max_size,unsupported.cypher.predicates_as_union_max_size>>|Maximum size after which the planner will not attempt to plan the disjunction of predicates on a single variable as a distinct union.For example, given the following pattern: `()-[e:FOO|BAR|BAZ]->()`, the planner will attempt to plan a union of `e:Foo`, `e:Bar`, and `e:Baz`unless `unsupported.cypher.predicates_as_union_max_size` is less than 3.
|<<internal_unsupported.cypher.replan_algorithm,unsupported.cypher.replan_algorithm>>|Large databases might change slowly, and to prevent queries from never being replanned the divergence threshold set by cypher.statistics_divergence_threshold is configured to shrink over time using the algorithm set here.
|<<internal_unsupported.cypher.runtime,unsupported.cypher.runtime>>|Set this to specify the default runtime for the default language version.
|<<internal_unsupported.cypher.splitting_top_behavior,unsupported.cypher.splitting_top_behavior>>|Determines whether the planner is allowed to push down the sort portion of an ORDER BY + LIMIT combination.
|<<internal_unsupported.cypher.statistics_divergence_target,unsupported.cypher.statistics_divergence_target>>|Large databases might change slowly, and so to prevent queries from never being replanned the divergence threshold set by cypher.statistics_divergence_threshold is configured to shrink over time.
|<<internal_unsupported.cypher.target_replan_interval,unsupported.cypher.target_replan_interval>>|Large databases might change slowly, and to prevent queries from never being replanned the divergence threshold set by cypher.statistics_divergence_threshold is configured to shrink over time.
|<<internal_unsupported.datacollector.max_query_text_size,unsupported.datacollector.max_query_text_size>>|Sets the upper limit for how much of the query text that will be retained by the query collector.
|<<internal_unsupported.datacollector.max_recent_query_count,unsupported.datacollector.max_recent_query_count>>|Max number of recent queries to collect in the data collector module.
|<<internal_unsupported.dbms.block_alter_database,unsupported.dbms.block_alter_database>>|Enable or disable the ability to alter databases.
|<<internal_unsupported.dbms.block_create_drop_database,unsupported.dbms.block_create_drop_database>>|Enable or disable the ability to create and drop databases.
|<<internal_unsupported.dbms.block_remote_alias,unsupported.dbms.block_remote_alias>>|Enable or disable the ability to use remote aliases.
|<<internal_unsupported.dbms.block_size.array_properties,unsupported.dbms.block_size.array_properties>>|Specifies the block size for storing arrays.
|<<internal_unsupported.dbms.block_size.labels,unsupported.dbms.block_size.labels>>|Specifies the block size for storing labels exceeding in-lined space in node record.
|<<internal_unsupported.dbms.block_size.strings,unsupported.dbms.block_size.strings>>|Specifies the block size for storing strings.
|<<internal_unsupported.dbms.block_start_stop_database,unsupported.dbms.block_start_stop_database>>|Enable or disable the ability to start and stop databases.
|<<internal_unsupported.dbms.bolt.inbound_message_throttle.high_watermark,unsupported.dbms.bolt.inbound_message_throttle.high_watermark>>|When the number of queued inbound messages grows beyond this value, reading from underlying channel will be paused (no more inbound messages will be available) until queued number of messages drops below the configured low watermark value.
|<<internal_unsupported.dbms.bolt.inbound_message_throttle.low_watermark,unsupported.dbms.bolt.inbound_message_throttle.low_watermark>>|When the number of queued inbound messages, previously reached configured high watermark value, drops below this value, reading from underlying channel will be enabled and any pending messages will start queuing again.
|<<internal_unsupported.dbms.bolt.netty_message_merge_cumulator,unsupported.dbms.bolt.netty_message_merge_cumulator>>|Enable/disable the use of a merge cumulator for netty.
|<<internal_unsupported.dbms.bolt.netty_server_shutdown_quiet_period,unsupported.dbms.bolt.netty_server_shutdown_quiet_period>>|Quiet period for netty shutdown.
|<<internal_unsupported.dbms.bolt.netty_server_shutdown_timeout,unsupported.dbms.bolt.netty_server_shutdown_timeout>>|Timeout for netty shutdown.
|<<internal_unsupported.dbms.bolt.netty_server_use_epoll,unsupported.dbms.bolt.netty_server_use_epoll>>|Enable/disable the use of Epoll for netty.
|<<internal_unsupported.dbms.bolt.outbound_buffer_throttle,unsupported.dbms.bolt.outbound_buffer_throttle>>|Whether to apply network level outbound network buffer based throttling.
|<<internal_unsupported.dbms.bolt.outbound_buffer_throttle.high_watermark,unsupported.dbms.bolt.outbound_buffer_throttle.high_watermark>>|When the size (in bytes) of outbound network buffers, used by bolt's network layer, grows beyond this value bolt channel will advertise itself as unwritable and will block related processing thread until it becomes writable again.
|<<internal_unsupported.dbms.bolt.outbound_buffer_throttle.low_watermark,unsupported.dbms.bolt.outbound_buffer_throttle.low_watermark>>|When the size (in bytes) of outbound network buffers, previously advertised as unwritable, gets below this value bolt channel will re-advertise itself as writable and blocked processing thread will resume execution.
|<<internal_unsupported.dbms.bolt.outbound_buffer_throttle.max_duration,unsupported.dbms.bolt.outbound_buffer_throttle.max_duration>>|When the total time outbound network buffer based throttle lock is held exceeds this value, the corresponding bolt channel will be aborted.
|<<internal_unsupported.dbms.checkpoint_log.rotation.keep.files,unsupported.dbms.checkpoint_log.rotation.keep.files>>|Number of checkpoint logs files to keep.
|<<internal_unsupported.dbms.checkpoint_log.rotation.size,unsupported.dbms.checkpoint_log.rotation.size>>|Specifies at which file size the checkpoint log will auto-rotate.
|<<internal_unsupported.dbms.config.command_evaluation_timeout,unsupported.dbms.config.command_evaluation_timeout>>|Timeout for configuration command evaluation, per command.
|<<internal_unsupported.dbms.counts_store_rotation_timeout,unsupported.dbms.counts_store_rotation_timeout>>|Maximum time to wait for active transaction completion when rotating counts store.
|<<internal_unsupported.dbms.cypher_ip_blocklist,unsupported.dbms.cypher_ip_blocklist>>|A list of CIDR-notation IPv4 or IPv6 addresses to block when accessing URLs.This list is checked when LOAD CSV or apoc.load.json is called.
|<<internal_unsupported.dbms.debug.page_cache_tracer_speed_reporting_threshold,unsupported.dbms.debug.page_cache_tracer_speed_reporting_threshold>>|Reporting interval for page cache speed logging.
|<<internal_unsupported.dbms.debug.print_page_buffer_allocation_trace,unsupported.dbms.debug.print_page_buffer_allocation_trace>>|Print stack trace on failed native io buffer allocation.
|<<internal_unsupported.dbms.debug.trace_cursors,unsupported.dbms.debug.trace_cursors>>|Trace unclosed cursors.
|<<internal_unsupported.dbms.debug.trace_tx_statement,unsupported.dbms.debug.trace_tx_statement>>|Trace open/close transaction statements.
|<<internal_unsupported.dbms.debug.track_cursor_close,unsupported.dbms.debug.track_cursor_close>>|Validate if cursors are properly closed.
|<<internal_unsupported.dbms.debug.track_tx_statement_close,unsupported.dbms.debug.track_tx_statement_close>>|Validate if transaction statements are properly closed.
|<<internal_unsupported.dbms.directories.auth,unsupported.dbms.directories.auth>>|Location of the auth store repository directory.
|<<internal_unsupported.dbms.directories.databases.root,unsupported.dbms.directories.databases.root>>|Path of the databases directory.
|<<internal_unsupported.dbms.directories.pid_file,unsupported.dbms.directories.pid_file>>|Path of the pid file.
|<<internal_unsupported.dbms.directories.scripts,unsupported.dbms.directories.scripts>>|Location of the database scripts directory.
|<<internal_unsupported.dbms.directories.windows_tools,unsupported.dbms.directories.windows_tools>>|Path of the lib directory.
|<<internal_unsupported.dbms.discoverable_bolt_address,unsupported.dbms.discoverable_bolt_address>>|Publicly discoverable bolt:// URI to use for Neo4j Drivers wanting to access the data in this particular database instance.
|<<internal_unsupported.dbms.discoverable_bolt_routing_address,unsupported.dbms.discoverable_bolt_routing_address>>|Publicly discoverable neo4j:// URI to use for Neo4j Drivers wanting to access a cluster or a single instance.
|<<internal_unsupported.dbms.dump_diagnostics,unsupported.dbms.dump_diagnostics>>|Whether or not to dump system and database diagnostics.
|<<internal_unsupported.dbms.enable_transaction_heap_allocation_tracking,unsupported.dbms.enable_transaction_heap_allocation_tracking>>|Track heap memory allocations for transactions.
|<<internal_unsupported.dbms.executiontime_limit.time,unsupported.dbms.executiontime_limit.time>>|If execution time limiting is enabled in the database, this configures the maximum request execution time.
|<<internal_unsupported.dbms.extra_lock_verification,unsupported.dbms.extra_lock_verification>>|Whether or not to do additional checks for locks when making changes as part of commit.
|<<internal_unsupported.dbms.force_small_id_cache,unsupported.dbms.force_small_id_cache>>|Forces smaller ID cache, in order to preserve memory.
|<<internal_unsupported.dbms.http_paths_blacklist,unsupported.dbms.http_paths_blacklist>>|Defines a blacklist of http paths that should not be accessed.
|<<internal_unsupported.dbms.idgenerator.log.enabled,unsupported.dbms.idgenerator.log.enabled>>|Enable/disable logging for the id generator.
|<<internal_unsupported.dbms.idgenerator.log.prune_threshold,unsupported.dbms.idgenerator.log.prune_threshold>>|Log file prune threshold for id generator logging.
|<<internal_unsupported.dbms.idgenerator.log.rotation_threshold,unsupported.dbms.idgenerator.log.rotation_threshold>>|Log file rotation threshold for id generator logging.
|<<internal_unsupported.dbms.index.archive_failed,unsupported.dbms.index.archive_failed>>|Create an archive of an index before re-creating it if failing to load on startup.
|<<internal_unsupported.dbms.index.default_fulltext_provider,unsupported.dbms.index.default_fulltext_provider>>|The default index provider used for managing full-text indexes.
|<<internal_unsupported.dbms.index.lucene.merge_factor,unsupported.dbms.index.lucene.merge_factor>>|Setting for the matching lucene IndexWriterConfig config.
|<<internal_unsupported.dbms.index.lucene.min_merge,unsupported.dbms.index.lucene.min_merge>>|Setting for the matching lucene IndexWriterConfig config.
|<<internal_unsupported.dbms.index.lucene.nocfs.ratio,unsupported.dbms.index.lucene.nocfs.ratio>>|Setting for the matching lucene IndexWriterConfig config.
|<<internal_unsupported.dbms.index.lucene.population_max_buffered_docs,unsupported.dbms.index.lucene.population_max_buffered_docs>>|Setting for the matching lucene IndexWriterConfig config.
|<<internal_unsupported.dbms.index.lucene.population_ram_buffer_size,unsupported.dbms.index.lucene.population_ram_buffer_size>>|Setting for the matching lucene IndexWriterConfig config.
|<<internal_unsupported.dbms.index.lucene.standard_ram_buffer_size,unsupported.dbms.index.lucene.standard_ram_buffer_size>>|Setting for the matching lucene IndexWriterConfig config.
|<<internal_unsupported.dbms.index.lucene.writer_max_buffered_docs,unsupported.dbms.index.lucene.writer_max_buffered_docs>>|Setting for the matching lucene IndexWriterConfig config.
|<<internal_unsupported.dbms.index.population_batch_max_byte_size,unsupported.dbms.index.population_batch_max_byte_size>>|Max size for an index population batch.
|<<internal_unsupported.dbms.index.population_print_debug,unsupported.dbms.index.population_print_debug>>|Printing debug information on index population.
|<<internal_unsupported.dbms.index.population_queue_threshold,unsupported.dbms.index.population_queue_threshold>>|Queue size for index population batched updates.
|<<internal_unsupported.dbms.index.populator_block_size,unsupported.dbms.index.populator_block_size>>|Block/buffer size for index population.
|<<internal_unsupported.dbms.index.populator_merge_factor,unsupported.dbms.index.populator_merge_factor>>|Merge factory for index population.
|<<internal_unsupported.dbms.index.sampling.async_recovery,unsupported.dbms.index.sampling.async_recovery>>|Enable asynchronous index sample recovery.
|<<internal_unsupported.dbms.index.sampling.async_recovery_wait,unsupported.dbms.index.sampling.async_recovery_wait>>|Wait for asynchronous index sample recovery to finish.
|<<internal_unsupported.dbms.index.sampling.log_recovered_samples,unsupported.dbms.index.sampling.log_recovered_samples>>|Logging information about recovered index samples.
|<<internal_unsupported.dbms.index.skip_default_indexes_on_creation,unsupported.dbms.index.skip_default_indexes_on_creation>>|If 'true', new database will be created without token indexes for labels and relationships.
|<<internal_unsupported.dbms.index.spatial.curve.bottom_threshold,unsupported.dbms.index.spatial.curve.bottom_threshold>>|When searching the spatial index we need to convert a 2D range in the quad tree into a set of 1D ranges on the underlying 1D space filling curve index.
|<<internal_unsupported.dbms.index.spatial.curve.extra_levels,unsupported.dbms.index.spatial.curve.extra_levels>>|When searching the spatial index we need to convert a 2D range in the quad tree into a set of 1D ranges on the underlying 1D space filling curve index.
|<<internal_unsupported.dbms.index.spatial.curve.top_threshold,unsupported.dbms.index.spatial.curve.top_threshold>>|When searching the spatial index we need to convert a 2D range in the quad tree into a set of 1D ranges on the underlying 1D space filling curve index.
|<<internal_unsupported.dbms.index_population.parallelism,unsupported.dbms.index_population.parallelism>>|Set the maximum number of concurrent index populations across system.
|<<internal_unsupported.dbms.index_population.workers,unsupported.dbms.index_population.workers>>|Set the number of threads used for each index population job.
|<<internal_unsupported.dbms.index_sampling.parallelism,unsupported.dbms.index_sampling.parallelism>>|Set the maximum number of threads that can concurrently be used to sample indexes.
|<<internal_unsupported.dbms.initial_transaction_heap_grab_size,unsupported.dbms.initial_transaction_heap_grab_size>>|Chunk size for heap memory reservation from the memory pool.
|<<internal_unsupported.dbms.io.controller.consider.external.enabled,unsupported.dbms.io.controller.consider.external.enabled>>|Let the IO controller consider/ignore external IO.
|<<internal_unsupported.dbms.kernel_id,unsupported.dbms.kernel_id>>|An identifier that uniquely identifies this graph database instance within this JVM.
|<<internal_unsupported.dbms.large_cluster.enable,unsupported.dbms.large_cluster.enable>>|Enablement of using of different Database allocators.
|<<internal_unsupported.dbms.lock_manager,unsupported.dbms.lock_manager>>|Name of the lock manager to be used, as defined in the corresponding LocksFactory.
|<<internal_unsupported.dbms.lock_manager.verbose_deadlocks,unsupported.dbms.lock_manager.verbose_deadlocks>>|Include additional information in deadlock descriptions.
|<<internal_unsupported.dbms.logs.query.heap_dump_enabled,unsupported.dbms.logs.query.heap_dump_enabled>>|Create a heap dump just before the end of each query execution.
|<<internal_unsupported.dbms.loopback_delete,unsupported.dbms.loopback_delete>>|Whether or not to delete an existing file for use with the Unix Domain Socket based loopback interface.
|<<internal_unsupported.dbms.loopback_enabled,unsupported.dbms.loopback_enabled>>|Enable or disable the bolt loopback connector.
|<<internal_unsupported.dbms.loopback_file,unsupported.dbms.loopback_file>>|The absolute path of the file for use with the Unix Domain Socket based loopback interface.
|<<internal_unsupported.dbms.lucene.ephemeral,unsupported.dbms.lucene.ephemeral>>|Configure lucene to be in memory only, for test environment.
|<<internal_unsupported.dbms.max_http_request_header_size,unsupported.dbms.max_http_request_header_size>>|Maximum request header size.
|<<internal_unsupported.dbms.max_http_response_header_size,unsupported.dbms.max_http_response_header_size>>|Maximum response header size.
|<<internal_unsupported.dbms.memory.counts_store_max_cached_entries,unsupported.dbms.memory.counts_store_max_cached_entries>>|The maximum number of cached entries in count store (based) stores.
|<<internal_unsupported.dbms.memory.managed_network_buffers,unsupported.dbms.memory.managed_network_buffers>>|Whether or not DBMS's byte buffer manager should be used for network stack buffers instead of each network library managing its buffers on its own.
|<<internal_unsupported.dbms.memory.pagecache.warmup.legacy_profile_loader,unsupported.dbms.memory.pagecache.warmup.legacy_profile_loader>>|Enables legacy strategy for loading pages from a profile.
|<<internal_unsupported.dbms.page.file.tracer,unsupported.dbms.page.file.tracer>>|Enable per page file metrics collection in a default page cache and cursor tracer.
|<<internal_unsupported.dbms.query.snapshot,unsupported.dbms.query.snapshot>>|Specifies if engine should run cypher query based on a snapshot of accessed data.
|<<internal_unsupported.dbms.query.snapshot.retries,unsupported.dbms.query.snapshot.retries>>|Specifies number or retries that query engine will do to execute query based on stable accessed data snapshot before giving up.
|<<internal_unsupported.dbms.query_execution_plan_cache_size,unsupported.dbms.query_execution_plan_cache_size>>|Cypher keeps a cache of the conversion from logical plans to execution plans.
|<<internal_unsupported.dbms.readonly.failover,unsupported.dbms.readonly.failover>>|Whether or database should switch to read only mode on disk space problems.
|<<internal_unsupported.dbms.recovery.enable_parallelism,unsupported.dbms.recovery.enable_parallelism>>|Whether or not to use multiple threads whilst performing recovery.
|<<internal_unsupported.dbms.recovery.ignore_store_id_validation,unsupported.dbms.recovery.ignore_store_id_validation>>|Ignore store id validation during recovery.
|<<internal_unsupported.dbms.report_configuration,unsupported.dbms.report_configuration>>|Print out the effective Neo4j configuration after startup.
|<<internal_unsupported.dbms.reserved.page.header.bytes,unsupported.dbms.reserved.page.header.bytes>>|Number of reserved header bytes in each page in page cache.
|<<internal_unsupported.dbms.security.ldap.authorization.connection_pooling,unsupported.dbms.security.ldap.authorization.connection_pooling>>|Set to true if connection pooling should be used for authorization searches using the system account.
|<<internal_unsupported.dbms.ssl.system.ignore_dot_files,unsupported.dbms.ssl.system.ignore_dot_files>>|Don't try and read dot-prefixed files or dot-prefixed directories in ssl policy directories.
|<<internal_unsupported.dbms.storage.consistency_check_on_apply,unsupported.dbms.storage.consistency_check_on_apply>>|Perform some data consistency checks on transaction apply.
|<<internal_unsupported.dbms.storage_engine,unsupported.dbms.storage_engine>>|Name of storage engine to use when creating new databases (except system database).
|<<internal_unsupported.dbms.strictly_prioritize_id_freelist,unsupported.dbms.strictly_prioritize_id_freelist>>|Default value whether or not to strictly prioritize ids from freelist, as opposed to allocating from high id.Given a scenario where there are multiple concurrent calls to allocating IDsand there are free ids on the freelist, some perhaps cached, some not.
|<<internal_unsupported.dbms.tokenscan.log.enabled,unsupported.dbms.tokenscan.log.enabled>>|Enable/disable write log for token lookup indexes.
|<<internal_unsupported.dbms.tokenscan.log.prune_threshold,unsupported.dbms.tokenscan.log.prune_threshold>>|Log file prune threshold for token lookup index write logging.
|<<internal_unsupported.dbms.tokenscan.log.rotation_threshold,unsupported.dbms.tokenscan.log.rotation_threshold>>|Log file rotation threshold for token lookup index write logging.
|<<internal_unsupported.dbms.topology_graph.enable,unsupported.dbms.topology_graph.enable>>|Turning off Topology graph.
|<<internal_unsupported.dbms.topology_graph_updater.enable,unsupported.dbms.topology_graph_updater.enable>>|Turning off Topology graph updater - never turn it off!.
|<<internal_unsupported.dbms.tracer,unsupported.dbms.tracer>>|Name of the tracer factory to be used.
|<<internal_unsupported.dbms.transaction_start_timeout,unsupported.dbms.transaction_start_timeout>>|The maximum amount of time to wait for the database to become available, when starting a new transaction.
|<<internal_unsupported.dbms.tx.logs.dedicated.appender,unsupported.dbms.tx.logs.dedicated.appender>>|Allow database to use dedicated transaction appender writer thread.
|<<internal_unsupported.dbms.tx_log.fail_on_corrupted_log_files,unsupported.dbms.tx_log.fail_on_corrupted_log_files>>|If `true`, Neo4j will abort recovery if any errors are encountered in the logical log.
|<<internal_unsupported.dbms.tx_log.presketch,unsupported.dbms.tx_log.presketch>>|Enables sketching of next transaction log file in the background during reverse recovery.
|<<internal_unsupported.dbms.upgrade_restriction_enabled,unsupported.dbms.upgrade_restriction_enabled>>|Enable or disable the ability to execute the `dbms.upgrade` procedure.
|<<internal_unsupported.dbms.uris.browser,unsupported.dbms.uris.browser>>|URI to the browser home page.
|<<internal_unsupported.dbms.uris.db,unsupported.dbms.uris.db>>|The start endpoint of database api.
|<<internal_unsupported.dbms.uris.dbms,unsupported.dbms.uris.dbms>>|The start endpoint of the dbms api.
|<<internal_unsupported.dbms.uris.management,unsupported.dbms.uris.management>>|The legacy manage endpoint.
|<<internal_unsupported.dbms.uris.rest,unsupported.dbms.uris.rest>>|The legacy data endpoint.
|<<internal_unsupported.dbms.wadl_generation_enabled,unsupported.dbms.wadl_generation_enabled>>|Toggle WADL generation.
|<<internal_unsupported.tools.batch_inserter.batch_size,unsupported.tools.batch_inserter.batch_size>>|Specifies number of operations that batch inserter will try to group into one batch before flushing data into underlying storage.
|<<internal_unsupported.vm_pause_monitor.measurement_duration,unsupported.vm_pause_monitor.measurement_duration>>|VM pause monitor measurement duration.
|<<internal_unsupported.vm_pause_monitor.stall_alert_threshold,unsupported.vm_pause_monitor.stall_alert_threshold>>|Alert threshold for total pause time during one VM pause monitor measurement.
|===
endif::nonhtmloutput[]

ifdef::nonhtmloutput[]
* <<internal_causal_clustering.akka_actor_system_restarter.initial_delay,causal_clustering.akka_actor_system_restarter.initial_delay>>: Initial retry interval for akka restarter (which uses exponential backoff if it fails).
* <<internal_causal_clustering.akka_actor_system_restarter.max_acceptable_failures,causal_clustering.akka_actor_system_restarter.max_acceptable_failures>>: Maximum number of akka restart attempts before we panic the DBMS.
* <<internal_causal_clustering.akka_actor_system_restarter.max_delay,causal_clustering.akka_actor_system_restarter.max_delay>>: Maximum retry interval for akka restarter (which uses exponential backoff if it fails).
* <<internal_causal_clustering.cluster_binding_retry_timeout,causal_clustering.cluster_binding_retry_timeout>>: Configures the time after which we retry binding to a cluster.
* <<internal_causal_clustering.cluster_id_publish_timeout,causal_clustering.cluster_id_publish_timeout>>: Configures the time taken attempting to publish a cluster id to the discovery service before potentially retrying.
* <<internal_causal_clustering.cluster_info_polling_max_wait,causal_clustering.cluster_info_polling_max_wait>>: Maximum time a polling request in the DatabaseInfoService will try before giving up.
* <<internal_causal_clustering.discovery_resolution_retry_interval,causal_clustering.discovery_resolution_retry_interval>>: The polling interval when attempting to resolve initial_discovery_members from DNS and SRV records.
* <<internal_causal_clustering.discovery_resolution_timeout,causal_clustering.discovery_resolution_timeout>>: Configures the time after which we give up trying to resolve a DNS/SRV record into a list of initial discovery members.
* <<internal_causal_clustering.enable_seed_validation,causal_clustering.enable_seed_validation>>: Enable validation of seeds.
* <<internal_causal_clustering.leader_transfer_interval,causal_clustering.leader_transfer_interval>>: The frequency with which a leader will try and transfer leadership to another member.
* <<internal_causal_clustering.leader_transfer_member_backoff,causal_clustering.leader_transfer_member_backoff>>: The amount of time we should wait before repeating an attempt to transfer the leadership of a given database to a member after that member rejects a previous transfer.
* <<internal_causal_clustering.leader_transfer_timeout,causal_clustering.leader_transfer_timeout>>: The time limit within which a leadership transfer request should be completed, otherwise the leader will resume accepting writes.
* <<internal_causal_clustering.max_commits_delay_id_reuse,causal_clustering.max_commits_delay_id_reuse>>: Maximum number of transactions to delay reuse of a deleted ID.
* <<internal_causal_clustering.max_time_delay_id_reuse,causal_clustering.max_time_delay_id_reuse>>: Maximum time to delay reuse of a deleted ID.
* <<internal_causal_clustering.middleware.akka.allow_any_core_to_bootstrap,causal_clustering.middleware.akka.allow_any_core_to_bootstrap>>: If the initial seed node cannot be found attempt to bootstrap with other cores.
* <<internal_causal_clustering.middleware.akka.bind_timeout,causal_clustering.middleware.akka.bind_timeout>>: Timeout for Akka socket binding.
* <<internal_causal_clustering.middleware.akka.cluster.min_nr_of_members,causal_clustering.middleware.akka.cluster.min_nr_of_members>>: Number of cores required for initial Akka cluster formation.
* <<internal_causal_clustering.middleware.akka.cluster.seed_node_timeout,causal_clustering.middleware.akka.cluster.seed_node_timeout>>: Time that seed nodes will spend trying to find an existing cluster before forming a new cluster.
* <<internal_causal_clustering.middleware.akka.cluster.seed_node_timeout_on_first_start,causal_clustering.middleware.akka.cluster.seed_node_timeout_on_first_start>>: Time that seed nodes will spend trying to find an existing cluster before forming a new cluster, when Neo4j is started for the first time.
* <<internal_causal_clustering.middleware.akka.connection_timeout,causal_clustering.middleware.akka.connection_timeout>>: Timeout for Akka connection.
* <<internal_causal_clustering.middleware.akka.default_parallelism,causal_clustering.middleware.akka.default_parallelism>>: Parallelism level of default dispatcher used by Akka based cluster topology discovery, including cluster, replicator, and discovery actors.
* <<internal_causal_clustering.middleware.akka.down_unreachable_on_new_joiner,causal_clustering.middleware.akka.down_unreachable_on_new_joiner>>: Allows a core to down all unreachable members if it needs to do that to allow a new core to join.
* <<internal_causal_clustering.middleware.akka.external_config,causal_clustering.middleware.akka.external_config>>: External config file for Akka.
* <<internal_causal_clustering.middleware.akka.failure_detector.acceptable_heartbeat_pause,causal_clustering.middleware.akka.failure_detector.acceptable_heartbeat_pause>>: Akka cluster phi accrual failure detector.
* <<internal_causal_clustering.middleware.akka.failure_detector.expected_response_after,causal_clustering.middleware.akka.failure_detector.expected_response_after>>: Akka cluster phi accrual failure detector.
* <<internal_causal_clustering.middleware.akka.failure_detector.heartbeat_interval,causal_clustering.middleware.akka.failure_detector.heartbeat_interval>>: Akka cluster phi accrual failure detector.
* <<internal_causal_clustering.middleware.akka.failure_detector.max_sample_size,causal_clustering.middleware.akka.failure_detector.max_sample_size>>: Akka cluster phi accrual failure detector.
* <<internal_causal_clustering.middleware.akka.failure_detector.min_std_deviation,causal_clustering.middleware.akka.failure_detector.min_std_deviation>>: Akka cluster phi accrual failure detector.
* <<internal_causal_clustering.middleware.akka.failure_detector.monitored_by_nr_of_members,causal_clustering.middleware.akka.failure_detector.monitored_by_nr_of_members>>: Akka cluster phi accrual failure detector.
* <<internal_causal_clustering.middleware.akka.failure_detector.threshold,causal_clustering.middleware.akka.failure_detector.threshold>>: Akka cluster phi accrual failure detector.
* <<internal_causal_clustering.middleware.akka.handshake_timeout,causal_clustering.middleware.akka.handshake_timeout>>: Timeout for Akka handshake.
* <<internal_causal_clustering.middleware.akka.shutdown_timeout,causal_clustering.middleware.akka.shutdown_timeout>>: Maximum timeout for akka shutdown.
* <<internal_causal_clustering.middleware.akka.sink_parallelism,causal_clustering.middleware.akka.sink_parallelism>>: Parallelism level of dispatcher used for communication from Akka based cluster topology discovery.
* <<internal_causal_clustering.min_time_delay_id_reuse,causal_clustering.min_time_delay_id_reuse>>: Minimum time to delay reuse of a deleted ID.
* <<internal_causal_clustering.raft_group_graveyard_state_size,causal_clustering.raft_group_graveyard_state_size>>: The maximum file size before the raft group graveyard state file is rotated (in unit of entries).
* <<internal_causal_clustering.raft_in_queue_max_batch,causal_clustering.raft_in_queue_max_batch>>: Largest batch processed by RAFT in number of entries.
* <<internal_causal_clustering.raft_in_queue_size,causal_clustering.raft_in_queue_size>>: Maximum number of entries in the RAFT in-queue.
* <<internal_causal_clustering.raft_messages_log_enable,causal_clustering.raft_messages_log_enable>>: Enable or disable the dump of all network messages pertaining to the RAFT protocol.
* <<internal_causal_clustering.raft_messages_log_path,causal_clustering.raft_messages_log_path>>: Path to RAFT messages log.
* <<internal_causal_clustering.read_replica_transaction_applier_batch_size,causal_clustering.read_replica_transaction_applier_batch_size>>: Threshold in Mb for when a downloaded batch of transactions for a read replicas should be incrementally applied.
* <<internal_causal_clustering.read_replica_transaction_applier_max_queue_size,causal_clustering.read_replica_transaction_applier_max_queue_size>>: Maximum queued size of transactions in Mb to be applied.
* <<internal_causal_clustering.seed_validation_timeout,causal_clustering.seed_validation_timeout>>: Specifies how long the seeding validation is allowed to keep trying to validate against remote before giving up.
* <<internal_causal_clustering.store_copy_backoff_max_wait,causal_clustering.store_copy_backoff_max_wait>>: Maximum backoff timeout for store copy requests.
* <<internal_causal_clustering.store_size_service_cache_timeout,causal_clustering.store_size_service_cache_timeout>>: Timeout for database store size values stored in the cache.
* <<internal_causal_clustering.temporary_database.extension_package_names,causal_clustering.temporary_database.extension_package_names>>: Once temporary database is created, this parameter defines what extensions are loaded based on the package names.
* <<internal_causal_clustering.topology_graph.default_num_primaries,causal_clustering.topology_graph.default_num_primaries>>: Default number of primaries in Large Cluster.
* <<internal_causal_clustering.topology_graph.default_num_secondaries,causal_clustering.topology_graph.default_num_secondaries>>: Default number of secondaries in Large Cluster.
* <<internal_causal_clustering.use_native_transport,causal_clustering.use_native_transport>>: Use native transport if available.
* <<internal_dbms.capabilities.blocked,dbms.capabilities.blocked>>: List of capabilities to block access from capabilities API or procedures.
* <<internal_dbms.connector.bolt.tcp_keep_alive,dbms.connector.bolt.tcp_keep_alive>>: Enable TCP keep alive probes on this connector.
* <<internal_dbms.connector.bolt.unsupported_thread_pool_queue_size,dbms.connector.bolt.unsupported_thread_pool_queue_size>>: The queue size of the thread pool bound to this connector (-1 for unbounded, 0 for direct handoff, > 0 for bounded).
* <<internal_dbms.connector.bolt.unsupported_unauth_connection_timeout,dbms.connector.bolt.unsupported_unauth_connection_timeout>>: The maximum time to wait for a user to finish authentication before closing the connection.
* <<internal_dbms.connector.bolt.unsupported_unauth_max_inbound_bytes,dbms.connector.bolt.unsupported_unauth_max_inbound_bytes>>: The maximum inbound message size in bytes are allowed before a connection is authenticated.
* <<internal_dbms.directories.tx_log,dbms.directories.tx_log>>: Location where Neo4j keeps the logical transaction logs.
* <<internal_dbms.init_file,dbms.init_file>>: Name of file containing commands to be run during initialization of the system database.
* <<internal_dbms.log_inconsistent_data_deletion,dbms.log_inconsistent_data_deletion>>: Whether or not to log contents of data that is inconsistent when deleting it.
* <<internal_dbms.routing.driver.event_loop_count,dbms.routing.driver.event_loop_count>>: Number of event loops used by drivers.
* <<internal_dbms.routing.driver.idle_check_interval,dbms.routing.driver.idle_check_interval>>: Time interval between driver idleness check.
* <<internal_dbms.routing.driver.logging.leaked_sessions,dbms.routing.driver.logging.leaked_sessions>>: Enables logging of leaked driver session.
* <<internal_dbms.routing.driver.timeout,dbms.routing.driver.timeout>>: Time interval of inactivity after which a driver will be closed.
* <<internal_dbms.security.property_level.blacklist,dbms.security.property_level.blacklist>>: This can be achieved with `DENY READ {property} ON GRAPH * ELEMENTS * TO role`.
* <<internal_dbms.security.property_level.enabled,dbms.security.property_level.enabled>>: This has been replaced by privilege management on roles.
* <<internal_fabric.driver.event_loop_count,fabric.driver.event_loop_count>>: Number of event loops used by drivers.
* <<internal_fabric.driver.idle_check_interval,fabric.driver.idle_check_interval>>: Time interval between driver idleness check.
* <<internal_fabric.driver.logging.leaked_sessions,fabric.driver.logging.leaked_sessions>>: Enables logging of leaked driver session.
* <<internal_fabric.driver.timeout,fabric.driver.timeout>>: Time interval of inactivity after which a driver will be closed.
* <<internal_fabric.enabled_by_default,fabric.enabled_by_default>>: Toggle if fabric is enabled by default.
* <<internal_fabric.stream.batch_size,fabric.stream.batch_size>>: Batch size used when requesting records from local Cypher engine.
* <<internal_unsupported.causal_clustering.cluster_status_request_maximum_wait,unsupported.causal_clustering.cluster_status_request_maximum_wait>>: Maximum timeout for cluster status request execution.
* <<internal_unsupported.causal_clustering.experimental_catchup_protocol_enabled,unsupported.causal_clustering.experimental_catchup_protocol_enabled>>: Usage of an experimental catchup protocol.
* <<internal_unsupported.causal_clustering.experimental_raft_protocol_enabled,unsupported.causal_clustering.experimental_raft_protocol_enabled>>: Usage of an experimental raft protocol.
* <<internal_unsupported.causal_clustering.inbound_connection_initialization_logging_enabled,unsupported.causal_clustering.inbound_connection_initialization_logging_enabled>>: Enable logging for inbound connection initialization.
* <<internal_unsupported.consistency_checker.fail_fast_threshold,unsupported.consistency_checker.fail_fast_threshold>>: Specifies if the consistency checker should stop when number of observed inconsistencies exceed the threshold.
* <<internal_unsupported.consistency_checker.memory_limit_factor,unsupported.consistency_checker.memory_limit_factor>>: Limits the maximum amount of off-heap memory the consistency checker will allocate.
* <<internal_unsupported.cypher.compiler_tracing,unsupported.cypher.compiler_tracing>>: Enable tracing of compilation in cypher.
* <<internal_unsupported.cypher.enable_extra_semantic_features,unsupported.cypher.enable_extra_semantic_features>>: Enables extra SemanticFeature:s during cypher semantic checking.
* <<internal_unsupported.cypher.enable_runtime_monitors,unsupported.cypher.enable_runtime_monitors>>: Set this to enable monitors in the Cypher runtime.
* <<internal_unsupported.cypher.expression_engine,unsupported.cypher.expression_engine>>: Choose the expression engine.
* <<internal_unsupported.cypher.expression_recompilation_limit,unsupported.cypher.expression_recompilation_limit>>: Number of uses before an expression is considered for compilation.
* <<internal_unsupported.cypher.idp_solver_duration_threshold,unsupported.cypher.idp_solver_duration_threshold>>: To improve IDP query planning time, we can restrict the internal planning loop duration, triggering more frequent compaction of candidate plans.
* <<internal_unsupported.cypher.idp_solver_table_threshold,unsupported.cypher.idp_solver_table_threshold>>: To improve IDP query planning time, we can restrict the internal planning table size, triggering compaction of candidate plans.
* <<internal_unsupported.cypher.non_indexed_label_warning_threshold,unsupported.cypher.non_indexed_label_warning_threshold>>: The threshold when a warning is generated if a label scan is done after a load csv where the label has no index.
* <<internal_unsupported.cypher.number_of_workers,unsupported.cypher.number_of_workers>>: Number of threads to allocate to Cypher worker threads for the parallel runtime.
* <<internal_unsupported.cypher.parser,unsupported.cypher.parser>>: The parser implementation to use for parsing cypher queries.
* <<internal_unsupported.cypher.pipelined.batch_size_big,unsupported.cypher.pipelined.batch_size_big>>: The size of batches in the pipelined runtime for queries which work with many rows.
* <<internal_unsupported.cypher.pipelined.batch_size_small,unsupported.cypher.pipelined.batch_size_small>>: The size of batches in the pipelined runtime for queries which work with few rows.
* <<internal_unsupported.cypher.pipelined.enable_runtime_trace,unsupported.cypher.pipelined.enable_runtime_trace>>: Enable tracing of pipelined runtime scheduler.
* <<internal_unsupported.cypher.pipelined.operator_engine,unsupported.cypher.pipelined.operator_engine>>: For compiled execution, specialized code is generated and then executed.
* <<internal_unsupported.cypher.pipelined.operator_fusion_over_pipeline_limit,unsupported.cypher.pipelined.operator_fusion_over_pipeline_limit>>: The maximum number of operator fusions over pipelines (i.e.
* <<internal_unsupported.cypher.pipelined.runtime_trace_path,unsupported.cypher.pipelined.runtime_trace_path>>: Path to the pipelined runtime scheduler trace.
* <<internal_unsupported.cypher.pipelined_interpreted_pipes_fallback,unsupported.cypher.pipelined_interpreted_pipes_fallback>>: Use interpreted pipes as a fallback for operators that do not have a specialized implementation in the pipelined runtime.
* <<internal_unsupported.cypher.planning_point_indexes_enabled,unsupported.cypher.planning_point_indexes_enabled>>: Feature flag to enable/disable planning use of point indexes.
* <<internal_unsupported.cypher.planning_range_indexes_enabled,unsupported.cypher.planning_range_indexes_enabled>>: Feature flag to enable/disable planning use of range indexes.
* <<internal_unsupported.cypher.planning_text_indexes_enabled,unsupported.cypher.planning_text_indexes_enabled>>: Feature flag to enable/disable planning use of text indexes.
* <<internal_unsupported.cypher.predicates_as_union_max_size,unsupported.cypher.predicates_as_union_max_size>>: Maximum size after which the planner will not attempt to plan the disjunction of predicates on a single variable as a distinct union.For example, given the following pattern: `()-[e:FOO|BAR|BAZ]->()`, the planner will attempt to plan a union of `e:Foo`, `e:Bar`, and `e:Baz`unless `unsupported.cypher.predicates_as_union_max_size` is less than 3.
* <<internal_unsupported.cypher.replan_algorithm,unsupported.cypher.replan_algorithm>>: Large databases might change slowly, and to prevent queries from never being replanned the divergence threshold set by cypher.statistics_divergence_threshold is configured to shrink over time using the algorithm set here.
* <<internal_unsupported.cypher.runtime,unsupported.cypher.runtime>>: Set this to specify the default runtime for the default language version.
* <<internal_unsupported.cypher.splitting_top_behavior,unsupported.cypher.splitting_top_behavior>>: Determines whether the planner is allowed to push down the sort portion of an ORDER BY + LIMIT combination.
* <<internal_unsupported.cypher.statistics_divergence_target,unsupported.cypher.statistics_divergence_target>>: Large databases might change slowly, and so to prevent queries from never being replanned the divergence threshold set by cypher.statistics_divergence_threshold is configured to shrink over time.
* <<internal_unsupported.cypher.target_replan_interval,unsupported.cypher.target_replan_interval>>: Large databases might change slowly, and to prevent queries from never being replanned the divergence threshold set by cypher.statistics_divergence_threshold is configured to shrink over time.
* <<internal_unsupported.datacollector.max_query_text_size,unsupported.datacollector.max_query_text_size>>: Sets the upper limit for how much of the query text that will be retained by the query collector.
* <<internal_unsupported.datacollector.max_recent_query_count,unsupported.datacollector.max_recent_query_count>>: Max number of recent queries to collect in the data collector module.
* <<internal_unsupported.dbms.block_alter_database,unsupported.dbms.block_alter_database>>: Enable or disable the ability to alter databases.
* <<internal_unsupported.dbms.block_create_drop_database,unsupported.dbms.block_create_drop_database>>: Enable or disable the ability to create and drop databases.
* <<internal_unsupported.dbms.block_remote_alias,unsupported.dbms.block_remote_alias>>: Enable or disable the ability to use remote aliases.
* <<internal_unsupported.dbms.block_size.array_properties,unsupported.dbms.block_size.array_properties>>: Specifies the block size for storing arrays.
* <<internal_unsupported.dbms.block_size.labels,unsupported.dbms.block_size.labels>>: Specifies the block size for storing labels exceeding in-lined space in node record.
* <<internal_unsupported.dbms.block_size.strings,unsupported.dbms.block_size.strings>>: Specifies the block size for storing strings.
* <<internal_unsupported.dbms.block_start_stop_database,unsupported.dbms.block_start_stop_database>>: Enable or disable the ability to start and stop databases.
* <<internal_unsupported.dbms.bolt.inbound_message_throttle.high_watermark,unsupported.dbms.bolt.inbound_message_throttle.high_watermark>>: When the number of queued inbound messages grows beyond this value, reading from underlying channel will be paused (no more inbound messages will be available) until queued number of messages drops below the configured low watermark value.
* <<internal_unsupported.dbms.bolt.inbound_message_throttle.low_watermark,unsupported.dbms.bolt.inbound_message_throttle.low_watermark>>: When the number of queued inbound messages, previously reached configured high watermark value, drops below this value, reading from underlying channel will be enabled and any pending messages will start queuing again.
* <<internal_unsupported.dbms.bolt.netty_message_merge_cumulator,unsupported.dbms.bolt.netty_message_merge_cumulator>>: Enable/disable the use of a merge cumulator for netty.
* <<internal_unsupported.dbms.bolt.netty_server_shutdown_quiet_period,unsupported.dbms.bolt.netty_server_shutdown_quiet_period>>: Quiet period for netty shutdown.
* <<internal_unsupported.dbms.bolt.netty_server_shutdown_timeout,unsupported.dbms.bolt.netty_server_shutdown_timeout>>: Timeout for netty shutdown.
* <<internal_unsupported.dbms.bolt.netty_server_use_epoll,unsupported.dbms.bolt.netty_server_use_epoll>>: Enable/disable the use of Epoll for netty.
* <<internal_unsupported.dbms.bolt.outbound_buffer_throttle,unsupported.dbms.bolt.outbound_buffer_throttle>>: Whether to apply network level outbound network buffer based throttling.
* <<internal_unsupported.dbms.bolt.outbound_buffer_throttle.high_watermark,unsupported.dbms.bolt.outbound_buffer_throttle.high_watermark>>: When the size (in bytes) of outbound network buffers, used by bolt's network layer, grows beyond this value bolt channel will advertise itself as unwritable and will block related processing thread until it becomes writable again.
* <<internal_unsupported.dbms.bolt.outbound_buffer_throttle.low_watermark,unsupported.dbms.bolt.outbound_buffer_throttle.low_watermark>>: When the size (in bytes) of outbound network buffers, previously advertised as unwritable, gets below this value bolt channel will re-advertise itself as writable and blocked processing thread will resume execution.
* <<internal_unsupported.dbms.bolt.outbound_buffer_throttle.max_duration,unsupported.dbms.bolt.outbound_buffer_throttle.max_duration>>: When the total time outbound network buffer based throttle lock is held exceeds this value, the corresponding bolt channel will be aborted.
* <<internal_unsupported.dbms.checkpoint_log.rotation.keep.files,unsupported.dbms.checkpoint_log.rotation.keep.files>>: Number of checkpoint logs files to keep.
* <<internal_unsupported.dbms.checkpoint_log.rotation.size,unsupported.dbms.checkpoint_log.rotation.size>>: Specifies at which file size the checkpoint log will auto-rotate.
* <<internal_unsupported.dbms.config.command_evaluation_timeout,unsupported.dbms.config.command_evaluation_timeout>>: Timeout for configuration command evaluation, per command.
* <<internal_unsupported.dbms.counts_store_rotation_timeout,unsupported.dbms.counts_store_rotation_timeout>>: Maximum time to wait for active transaction completion when rotating counts store.
* <<internal_unsupported.dbms.cypher_ip_blocklist,unsupported.dbms.cypher_ip_blocklist>>: A list of CIDR-notation IPv4 or IPv6 addresses to block when accessing URLs.This list is checked when LOAD CSV or apoc.load.json is called.
* <<internal_unsupported.dbms.debug.page_cache_tracer_speed_reporting_threshold,unsupported.dbms.debug.page_cache_tracer_speed_reporting_threshold>>: Reporting interval for page cache speed logging.
* <<internal_unsupported.dbms.debug.print_page_buffer_allocation_trace,unsupported.dbms.debug.print_page_buffer_allocation_trace>>: Print stack trace on failed native io buffer allocation.
* <<internal_unsupported.dbms.debug.trace_cursors,unsupported.dbms.debug.trace_cursors>>: Trace unclosed cursors.
* <<internal_unsupported.dbms.debug.trace_tx_statement,unsupported.dbms.debug.trace_tx_statement>>: Trace open/close transaction statements.
* <<internal_unsupported.dbms.debug.track_cursor_close,unsupported.dbms.debug.track_cursor_close>>: Validate if cursors are properly closed.
* <<internal_unsupported.dbms.debug.track_tx_statement_close,unsupported.dbms.debug.track_tx_statement_close>>: Validate if transaction statements are properly closed.
* <<internal_unsupported.dbms.directories.auth,unsupported.dbms.directories.auth>>: Location of the auth store repository directory.
* <<internal_unsupported.dbms.directories.databases.root,unsupported.dbms.directories.databases.root>>: Path of the databases directory.
* <<internal_unsupported.dbms.directories.pid_file,unsupported.dbms.directories.pid_file>>: Path of the pid file.
* <<internal_unsupported.dbms.directories.scripts,unsupported.dbms.directories.scripts>>: Location of the database scripts directory.
* <<internal_unsupported.dbms.directories.windows_tools,unsupported.dbms.directories.windows_tools>>: Path of the lib directory.
* <<internal_unsupported.dbms.discoverable_bolt_address,unsupported.dbms.discoverable_bolt_address>>: Publicly discoverable bolt:// URI to use for Neo4j Drivers wanting to access the data in this particular database instance.
* <<internal_unsupported.dbms.discoverable_bolt_routing_address,unsupported.dbms.discoverable_bolt_routing_address>>: Publicly discoverable neo4j:// URI to use for Neo4j Drivers wanting to access a cluster or a single instance.
* <<internal_unsupported.dbms.dump_diagnostics,unsupported.dbms.dump_diagnostics>>: Whether or not to dump system and database diagnostics.
* <<internal_unsupported.dbms.enable_transaction_heap_allocation_tracking,unsupported.dbms.enable_transaction_heap_allocation_tracking>>: Track heap memory allocations for transactions.
* <<internal_unsupported.dbms.executiontime_limit.time,unsupported.dbms.executiontime_limit.time>>: If execution time limiting is enabled in the database, this configures the maximum request execution time.
* <<internal_unsupported.dbms.extra_lock_verification,unsupported.dbms.extra_lock_verification>>: Whether or not to do additional checks for locks when making changes as part of commit.
* <<internal_unsupported.dbms.force_small_id_cache,unsupported.dbms.force_small_id_cache>>: Forces smaller ID cache, in order to preserve memory.
* <<internal_unsupported.dbms.http_paths_blacklist,unsupported.dbms.http_paths_blacklist>>: Defines a blacklist of http paths that should not be accessed.
* <<internal_unsupported.dbms.idgenerator.log.enabled,unsupported.dbms.idgenerator.log.enabled>>: Enable/disable logging for the id generator.
* <<internal_unsupported.dbms.idgenerator.log.prune_threshold,unsupported.dbms.idgenerator.log.prune_threshold>>: Log file prune threshold for id generator logging.
* <<internal_unsupported.dbms.idgenerator.log.rotation_threshold,unsupported.dbms.idgenerator.log.rotation_threshold>>: Log file rotation threshold for id generator logging.
* <<internal_unsupported.dbms.index.archive_failed,unsupported.dbms.index.archive_failed>>: Create an archive of an index before re-creating it if failing to load on startup.
* <<internal_unsupported.dbms.index.default_fulltext_provider,unsupported.dbms.index.default_fulltext_provider>>: The default index provider used for managing full-text indexes.
* <<internal_unsupported.dbms.index.lucene.merge_factor,unsupported.dbms.index.lucene.merge_factor>>: Setting for the matching lucene IndexWriterConfig config.
* <<internal_unsupported.dbms.index.lucene.min_merge,unsupported.dbms.index.lucene.min_merge>>: Setting for the matching lucene IndexWriterConfig config.
* <<internal_unsupported.dbms.index.lucene.nocfs.ratio,unsupported.dbms.index.lucene.nocfs.ratio>>: Setting for the matching lucene IndexWriterConfig config.
* <<internal_unsupported.dbms.index.lucene.population_max_buffered_docs,unsupported.dbms.index.lucene.population_max_buffered_docs>>: Setting for the matching lucene IndexWriterConfig config.
* <<internal_unsupported.dbms.index.lucene.population_ram_buffer_size,unsupported.dbms.index.lucene.population_ram_buffer_size>>: Setting for the matching lucene IndexWriterConfig config.
* <<internal_unsupported.dbms.index.lucene.standard_ram_buffer_size,unsupported.dbms.index.lucene.standard_ram_buffer_size>>: Setting for the matching lucene IndexWriterConfig config.
* <<internal_unsupported.dbms.index.lucene.writer_max_buffered_docs,unsupported.dbms.index.lucene.writer_max_buffered_docs>>: Setting for the matching lucene IndexWriterConfig config.
* <<internal_unsupported.dbms.index.population_batch_max_byte_size,unsupported.dbms.index.population_batch_max_byte_size>>: Max size for an index population batch.
* <<internal_unsupported.dbms.index.population_print_debug,unsupported.dbms.index.population_print_debug>>: Printing debug information on index population.
* <<internal_unsupported.dbms.index.population_queue_threshold,unsupported.dbms.index.population_queue_threshold>>: Queue size for index population batched updates.
* <<internal_unsupported.dbms.index.populator_block_size,unsupported.dbms.index.populator_block_size>>: Block/buffer size for index population.
* <<internal_unsupported.dbms.index.populator_merge_factor,unsupported.dbms.index.populator_merge_factor>>: Merge factory for index population.
* <<internal_unsupported.dbms.index.sampling.async_recovery,unsupported.dbms.index.sampling.async_recovery>>: Enable asynchronous index sample recovery.
* <<internal_unsupported.dbms.index.sampling.async_recovery_wait,unsupported.dbms.index.sampling.async_recovery_wait>>: Wait for asynchronous index sample recovery to finish.
* <<internal_unsupported.dbms.index.sampling.log_recovered_samples,unsupported.dbms.index.sampling.log_recovered_samples>>: Logging information about recovered index samples.
* <<internal_unsupported.dbms.index.skip_default_indexes_on_creation,unsupported.dbms.index.skip_default_indexes_on_creation>>: If 'true', new database will be created without token indexes for labels and relationships.
* <<internal_unsupported.dbms.index.spatial.curve.bottom_threshold,unsupported.dbms.index.spatial.curve.bottom_threshold>>: When searching the spatial index we need to convert a 2D range in the quad tree into a set of 1D ranges on the underlying 1D space filling curve index.
* <<internal_unsupported.dbms.index.spatial.curve.extra_levels,unsupported.dbms.index.spatial.curve.extra_levels>>: When searching the spatial index we need to convert a 2D range in the quad tree into a set of 1D ranges on the underlying 1D space filling curve index.
* <<internal_unsupported.dbms.index.spatial.curve.top_threshold,unsupported.dbms.index.spatial.curve.top_threshold>>: When searching the spatial index we need to convert a 2D range in the quad tree into a set of 1D ranges on the underlying 1D space filling curve index.
* <<internal_unsupported.dbms.index_population.parallelism,unsupported.dbms.index_population.parallelism>>: Set the maximum number of concurrent index populations across system.
* <<internal_unsupported.dbms.index_population.workers,unsupported.dbms.index_population.workers>>: Set the number of threads used for each index population job.
* <<internal_unsupported.dbms.index_sampling.parallelism,unsupported.dbms.index_sampling.parallelism>>: Set the maximum number of threads that can concurrently be used to sample indexes.
* <<internal_unsupported.dbms.initial_transaction_heap_grab_size,unsupported.dbms.initial_transaction_heap_grab_size>>: Chunk size for heap memory reservation from the memory pool.
* <<internal_unsupported.dbms.io.controller.consider.external.enabled,unsupported.dbms.io.controller.consider.external.enabled>>: Let the IO controller consider/ignore external IO.
* <<internal_unsupported.dbms.kernel_id,unsupported.dbms.kernel_id>>: An identifier that uniquely identifies this graph database instance within this JVM.
* <<internal_unsupported.dbms.large_cluster.enable,unsupported.dbms.large_cluster.enable>>: Enablement of using of different Database allocators.
* <<internal_unsupported.dbms.lock_manager,unsupported.dbms.lock_manager>>: Name of the lock manager to be used, as defined in the corresponding LocksFactory.
* <<internal_unsupported.dbms.lock_manager.verbose_deadlocks,unsupported.dbms.lock_manager.verbose_deadlocks>>: Include additional information in deadlock descriptions.
* <<internal_unsupported.dbms.logs.query.heap_dump_enabled,unsupported.dbms.logs.query.heap_dump_enabled>>: Create a heap dump just before the end of each query execution.
* <<internal_unsupported.dbms.loopback_delete,unsupported.dbms.loopback_delete>>: Whether or not to delete an existing file for use with the Unix Domain Socket based loopback interface.
* <<internal_unsupported.dbms.loopback_enabled,unsupported.dbms.loopback_enabled>>: Enable or disable the bolt loopback connector.
* <<internal_unsupported.dbms.loopback_file,unsupported.dbms.loopback_file>>: The absolute path of the file for use with the Unix Domain Socket based loopback interface.
* <<internal_unsupported.dbms.lucene.ephemeral,unsupported.dbms.lucene.ephemeral>>: Configure lucene to be in memory only, for test environment.
* <<internal_unsupported.dbms.max_http_request_header_size,unsupported.dbms.max_http_request_header_size>>: Maximum request header size.
* <<internal_unsupported.dbms.max_http_response_header_size,unsupported.dbms.max_http_response_header_size>>: Maximum response header size.
* <<internal_unsupported.dbms.memory.counts_store_max_cached_entries,unsupported.dbms.memory.counts_store_max_cached_entries>>: The maximum number of cached entries in count store (based) stores.
* <<internal_unsupported.dbms.memory.managed_network_buffers,unsupported.dbms.memory.managed_network_buffers>>: Whether or not DBMS's byte buffer manager should be used for network stack buffers instead of each network library managing its buffers on its own.
* <<internal_unsupported.dbms.memory.pagecache.warmup.legacy_profile_loader,unsupported.dbms.memory.pagecache.warmup.legacy_profile_loader>>: Enables legacy strategy for loading pages from a profile.
* <<internal_unsupported.dbms.page.file.tracer,unsupported.dbms.page.file.tracer>>: Enable per page file metrics collection in a default page cache and cursor tracer.
* <<internal_unsupported.dbms.query.snapshot,unsupported.dbms.query.snapshot>>: Specifies if engine should run cypher query based on a snapshot of accessed data.
* <<internal_unsupported.dbms.query.snapshot.retries,unsupported.dbms.query.snapshot.retries>>: Specifies number or retries that query engine will do to execute query based on stable accessed data snapshot before giving up.
* <<internal_unsupported.dbms.query_execution_plan_cache_size,unsupported.dbms.query_execution_plan_cache_size>>: Cypher keeps a cache of the conversion from logical plans to execution plans.
* <<internal_unsupported.dbms.readonly.failover,unsupported.dbms.readonly.failover>>: Whether or database should switch to read only mode on disk space problems.
* <<internal_unsupported.dbms.recovery.enable_parallelism,unsupported.dbms.recovery.enable_parallelism>>: Whether or not to use multiple threads whilst performing recovery.
* <<internal_unsupported.dbms.recovery.ignore_store_id_validation,unsupported.dbms.recovery.ignore_store_id_validation>>: Ignore store id validation during recovery.
* <<internal_unsupported.dbms.report_configuration,unsupported.dbms.report_configuration>>: Print out the effective Neo4j configuration after startup.
* <<internal_unsupported.dbms.reserved.page.header.bytes,unsupported.dbms.reserved.page.header.bytes>>: Number of reserved header bytes in each page in page cache.
* <<internal_unsupported.dbms.security.ldap.authorization.connection_pooling,unsupported.dbms.security.ldap.authorization.connection_pooling>>: Set to true if connection pooling should be used for authorization searches using the system account.
* <<internal_unsupported.dbms.ssl.system.ignore_dot_files,unsupported.dbms.ssl.system.ignore_dot_files>>: Don't try and read dot-prefixed files or dot-prefixed directories in ssl policy directories.
* <<internal_unsupported.dbms.storage.consistency_check_on_apply,unsupported.dbms.storage.consistency_check_on_apply>>: Perform some data consistency checks on transaction apply.
* <<internal_unsupported.dbms.storage_engine,unsupported.dbms.storage_engine>>: Name of storage engine to use when creating new databases (except system database).
* <<internal_unsupported.dbms.strictly_prioritize_id_freelist,unsupported.dbms.strictly_prioritize_id_freelist>>: Default value whether or not to strictly prioritize ids from freelist, as opposed to allocating from high id.Given a scenario where there are multiple concurrent calls to allocating IDsand there are free ids on the freelist, some perhaps cached, some not.
* <<internal_unsupported.dbms.tokenscan.log.enabled,unsupported.dbms.tokenscan.log.enabled>>: Enable/disable write log for token lookup indexes.
* <<internal_unsupported.dbms.tokenscan.log.prune_threshold,unsupported.dbms.tokenscan.log.prune_threshold>>: Log file prune threshold for token lookup index write logging.
* <<internal_unsupported.dbms.tokenscan.log.rotation_threshold,unsupported.dbms.tokenscan.log.rotation_threshold>>: Log file rotation threshold for token lookup index write logging.
* <<internal_unsupported.dbms.topology_graph.enable,unsupported.dbms.topology_graph.enable>>: Turning off Topology graph.
* <<internal_unsupported.dbms.topology_graph_updater.enable,unsupported.dbms.topology_graph_updater.enable>>: Turning off Topology graph updater - never turn it off!.
* <<internal_unsupported.dbms.tracer,unsupported.dbms.tracer>>: Name of the tracer factory to be used.
* <<internal_unsupported.dbms.transaction_start_timeout,unsupported.dbms.transaction_start_timeout>>: The maximum amount of time to wait for the database to become available, when starting a new transaction.
* <<internal_unsupported.dbms.tx.logs.dedicated.appender,unsupported.dbms.tx.logs.dedicated.appender>>: Allow database to use dedicated transaction appender writer thread.
* <<internal_unsupported.dbms.tx_log.fail_on_corrupted_log_files,unsupported.dbms.tx_log.fail_on_corrupted_log_files>>: If `true`, Neo4j will abort recovery if any errors are encountered in the logical log.
* <<internal_unsupported.dbms.tx_log.presketch,unsupported.dbms.tx_log.presketch>>: Enables sketching of next transaction log file in the background during reverse recovery.
* <<internal_unsupported.dbms.upgrade_restriction_enabled,unsupported.dbms.upgrade_restriction_enabled>>: Enable or disable the ability to execute the `dbms.upgrade` procedure.
* <<internal_unsupported.dbms.uris.browser,unsupported.dbms.uris.browser>>: URI to the browser home page.
* <<internal_unsupported.dbms.uris.db,unsupported.dbms.uris.db>>: The start endpoint of database api.
* <<internal_unsupported.dbms.uris.dbms,unsupported.dbms.uris.dbms>>: The start endpoint of the dbms api.
* <<internal_unsupported.dbms.uris.management,unsupported.dbms.uris.management>>: The legacy manage endpoint.
* <<internal_unsupported.dbms.uris.rest,unsupported.dbms.uris.rest>>: The legacy data endpoint.
* <<internal_unsupported.dbms.wadl_generation_enabled,unsupported.dbms.wadl_generation_enabled>>: Toggle WADL generation.
* <<internal_unsupported.tools.batch_inserter.batch_size,unsupported.tools.batch_inserter.batch_size>>: Specifies number of operations that batch inserter will try to group into one batch before flushing data into underlying storage.
* <<internal_unsupported.vm_pause_monitor.measurement_duration,unsupported.vm_pause_monitor.measurement_duration>>: VM pause monitor measurement duration.
* <<internal_unsupported.vm_pause_monitor.stall_alert_threshold,unsupported.vm_pause_monitor.stall_alert_threshold>>: Alert threshold for total pause time during one VM pause monitor measurement.
endif::nonhtmloutput[]


// end::settings-reference-internal-settings[]

[[internal_causal_clustering.akka_actor_system_restarter.initial_delay]]
.causal_clustering.akka_actor_system_restarter.initial_delay
[cols="<1s,<4"]
|===
|Description
a|Initial retry interval for akka restarter (which uses exponential backoff if it fails)
|Valid values
a|causal_clustering.akka_actor_system_restarter.initial_delay, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++1s+++
|Internal
a|causal_clustering.akka_actor_system_restarter.initial_delay is an internal, unsupported setting.
|===

[[internal_causal_clustering.akka_actor_system_restarter.max_acceptable_failures]]
.causal_clustering.akka_actor_system_restarter.max_acceptable_failures
[cols="<1s,<4"]
|===
|Description
a|Maximum number of akka restart attempts before we panic the DBMS. Set to -1 to retry forever.
|Valid values
a|causal_clustering.akka_actor_system_restarter.max_acceptable_failures, an integer
|Default value
m|+++8+++
|Internal
a|causal_clustering.akka_actor_system_restarter.max_acceptable_failures is an internal, unsupported setting.
|===

[[internal_causal_clustering.akka_actor_system_restarter.max_delay]]
.causal_clustering.akka_actor_system_restarter.max_delay
[cols="<1s,<4"]
|===
|Description
a|Maximum retry interval for akka restarter (which uses exponential backoff if it fails)
|Valid values
a|causal_clustering.akka_actor_system_restarter.max_delay, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++1m+++
|Internal
a|causal_clustering.akka_actor_system_restarter.max_delay is an internal, unsupported setting.
|===

[[internal_causal_clustering.cluster_binding_retry_timeout]]
.causal_clustering.cluster_binding_retry_timeout
[cols="<1s,<4"]
|===
|Description
a|Configures the time after which we retry binding to a cluster. Only applies to Akka discovery. A discovery type of DNS/SRV/K8S will be queried again on retry.
|Valid values
a|causal_clustering.cluster_binding_retry_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++1m+++
|Internal
a|causal_clustering.cluster_binding_retry_timeout is an internal, unsupported setting.
|===

[[internal_causal_clustering.cluster_id_publish_timeout]]
.causal_clustering.cluster_id_publish_timeout
[cols="<1s,<4"]
|===
|Description
a|Configures the time taken attempting to publish a cluster id to the discovery service before potentially retrying.
|Valid values
a|causal_clustering.cluster_id_publish_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++15s+++
|Internal
a|causal_clustering.cluster_id_publish_timeout is an internal, unsupported setting.
|===

[[internal_causal_clustering.cluster_info_polling_max_wait]]
.causal_clustering.cluster_info_polling_max_wait
[cols="<1s,<4"]
|===
|Description
a|Maximum time a polling request in the DatabaseInfoService will try before giving up.
|Valid values
a|causal_clustering.cluster_info_polling_max_wait, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++5s+++
|Internal
a|causal_clustering.cluster_info_polling_max_wait is an internal, unsupported setting.
|===

[[internal_causal_clustering.discovery_resolution_retry_interval]]
.causal_clustering.discovery_resolution_retry_interval
[cols="<1s,<4"]
|===
|Description
a|The polling interval when attempting to resolve initial_discovery_members from DNS and SRV records.
|Valid values
a|causal_clustering.discovery_resolution_retry_interval, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++5s+++
|Internal
a|causal_clustering.discovery_resolution_retry_interval is an internal, unsupported setting.
|===

[[internal_causal_clustering.discovery_resolution_timeout]]
.causal_clustering.discovery_resolution_timeout
[cols="<1s,<4"]
|===
|Description
a|Configures the time after which we give up trying to resolve a DNS/SRV record into a list of initial discovery members.
|Valid values
a|causal_clustering.discovery_resolution_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++5m+++
|Internal
a|causal_clustering.discovery_resolution_timeout is an internal, unsupported setting.
|===

[[internal_causal_clustering.enable_seed_validation]]
.causal_clustering.enable_seed_validation
[cols="<1s,<4"]
|===
|Description
a|Enable validation of seeds.
|Valid values
a|causal_clustering.enable_seed_validation, a boolean
|Default value
m|+++false+++
|Internal
a|causal_clustering.enable_seed_validation is an internal, unsupported setting.
|===

[[internal_causal_clustering.leader_transfer_interval]]
.causal_clustering.leader_transfer_interval
[cols="<1s,<4"]
|===
|Description
a|The frequency with which a leader will try and transfer leadership to another member.
|Valid values
a|causal_clustering.leader_transfer_interval, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++15s+++
|Internal
a|causal_clustering.leader_transfer_interval is an internal, unsupported setting.
|===

[[internal_causal_clustering.leader_transfer_member_backoff]]
.causal_clustering.leader_transfer_member_backoff
[cols="<1s,<4"]
|===
|Description
a|The amount of time we should wait before repeating an attempt to transfer the leadership of a given database to a member after that member rejects a previous transfer.
|Valid values
a|causal_clustering.leader_transfer_member_backoff, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++30s+++
|Internal
a|causal_clustering.leader_transfer_member_backoff is an internal, unsupported setting.
|===

[[internal_causal_clustering.leader_transfer_timeout]]
.causal_clustering.leader_transfer_timeout
[cols="<1s,<4"]
|===
|Description
a|The time limit within which a leadership transfer request should be completed, otherwise the leader will resume accepting writes.
|Valid values
a|causal_clustering.leader_transfer_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++3s+++
|Internal
a|causal_clustering.leader_transfer_timeout is an internal, unsupported setting.
|===

[[internal_causal_clustering.max_commits_delay_id_reuse]]
.causal_clustering.max_commits_delay_id_reuse
[cols="<1s,<4"]
|===
|Description
a|Maximum number of transactions to delay reuse of a deleted ID.
|Valid values
a|causal_clustering.max_commits_delay_id_reuse, an integer
|Default value
m|+++1000+++
|Internal
a|causal_clustering.max_commits_delay_id_reuse is an internal, unsupported setting.
|===

[[internal_causal_clustering.max_time_delay_id_reuse]]
.causal_clustering.max_time_delay_id_reuse
[cols="<1s,<4"]
|===
|Description
a|Maximum time to delay reuse of a deleted ID.
|Valid values
a|causal_clustering.max_time_delay_id_reuse, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++5m+++
|Internal
a|causal_clustering.max_time_delay_id_reuse is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.allow_any_core_to_bootstrap]]
.causal_clustering.middleware.akka.allow_any_core_to_bootstrap
[cols="<1s,<4"]
|===
|Description
a|If the initial seed node cannot be found attempt to bootstrap with other cores.
|Valid values
a|causal_clustering.middleware.akka.allow_any_core_to_bootstrap, a boolean
|Default value
m|+++false+++
|Internal
a|causal_clustering.middleware.akka.allow_any_core_to_bootstrap is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.bind_timeout]]
.causal_clustering.middleware.akka.bind_timeout
[cols="<1s,<4"]
|===
|Description
a|Timeout for Akka socket binding.
|Valid values
a|causal_clustering.middleware.akka.bind_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10s+++
|Internal
a|causal_clustering.middleware.akka.bind_timeout is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.cluster.min_nr_of_members]]
.causal_clustering.middleware.akka.cluster.min_nr_of_members
[cols="<1s,<4"]
|===
|Description
a|Number of cores required for initial Akka cluster formation.
|Valid values
a|causal_clustering.middleware.akka.cluster.min_nr_of_members, an integer
|Default value
m|+++2+++
|Internal
a|causal_clustering.middleware.akka.cluster.min_nr_of_members is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.cluster.seed_node_timeout]]
.causal_clustering.middleware.akka.cluster.seed_node_timeout
[cols="<1s,<4"]
|===
|Description
a|Time that seed nodes will spend trying to find an existing cluster before forming a new cluster.
|Valid values
a|causal_clustering.middleware.akka.cluster.seed_node_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`) which Must be set less than or equal to value of 'causal_clustering.cluster_binding_retry_timeout' divided by 2
|Default value
m|+++30s+++
|Internal
a|causal_clustering.middleware.akka.cluster.seed_node_timeout is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.cluster.seed_node_timeout_on_first_start]]
.causal_clustering.middleware.akka.cluster.seed_node_timeout_on_first_start
[cols="<1s,<4"]
|===
|Description
a|Time that seed nodes will spend trying to find an existing cluster before forming a new cluster, when Neo4j is started for the first time.
|Valid values
a|causal_clustering.middleware.akka.cluster.seed_node_timeout_on_first_start, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`) which Must be set less than or equal to value of 'causal_clustering.middleware.akka.cluster.seed_node_timeout' 
|Default value
m|+++3s+++
|Internal
a|causal_clustering.middleware.akka.cluster.seed_node_timeout_on_first_start is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.connection_timeout]]
.causal_clustering.middleware.akka.connection_timeout
[cols="<1s,<4"]
|===
|Description
a|Timeout for Akka connection.
|Valid values
a|causal_clustering.middleware.akka.connection_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10s+++
|Internal
a|causal_clustering.middleware.akka.connection_timeout is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.default_parallelism]]
.causal_clustering.middleware.akka.default_parallelism
[cols="<1s,<4"]
|===
|Description
a|Parallelism level of default dispatcher used by Akka based cluster topology discovery, including cluster, replicator, and discovery actors.
|Valid values
a|causal_clustering.middleware.akka.default_parallelism, an integer
|Default value
m|+++4+++
|Internal
a|causal_clustering.middleware.akka.default_parallelism is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.down_unreachable_on_new_joiner]]
.causal_clustering.middleware.akka.down_unreachable_on_new_joiner
[cols="<1s,<4"]
|===
|Description
a|Allows a core to down all unreachable members if it needs to do that to allow a new core to join.
|Valid values
a|causal_clustering.middleware.akka.down_unreachable_on_new_joiner, a boolean
|Default value
m|+++true+++
|Internal
a|causal_clustering.middleware.akka.down_unreachable_on_new_joiner is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.external_config]]
.causal_clustering.middleware.akka.external_config
[cols="<1s,<4"]
|===
|Description
a|External config file for Akka.
|Valid values
a|causal_clustering.middleware.akka.external_config, a path which depends on dbms.mode. If dbms.mode one of `[CORE, READ_REPLICA]` then it must be a parsable file or empty otherwise it depends on dbms.mode. If dbms.mode one of `[SINGLE]` then it depends on dbms.clustering.enable. If dbms.clustering.enable is `true` then it must be a parsable file or empty otherwise it is unconstrained. otherwise it is unconstrained..
|Internal
a|causal_clustering.middleware.akka.external_config is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.failure_detector.acceptable_heartbeat_pause]]
.causal_clustering.middleware.akka.failure_detector.acceptable_heartbeat_pause
[cols="<1s,<4"]
|===
|Description
a|Akka cluster phi accrual failure detector. Number of potentially lost/delayed heartbeats that will be accepted before considering it to be an anomaly. This margin is important to be able to survive sudden, occasional, pauses in heartbeat arrivals, due to for example garbage collect or network drop.
|Valid values
a|causal_clustering.middleware.akka.failure_detector.acceptable_heartbeat_pause, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++30s+++
|Internal
a|causal_clustering.middleware.akka.failure_detector.acceptable_heartbeat_pause is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.failure_detector.expected_response_after]]
.causal_clustering.middleware.akka.failure_detector.expected_response_after
[cols="<1s,<4"]
|===
|Description
a|Akka cluster phi accrual failure detector. After the heartbeat request has been sent the first failure detection will start after this period, even though no heartbeat message has been received.
|Valid values
a|causal_clustering.middleware.akka.failure_detector.expected_response_after, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10s+++
|Internal
a|causal_clustering.middleware.akka.failure_detector.expected_response_after is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.failure_detector.heartbeat_interval]]
.causal_clustering.middleware.akka.failure_detector.heartbeat_interval
[cols="<1s,<4"]
|===
|Description
a|Akka cluster phi accrual failure detector. How often keep-alive heartbeat messages should be sent to each connection.
|Valid values
a|causal_clustering.middleware.akka.failure_detector.heartbeat_interval, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++1s+++
|Internal
a|causal_clustering.middleware.akka.failure_detector.heartbeat_interval is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.failure_detector.max_sample_size]]
.causal_clustering.middleware.akka.failure_detector.max_sample_size
[cols="<1s,<4"]
|===
|Description
a|Akka cluster phi accrual failure detector. Number of the samples of inter-heartbeat arrival times to adaptively calculate the failure timeout for connections.
|Valid values
a|causal_clustering.middleware.akka.failure_detector.max_sample_size, an integer
|Default value
m|+++1000+++
|Internal
a|causal_clustering.middleware.akka.failure_detector.max_sample_size is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.failure_detector.min_std_deviation]]
.causal_clustering.middleware.akka.failure_detector.min_std_deviation
[cols="<1s,<4"]
|===
|Description
a|Akka cluster phi accrual failure detector. Minimum standard deviation to use for the normal distribution in AccrualFailureDetector. Too low standard deviation might result in too much sensitivity for sudden, but normal, deviations in heartbeat inter arrival times.
|Valid values
a|causal_clustering.middleware.akka.failure_detector.min_std_deviation, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++100ms+++
|Internal
a|causal_clustering.middleware.akka.failure_detector.min_std_deviation is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.failure_detector.monitored_by_nr_of_members]]
.causal_clustering.middleware.akka.failure_detector.monitored_by_nr_of_members
[cols="<1s,<4"]
|===
|Description
a|Akka cluster phi accrual failure detector. Number of member nodes that each member will send heartbeat messages to, i.e. each node will be monitored by this number of other nodes.
|Valid values
a|causal_clustering.middleware.akka.failure_detector.monitored_by_nr_of_members, an integer
|Default value
m|+++5+++
|Internal
a|causal_clustering.middleware.akka.failure_detector.monitored_by_nr_of_members is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.failure_detector.threshold]]
.causal_clustering.middleware.akka.failure_detector.threshold
[cols="<1s,<4"]
|===
|Description
a|Akka cluster phi accrual failure detector. Defines the failure detector threshold. A low threshold is prone to generate many wrong suspicions but ensures a quick detection in the event of a real crash. Conversely, a high threshold generates fewer mistakes but needs more time to detect actual crashes.
|Valid values
a|causal_clustering.middleware.akka.failure_detector.threshold, a double
|Default value
m|+++12.0+++
|Internal
a|causal_clustering.middleware.akka.failure_detector.threshold is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.handshake_timeout]]
.causal_clustering.middleware.akka.handshake_timeout
[cols="<1s,<4"]
|===
|Description
a|Timeout for Akka handshake.
|Valid values
a|causal_clustering.middleware.akka.handshake_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++30s+++
|Internal
a|causal_clustering.middleware.akka.handshake_timeout is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.shutdown_timeout]]
.causal_clustering.middleware.akka.shutdown_timeout
[cols="<1s,<4"]
|===
|Description
a|Maximum timeout for akka shutdown.
|Valid values
a|causal_clustering.middleware.akka.shutdown_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++2m+++
|Internal
a|causal_clustering.middleware.akka.shutdown_timeout is an internal, unsupported setting.
|===

[[internal_causal_clustering.middleware.akka.sink_parallelism]]
.causal_clustering.middleware.akka.sink_parallelism
[cols="<1s,<4"]
|===
|Description
a|Parallelism level of dispatcher used for communication from Akka based cluster topology discovery.
|Valid values
a|causal_clustering.middleware.akka.sink_parallelism, an integer
|Default value
m|+++2+++
|Internal
a|causal_clustering.middleware.akka.sink_parallelism is an internal, unsupported setting.
|===

[[internal_causal_clustering.min_time_delay_id_reuse]]
.causal_clustering.min_time_delay_id_reuse
[cols="<1s,<4"]
|===
|Description
a|Minimum time to delay reuse of a deleted ID.
|Valid values
a|causal_clustering.min_time_delay_id_reuse, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++1m+++
|Internal
a|causal_clustering.min_time_delay_id_reuse is an internal, unsupported setting.
|===

[[internal_causal_clustering.raft_group_graveyard_state_size]]
.causal_clustering.raft_group_graveyard_state_size
[cols="<1s,<4"]
|===
|Description
a|The maximum file size before the raft group graveyard state file is rotated (in unit of entries)
|Valid values
a|causal_clustering.raft_group_graveyard_state_size, an integer
|Default value
m|+++10+++
|Internal
a|causal_clustering.raft_group_graveyard_state_size is an internal, unsupported setting.
|===

[[internal_causal_clustering.raft_in_queue_max_batch]]
.causal_clustering.raft_in_queue_max_batch
[cols="<1s,<4"]
|===
|Description
a|Largest batch processed by RAFT in number of entries.
|Valid values
a|causal_clustering.raft_in_queue_max_batch, an integer
|Default value
m|+++128+++
|Internal
a|causal_clustering.raft_in_queue_max_batch is an internal, unsupported setting.
|===

[[internal_causal_clustering.raft_in_queue_size]]
.causal_clustering.raft_in_queue_size
[cols="<1s,<4"]
|===
|Description
a|Maximum number of entries in the RAFT in-queue.
|Valid values
a|causal_clustering.raft_in_queue_size, an integer
|Default value
m|+++1024+++
|Internal
a|causal_clustering.raft_in_queue_size is an internal, unsupported setting.
|===

[[internal_causal_clustering.raft_messages_log_enable]]
.causal_clustering.raft_messages_log_enable
[cols="<1s,<4"]
|===
|Description
a|Enable or disable the dump of all network messages pertaining to the RAFT protocol.
|Valid values
a|causal_clustering.raft_messages_log_enable, a boolean
|Default value
m|+++false+++
|Internal
a|causal_clustering.raft_messages_log_enable is an internal, unsupported setting.
|===

[[internal_causal_clustering.raft_messages_log_path]]
.causal_clustering.raft_messages_log_path
[cols="<1s,<4"]
|===
|Description
a|Path to RAFT messages log.
|Valid values
a|causal_clustering.raft_messages_log_path, a path. If relative it is resolved from dbms.directories.logs
|Default value
m|+++raft-messages.log+++
|Internal
a|causal_clustering.raft_messages_log_path is an internal, unsupported setting.
|===

[[internal_causal_clustering.read_replica_transaction_applier_batch_size]]
.causal_clustering.read_replica_transaction_applier_batch_size
[cols="<1s,<4"]
|===
|Description
a|Threshold in Mb for when a downloaded batch of transactions for a read replicas should be incrementally applied. When a read replica has pulled transaction data overseeing this value they will be applied to the store.
|Valid values
a|causal_clustering.read_replica_transaction_applier_batch_size, an integer which is minimum `1`
|Default value
m|+++1+++
|Internal
a|causal_clustering.read_replica_transaction_applier_batch_size is an internal, unsupported setting.
|===

[[internal_causal_clustering.read_replica_transaction_applier_max_queue_size]]
.causal_clustering.read_replica_transaction_applier_max_queue_size
[cols="<1s,<4"]
|===
|Description
a|Maximum queued size of transactions in Mb to be applied. Pull update jobs will stop receiving new transactions when the limit is reached until the queue has been reduced.
|Valid values
a|causal_clustering.read_replica_transaction_applier_max_queue_size, an integer which is minimum `1`
|Default value
m|+++10+++
|Internal
a|causal_clustering.read_replica_transaction_applier_max_queue_size is an internal, unsupported setting.
|===

[[internal_causal_clustering.seed_validation_timeout]]
.causal_clustering.seed_validation_timeout
[cols="<1s,<4"]
|===
|Description
a|Specifies how long the seeding validation is allowed to keep trying to validate against remote before giving up.
|Valid values
a|causal_clustering.seed_validation_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10m+++
|Internal
a|causal_clustering.seed_validation_timeout is an internal, unsupported setting.
|===

[[internal_causal_clustering.store_copy_backoff_max_wait]]
.causal_clustering.store_copy_backoff_max_wait
[cols="<1s,<4"]
|===
|Description
a|Maximum backoff timeout for store copy requests.
|Valid values
a|causal_clustering.store_copy_backoff_max_wait, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++5s+++
|Internal
a|causal_clustering.store_copy_backoff_max_wait is an internal, unsupported setting.
|===

[[internal_causal_clustering.store_size_service_cache_timeout]]
.causal_clustering.store_size_service_cache_timeout
[cols="<1s,<4"]
|===
|Description
a|Timeout for database store size values stored in the cache.
|Valid values
a|causal_clustering.store_size_service_cache_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10s+++
|Internal
a|causal_clustering.store_size_service_cache_timeout is an internal, unsupported setting.
|===

[[internal_causal_clustering.temporary_database.extension_package_names]]
.causal_clustering.temporary_database.extension_package_names
[cols="<1s,<4"]
|===
|Description
a|Once temporary database is created, this parameter defines what extensions are loaded based on the package names.
|Valid values
a|causal_clustering.temporary_database.extension_package_names, a ',' separated set with elements of type 'a string'.
|Default value
m|+++com.neo4j,org.neo4j+++
|Internal
a|causal_clustering.temporary_database.extension_package_names is an internal, unsupported setting.
|===

[[internal_causal_clustering.topology_graph.default_num_primaries]]
.causal_clustering.topology_graph.default_num_primaries
[cols="<1s,<4"]
|===
|Description
a|Default number of primaries in Large Cluster.
|Valid values
a|causal_clustering.topology_graph.default_num_primaries, an integer which is minimum `2` and is maximum `11`
|Dynamic a|true
|Default value
m|+++3+++
|Internal
a|causal_clustering.topology_graph.default_num_primaries is an internal, unsupported setting.
|===

[[internal_causal_clustering.topology_graph.default_num_secondaries]]
.causal_clustering.topology_graph.default_num_secondaries
[cols="<1s,<4"]
|===
|Description
a|Default number of secondaries in Large Cluster.
|Valid values
a|causal_clustering.topology_graph.default_num_secondaries, an integer which is minimum `0` and is maximum `20`
|Dynamic a|true
|Default value
m|+++0+++
|Internal
a|causal_clustering.topology_graph.default_num_secondaries is an internal, unsupported setting.
|===

[[internal_causal_clustering.use_native_transport]]
.causal_clustering.use_native_transport
[cols="<1s,<4"]
|===
|Description
a|Use native transport if available. Epoll for Linux or Kqueue for MacOS/BSD. If this setting is set to false, or if native transport is not available, Nio transport will be used.
|Valid values
a|causal_clustering.use_native_transport, a boolean
|Default value
m|+++true+++
|Internal
a|causal_clustering.use_native_transport is an internal, unsupported setting.
|===

[[internal_dbms.capabilities.blocked]]
.dbms.capabilities.blocked
[cols="<1s,<4"]
|===
|Description
a|List of capabilities to block access from capabilities API or procedures. Each entry can be a wildcard expression containing '*' to match a single namespace entry and '**' to match any number of consequent namespace entries. For example 'dbms.*.version' would match any of the 'dbms.instance.version' or 'dbms.bolt.version' however would not match 'dbms.instance.kernel.version' - which could however be matched by 'dbms.**.version' pattern. Note that capability names comply with the regular expression '^\w+(.\w+)*$' (a word followed by any number of words, each separated by '.'.
|Valid values
a|dbms.capabilities.blocked, a ',' separated list with elements of type 'a string'.
|Dynamic a|true
|Default value
m|++++++
|Internal
a|dbms.capabilities.blocked is an internal, unsupported setting.
|===

[[internal_dbms.connector.bolt.tcp_keep_alive]]
.dbms.connector.bolt.tcp_keep_alive
[cols="<1s,<4"]
|===
|Description
a|Enable TCP keep alive probes on this connector.
|Valid values
a|dbms.connector.bolt.tcp_keep_alive, a boolean
|Default value
m|+++true+++
|Internal
a|dbms.connector.bolt.tcp_keep_alive is an internal, unsupported setting.
|===

[[internal_dbms.connector.bolt.unsupported_thread_pool_queue_size]]
.dbms.connector.bolt.unsupported_thread_pool_queue_size
[cols="<1s,<4"]
|===
|Description
a|The queue size of the thread pool bound to this connector (-1 for unbounded, 0 for direct handoff, > 0 for bounded)
|Valid values
a|dbms.connector.bolt.unsupported_thread_pool_queue_size, an integer
|Default value
m|+++0+++
|Internal
a|dbms.connector.bolt.unsupported_thread_pool_queue_size is an internal, unsupported setting.
|===

[[internal_dbms.connector.bolt.unsupported_unauth_connection_timeout]]
.dbms.connector.bolt.unsupported_unauth_connection_timeout
[cols="<1s,<4"]
|===
|Description
a|The maximum time to wait for a user to finish authentication before closing the connection.
|Valid values
a|dbms.connector.bolt.unsupported_unauth_connection_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++30s+++
|Internal
a|dbms.connector.bolt.unsupported_unauth_connection_timeout is an internal, unsupported setting.
|===

[[internal_dbms.connector.bolt.unsupported_unauth_max_inbound_bytes]]
.dbms.connector.bolt.unsupported_unauth_max_inbound_bytes
[cols="<1s,<4"]
|===
|Description
a|The maximum inbound message size in bytes are allowed before a connection is authenticated.
|Valid values
a|dbms.connector.bolt.unsupported_unauth_max_inbound_bytes, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`)
|Default value
m|+++8.00KiB+++
|Internal
a|dbms.connector.bolt.unsupported_unauth_max_inbound_bytes is an internal, unsupported setting.
|===

[[internal_dbms.directories.tx_log]]
.dbms.directories.tx_log
[cols="<1s,<4"]
|===
|Description
a|Location where Neo4j keeps the logical transaction logs.
|Valid values
a|dbms.directories.tx_log, a path. If relative it is resolved from unsupported.dbms.directories.databases.root
|Default value
m|+++neo4j+++
|Deprecated
a|The `dbms.directories.tx_log` configuration setting has been deprecated.
|Internal
a|dbms.directories.tx_log is an internal, unsupported setting.
|===

[[internal_dbms.init_file]]
.dbms.init_file
[cols="<1s,<4"]
|===
|Description
a|Name of file containing commands to be run during initialization of the system database. The file should exists in the scripts directory in neo4j home directory.
|Valid values
a|dbms.init_file, a path. If relative it is resolved from unsupported.dbms.directories.scripts
|Internal
a|dbms.init_file is an internal, unsupported setting.
|===

[[internal_dbms.log_inconsistent_data_deletion]]
.dbms.log_inconsistent_data_deletion
[cols="<1s,<4"]
|===
|Description
a|Whether or not to log contents of data that is inconsistent when deleting it.
|Valid values
a|dbms.log_inconsistent_data_deletion, a boolean
|Dynamic a|true
|Default value
m|+++false+++
|Internal
a|dbms.log_inconsistent_data_deletion is an internal, unsupported setting.
|===

[[internal_dbms.routing.driver.event_loop_count]]
.dbms.routing.driver.event_loop_count
[cols="<1s,<4"]
|===
|Description
a|Number of event loops used by drivers. Event loops are shard between drivers, so this is the total number of event loops created.
|Valid values
a|dbms.routing.driver.event_loop_count, an integer
|Default value
m|Number of available processors
|Internal
a|dbms.routing.driver.event_loop_count is an internal, unsupported setting.
|===

[[internal_dbms.routing.driver.idle_check_interval]]
.dbms.routing.driver.idle_check_interval
[cols="<1s,<4"]
|===
|Description
a|Time interval between driver idleness check.
|Valid values
a|dbms.routing.driver.idle_check_interval, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++1m+++
|Internal
a|dbms.routing.driver.idle_check_interval is an internal, unsupported setting.
|===

[[internal_dbms.routing.driver.logging.leaked_sessions]]
.dbms.routing.driver.logging.leaked_sessions
[cols="<1s,<4"]
|===
|Description
a|Enables logging of leaked driver session.
|Valid values
a|dbms.routing.driver.logging.leaked_sessions, a boolean
|Default value
m|+++false+++
|Internal
a|dbms.routing.driver.logging.leaked_sessions is an internal, unsupported setting.
|===

[[internal_dbms.routing.driver.timeout]]
.dbms.routing.driver.timeout
[cols="<1s,<4"]
|===
|Description
a|Time interval of inactivity after which a driver will be closed.
|Valid values
a|dbms.routing.driver.timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++1m+++
|Internal
a|dbms.routing.driver.timeout is an internal, unsupported setting.
|===

[[internal_dbms.security.property_level.blacklist]]
.dbms.security.property_level.blacklist
[cols="<1s,<4"]
|===
|Description
a|This can be achieved with `DENY READ {property} ON GRAPH * ELEMENTS * TO role`. Using this setting will prevent the server from starting.
|Valid values
a|dbms.security.property_level.blacklist, a string
|Deprecated
a|The `dbms.security.property_level.blacklist` configuration setting has been deprecated.
|Internal
a|dbms.security.property_level.blacklist is an internal, unsupported setting.
|===

[[internal_dbms.security.property_level.enabled]]
.dbms.security.property_level.enabled
[cols="<1s,<4"]
|===
|Description
a|This has been replaced by privilege management on roles. Setting it to true will prevent the server from starting.
|Valid values
a|dbms.security.property_level.enabled, a boolean
|Default value
m|+++false+++
|Deprecated
a|The `dbms.security.property_level.enabled` configuration setting has been deprecated.
|Internal
a|dbms.security.property_level.enabled is an internal, unsupported setting.
|===

[[internal_fabric.driver.event_loop_count]]
.fabric.driver.event_loop_count
[cols="<1s,<4"]
|===
|Description
a|Number of event loops used by drivers. Event loops are shard between drivers, so this is the total number of event loops created.
|Valid values
a|fabric.driver.event_loop_count, an integer
|Default value
m|Number of available processors
|Internal
a|fabric.driver.event_loop_count is an internal, unsupported setting.
|===

[[internal_fabric.driver.idle_check_interval]]
.fabric.driver.idle_check_interval
[cols="<1s,<4"]
|===
|Description
a|Time interval between driver idleness check.
|Valid values
a|fabric.driver.idle_check_interval, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++1m+++
|Internal
a|fabric.driver.idle_check_interval is an internal, unsupported setting.
|===

[[internal_fabric.driver.logging.leaked_sessions]]
.fabric.driver.logging.leaked_sessions
[cols="<1s,<4"]
|===
|Description
a|Enables logging of leaked driver session.
|Valid values
a|fabric.driver.logging.leaked_sessions, a boolean
|Default value
m|+++false+++
|Internal
a|fabric.driver.logging.leaked_sessions is an internal, unsupported setting.
|===

[[internal_fabric.driver.timeout]]
.fabric.driver.timeout
[cols="<1s,<4"]
|===
|Description
a|Time interval of inactivity after which a driver will be closed.
|Valid values
a|fabric.driver.timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++1m+++
|Internal
a|fabric.driver.timeout is an internal, unsupported setting.
|===

[[internal_fabric.enabled_by_default]]
.fabric.enabled_by_default
[cols="<1s,<4"]
|===
|Description
a|Toggle if fabric is enabled by default.
|Valid values
a|fabric.enabled_by_default, a boolean
|Default value
m|+++true+++
|Internal
a|fabric.enabled_by_default is an internal, unsupported setting.
|===

[[internal_fabric.stream.batch_size]]
.fabric.stream.batch_size
[cols="<1s,<4"]
|===
|Description
a|Batch size used when requesting records from local Cypher engine.
|Valid values
a|fabric.stream.batch_size, an integer which is minimum `1`
|Default value
m|+++50+++
|Internal
a|fabric.stream.batch_size is an internal, unsupported setting.
|===

[[internal_unsupported.causal_clustering.cluster_status_request_maximum_wait]]
.unsupported.causal_clustering.cluster_status_request_maximum_wait
[cols="<1s,<4"]
|===
|Description
a|Maximum timeout for cluster status request execution.
|Valid values
a|unsupported.causal_clustering.cluster_status_request_maximum_wait, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++5s+++
|Internal
a|unsupported.causal_clustering.cluster_status_request_maximum_wait is an internal, unsupported setting.
|===

[[internal_unsupported.causal_clustering.experimental_catchup_protocol_enabled]]
.unsupported.causal_clustering.experimental_catchup_protocol_enabled
[cols="<1s,<4"]
|===
|Description
a|Usage of an experimental catchup protocol.
|Valid values
a|unsupported.causal_clustering.experimental_catchup_protocol_enabled, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.causal_clustering.experimental_catchup_protocol_enabled is an internal, unsupported setting.
|===

[[internal_unsupported.causal_clustering.experimental_raft_protocol_enabled]]
.unsupported.causal_clustering.experimental_raft_protocol_enabled
[cols="<1s,<4"]
|===
|Description
a|Usage of an experimental raft protocol.
|Valid values
a|unsupported.causal_clustering.experimental_raft_protocol_enabled, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.causal_clustering.experimental_raft_protocol_enabled is an internal, unsupported setting.
|===

[[internal_unsupported.causal_clustering.inbound_connection_initialization_logging_enabled]]
.unsupported.causal_clustering.inbound_connection_initialization_logging_enabled
[cols="<1s,<4"]
|===
|Description
a|Enable logging for inbound connection initialization.
|Valid values
a|unsupported.causal_clustering.inbound_connection_initialization_logging_enabled, a boolean
|Dynamic a|true
|Default value
m|+++true+++
|Internal
a|unsupported.causal_clustering.inbound_connection_initialization_logging_enabled is an internal, unsupported setting.
|===

[[internal_unsupported.consistency_checker.fail_fast_threshold]]
.unsupported.consistency_checker.fail_fast_threshold
[cols="<1s,<4"]
|===
|Description
a|Specifies if the consistency checker should stop when number of observed inconsistencies exceed the threshold. If the value is zero, all inconsistencies will be reported.
|Valid values
a|unsupported.consistency_checker.fail_fast_threshold, an integer which is minimum `0`
|Default value
m|+++0+++
|Internal
a|unsupported.consistency_checker.fail_fast_threshold is an internal, unsupported setting.
|===

[[internal_unsupported.consistency_checker.memory_limit_factor]]
.unsupported.consistency_checker.memory_limit_factor
[cols="<1s,<4"]
|===
|Description
a|Limits the maximum amount of off-heap memory the consistency checker will allocate. The value is given as a factor between 0.1 .. 1 and will be multiplied with actual available memory to get the effectively available amount of memory taken into consideration.
|Valid values
a|unsupported.consistency_checker.memory_limit_factor, a double which is minimum `0.1` and is maximum `1.0`
|Default value
m|+++0.9+++
|Internal
a|unsupported.consistency_checker.memory_limit_factor is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.compiler_tracing]]
.unsupported.cypher.compiler_tracing
[cols="<1s,<4"]
|===
|Description
a|Enable tracing of compilation in cypher.
|Valid values
a|unsupported.cypher.compiler_tracing, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.cypher.compiler_tracing is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.enable_extra_semantic_features]]
.unsupported.cypher.enable_extra_semantic_features
[cols="<1s,<4"]
|===
|Description
a|Enables extra SemanticFeature:s during cypher semantic checking.
|Valid values
a|unsupported.cypher.enable_extra_semantic_features, a ',' separated set with elements of type 'a string'.
|Default value
m|++++++
|Internal
a|unsupported.cypher.enable_extra_semantic_features is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.enable_runtime_monitors]]
.unsupported.cypher.enable_runtime_monitors
[cols="<1s,<4"]
|===
|Description
a|Set this to enable monitors in the Cypher runtime.
|Valid values
a|unsupported.cypher.enable_runtime_monitors, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.cypher.enable_runtime_monitors is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.expression_engine]]
.unsupported.cypher.expression_engine
[cols="<1s,<4"]
|===
|Description
a|Choose the expression engine. The default is to only compile expressions that are hot, if 'COMPILED' is chosen all expressions will be compiled directly and if 'INTERPRETED' is chosen expressions will never be compiled.
|Valid values
a|unsupported.cypher.expression_engine, one of [DEFAULT, INTERPRETED, COMPILED, ONLY_WHEN_HOT]
|Default value
m|+++DEFAULT+++
|Internal
a|unsupported.cypher.expression_engine is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.expression_recompilation_limit]]
.unsupported.cypher.expression_recompilation_limit
[cols="<1s,<4"]
|===
|Description
a|Number of uses before an expression is considered for compilation.
|Valid values
a|unsupported.cypher.expression_recompilation_limit, an integer which is minimum `0`
|Default value
m|+++10+++
|Internal
a|unsupported.cypher.expression_recompilation_limit is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.idp_solver_duration_threshold]]
.unsupported.cypher.idp_solver_duration_threshold
[cols="<1s,<4"]
|===
|Description
a|To improve IDP query planning time, we can restrict the internal planning loop duration, triggering more frequent compaction of candidate plans. The smaller the threshold the faster the planning, but the higher the risk of sub-optimal plans.
|Valid values
a|unsupported.cypher.idp_solver_duration_threshold, a long which is minimum `10`
|Default value
m|+++1000+++
|Internal
a|unsupported.cypher.idp_solver_duration_threshold is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.idp_solver_table_threshold]]
.unsupported.cypher.idp_solver_table_threshold
[cols="<1s,<4"]
|===
|Description
a|To improve IDP query planning time, we can restrict the internal planning table size, triggering compaction of candidate plans. The smaller the threshold the faster the planning, but the higher the risk of sub-optimal plans.
|Valid values
a|unsupported.cypher.idp_solver_table_threshold, an integer which is minimum `16`
|Default value
m|+++128+++
|Internal
a|unsupported.cypher.idp_solver_table_threshold is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.non_indexed_label_warning_threshold]]
.unsupported.cypher.non_indexed_label_warning_threshold
[cols="<1s,<4"]
|===
|Description
a|The threshold when a warning is generated if a label scan is done after a load csv where the label has no index.
|Valid values
a|unsupported.cypher.non_indexed_label_warning_threshold, a long
|Default value
m|+++10000+++
|Internal
a|unsupported.cypher.non_indexed_label_warning_threshold is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.number_of_workers]]
.unsupported.cypher.number_of_workers
[cols="<1s,<4"]
|===
|Description
a|Number of threads to allocate to Cypher worker threads for the parallel runtime. If set to 0, two workers will be started for every physical core in the system. If set to -1, no workers will be started and the parallel runtime cannot be used.
|Valid values
a|unsupported.cypher.number_of_workers, an integer
|Default value
m|+++0+++
|Internal
a|unsupported.cypher.number_of_workers is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.parser]]
.unsupported.cypher.parser
[cols="<1s,<4"]
|===
|Description
a|The parser implementation to use for parsing cypher queries.
|Valid values
a|unsupported.cypher.parser, one of [DEFAULT, PARBOILED, JAVACC]
|Default value
m|+++DEFAULT+++
|Internal
a|unsupported.cypher.parser is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.pipelined.batch_size_big]]
.unsupported.cypher.pipelined.batch_size_big
[cols="<1s,<4"]
|===
|Description
a|The size of batches in the pipelined runtime for queries which work with many rows.
|Valid values
a|unsupported.cypher.pipelined.batch_size_big, an integer which is minimum `1`
|Default value
m|+++1024+++
|Internal
a|unsupported.cypher.pipelined.batch_size_big is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.pipelined.batch_size_small]]
.unsupported.cypher.pipelined.batch_size_small
[cols="<1s,<4"]
|===
|Description
a|The size of batches in the pipelined runtime for queries which work with few rows.
|Valid values
a|unsupported.cypher.pipelined.batch_size_small, an integer which is minimum `1`
|Default value
m|+++128+++
|Internal
a|unsupported.cypher.pipelined.batch_size_small is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.pipelined.enable_runtime_trace]]
.unsupported.cypher.pipelined.enable_runtime_trace
[cols="<1s,<4"]
|===
|Description
a|Enable tracing of pipelined runtime scheduler.
|Valid values
a|unsupported.cypher.pipelined.enable_runtime_trace, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.cypher.pipelined.enable_runtime_trace is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.pipelined.operator_engine]]
.unsupported.cypher.pipelined.operator_engine
[cols="<1s,<4"]
|===
|Description
a|For compiled execution, specialized code is generated and then executed. More optimizations such as operator fusion may apply. Operator fusion means that multiple operators such as for example AllNodesScan -> Filter -> ProduceResult can be compiled into a single specialized operator. This setting only applies to the pipelined and parallel runtime. Allowed values are "default" (the default, use compiled when applicable), "compiled" and "interpreted".
|Valid values
a|unsupported.cypher.pipelined.operator_engine, one of [DEFAULT, COMPILED, INTERPRETED]
|Default value
m|+++DEFAULT+++
|Internal
a|unsupported.cypher.pipelined.operator_engine is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.pipelined.operator_fusion_over_pipeline_limit]]
.unsupported.cypher.pipelined.operator_fusion_over_pipeline_limit
[cols="<1s,<4"]
|===
|Description
a|The maximum number of operator fusions over pipelines (i.e. where an operator that would normally be considered pipeline-breaking, e.g. expand), that is considered before a pipeline break is forced.
|Valid values
a|unsupported.cypher.pipelined.operator_fusion_over_pipeline_limit, an integer
|Default value
m|+++8+++
|Internal
a|unsupported.cypher.pipelined.operator_fusion_over_pipeline_limit is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.pipelined.runtime_trace_path]]
.unsupported.cypher.pipelined.runtime_trace_path
[cols="<1s,<4"]
|===
|Description
a|Path to the pipelined runtime scheduler trace. If 'stdOut' and tracing is on, will print to std out.
|Valid values
a|unsupported.cypher.pipelined.runtime_trace_path, a path. If relative it is resolved from dbms.directories.neo4j_home
|Default value
m|+++stdOut+++
|Internal
a|unsupported.cypher.pipelined.runtime_trace_path is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.pipelined_interpreted_pipes_fallback]]
.unsupported.cypher.pipelined_interpreted_pipes_fallback
[cols="<1s,<4"]
|===
|Description
a|Use interpreted pipes as a fallback for operators that do not have a specialized implementation in the pipelined runtime. Allowed values are "disabled", "default" (the default, use whitelisted_plans_only when applicable), "whitelisted_plans_only" and "all" (experimental). The default is to enable the use of a subset of whitelisted operators that are known to be supported, whereas "all" is an experimental option that enables the fallback to be used for all possible operators that are not known to be unsupported.
|Valid values
a|unsupported.cypher.pipelined_interpreted_pipes_fallback, one of [DISABLED, DEFAULT, ALL, WHITELISTED_PLANS_ONLY]
|Default value
m|+++DEFAULT+++
|Internal
a|unsupported.cypher.pipelined_interpreted_pipes_fallback is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.planning_point_indexes_enabled]]
.unsupported.cypher.planning_point_indexes_enabled
[cols="<1s,<4"]
|===
|Description
a|Feature flag to enable/disable planning use of point indexes.
|Valid values
a|unsupported.cypher.planning_point_indexes_enabled, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.cypher.planning_point_indexes_enabled is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.planning_range_indexes_enabled]]
.unsupported.cypher.planning_range_indexes_enabled
[cols="<1s,<4"]
|===
|Description
a|Feature flag to enable/disable planning use of range indexes.
|Valid values
a|unsupported.cypher.planning_range_indexes_enabled, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.cypher.planning_range_indexes_enabled is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.planning_text_indexes_enabled]]
.unsupported.cypher.planning_text_indexes_enabled
[cols="<1s,<4"]
|===
|Description
a|Feature flag to enable/disable planning use of text indexes.
|Valid values
a|unsupported.cypher.planning_text_indexes_enabled, a boolean
|Default value
m|+++true+++
|Internal
a|unsupported.cypher.planning_text_indexes_enabled is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.predicates_as_union_max_size]]
.unsupported.cypher.predicates_as_union_max_size
[cols="<1s,<4"]
|===
|Description
a|Maximum size after which the planner will not attempt to plan the disjunction of predicates on a single variable as a distinct union.For example, given the following pattern: `()-[e:FOO{vbar}BAR{vbar}BAZ]->()`, the planner will attempt to plan a union of `e:Foo`, `e:Bar`, and `e:Baz`unless ``unsupported.cypher.predicates_as_union_max_size`` is less than 3.
|Valid values
a|unsupported.cypher.predicates_as_union_max_size, an integer which is minimum `0`
|Default value
m|+++255+++
|Internal
a|unsupported.cypher.predicates_as_union_max_size is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.replan_algorithm]]
.unsupported.cypher.replan_algorithm
[cols="<1s,<4"]
|===
|Description
a|Large databases might change slowly, and to prevent queries from never being replanned the divergence threshold set by cypher.statistics_divergence_threshold is configured to shrink over time using the algorithm set here. This will cause the threshold to reach the value set by <<config_unsupported.cypher.statistics_divergence_target,unsupported.cypher.statistics_divergence_target>> once the time since the previous replanning has reached the value set in <<config_unsupported.cypher.target_replan_interval,unsupported.cypher.target_replan_interval>>. Setting the algorithm to 'none' will cause the threshold to not decay over time.
|Valid values
a|unsupported.cypher.replan_algorithm, one of [DEFAULT, NONE, INVERSE, EXPONENTIAL]
|Default value
m|+++DEFAULT+++
|Internal
a|unsupported.cypher.replan_algorithm is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.runtime]]
.unsupported.cypher.runtime
[cols="<1s,<4"]
|===
|Description
a|Set this to specify the default runtime for the default language version.
|Valid values
a|unsupported.cypher.runtime, one of [DEFAULT, INTERPRETED, SLOTTED, PIPELINED]
|Default value
m|+++DEFAULT+++
|Internal
a|unsupported.cypher.runtime is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.splitting_top_behavior]]
.unsupported.cypher.splitting_top_behavior
[cols="<1s,<4"]
|===
|Description
a|Determines whether the planner is allowed to push down the sort portion of an ORDER BY + LIMIT combination.
|Valid values
a|unsupported.cypher.splitting_top_behavior, one of [DEFAULT, DISALLOW]
|Default value
m|+++DEFAULT+++
|Internal
a|unsupported.cypher.splitting_top_behavior is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.statistics_divergence_target]]
.unsupported.cypher.statistics_divergence_target
[cols="<1s,<4"]
|===
|Description
a|Large databases might change slowly, and so to prevent queries from never being replanned the divergence threshold set by cypher.statistics_divergence_threshold is configured to shrink over time. The algorithm used to manage this change is set by <<config_unsupported.cypher.replan_algorithm,unsupported.cypher.replan_algorithm>> and will cause the threshold to reach the value set here once the time since the previous replanning has reached <<config_unsupported.cypher.target_replan_interval,unsupported.cypher.target_replan_interval>>. Setting this value to higher than the cypher.statistics_divergence_threshold will cause the threshold to not decay over time.
|Valid values
a|unsupported.cypher.statistics_divergence_target, a double which is in the range `0.0` to `1.0`
|Default value
m|+++0.1+++
|Internal
a|unsupported.cypher.statistics_divergence_target is an internal, unsupported setting.
|===

[[internal_unsupported.cypher.target_replan_interval]]
.unsupported.cypher.target_replan_interval
[cols="<1s,<4"]
|===
|Description
a|Large databases might change slowly, and to prevent queries from never being replanned the divergence threshold set by cypher.statistics_divergence_threshold is configured to shrink over time. The algorithm used to manage this change is set by <<config_unsupported.cypher.replan_algorithm,unsupported.cypher.replan_algorithm>> and will cause the threshold to reach the value set by <<config_unsupported.cypher.statistics_divergence_target,unsupported.cypher.statistics_divergence_target>> once the time since the previous replanning has reached the value set here. Setting this value to less than the value of cypher.min_replan_interval will cause the threshold to not decay over time.
|Valid values
a|unsupported.cypher.target_replan_interval, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++7h+++
|Internal
a|unsupported.cypher.target_replan_interval is an internal, unsupported setting.
|===

[[internal_unsupported.datacollector.max_query_text_size]]
.unsupported.datacollector.max_query_text_size
[cols="<1s,<4"]
|===
|Description
a|Sets the upper limit for how much of the query text that will be retained by the query collector. For queries longer than the limit, only a prefix of size limit will be retained by the collector. Lowering this value will reduce the memory footprint of collected query invocations under loads with many queries with long query texts, which could occur for generated queries. The downside is that on retrieving queries by `db.stats.retrieve`, queries longer than this max size would be returned incomplete. Setting this to 0 will completely drop query texts from the collected queries.
|Valid values
a|unsupported.datacollector.max_query_text_size, an integer which is minimum `0`
|Default value
m|+++10000+++
|Internal
a|unsupported.datacollector.max_query_text_size is an internal, unsupported setting.
|===

[[internal_unsupported.datacollector.max_recent_query_count]]
.unsupported.datacollector.max_recent_query_count
[cols="<1s,<4"]
|===
|Description
a|Max number of recent queries to collect in the data collector module. Will round down to the nearest power of two. The default number (8192 query invocations)  was chosen as a trade-off between getting a useful amount of queries, and not wasting too much heap. Even with a buffer full of unique queries, the estimated footprint lies in tens of MBs. If the buffer is full of cached queries, the retained size was measured to 265 kB. Setting this to 0 will disable data collection of queries completely.
|Valid values
a|unsupported.datacollector.max_recent_query_count, an integer which is minimum `0`
|Default value
m|+++8192+++
|Internal
a|unsupported.datacollector.max_recent_query_count is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.block_alter_database]]
.unsupported.dbms.block_alter_database
[cols="<1s,<4"]
|===
|Description
a|Enable or disable the ability to alter databases.
|Valid values
a|unsupported.dbms.block_alter_database, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.block_alter_database is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.block_create_drop_database]]
.unsupported.dbms.block_create_drop_database
[cols="<1s,<4"]
|===
|Description
a|Enable or disable the ability to create and drop databases.
|Valid values
a|unsupported.dbms.block_create_drop_database, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.block_create_drop_database is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.block_remote_alias]]
.unsupported.dbms.block_remote_alias
[cols="<1s,<4"]
|===
|Description
a|Enable or disable the ability to use remote aliases.
|Valid values
a|unsupported.dbms.block_remote_alias, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.block_remote_alias is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.block_size.array_properties]]
.unsupported.dbms.block_size.array_properties
[cols="<1s,<4"]
|===
|Description
a|Specifies the block size for storing arrays. This parameter is only honored when the store is created, otherwise it is ignored. Also note that each block carries a ~10B of overhead so record size on disk will be slightly larger than the configured block size.
|Valid values
a|unsupported.dbms.block_size.array_properties, an integer which is minimum `0`
|Default value
m|+++0+++
|Internal
a|unsupported.dbms.block_size.array_properties is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.block_size.labels]]
.unsupported.dbms.block_size.labels
[cols="<1s,<4"]
|===
|Description
a|Specifies the block size for storing labels exceeding in-lined space in node record. This parameter is only honored when the store is created, otherwise it is ignored. Also note that each block carries a ~10B of overhead so record size on disk will be slightly larger than the configured block size.
|Valid values
a|unsupported.dbms.block_size.labels, an integer which is minimum `0`
|Default value
m|+++0+++
|Internal
a|unsupported.dbms.block_size.labels is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.block_size.strings]]
.unsupported.dbms.block_size.strings
[cols="<1s,<4"]
|===
|Description
a|Specifies the block size for storing strings. This parameter is only honored when the store is created, otherwise it is ignored. Note that each character in a string occupies two bytes, meaning that e.g a block size of 120 will hold a 60 character long string before overflowing into a second block. Also note that each block carries a ~10B of overhead so record size on disk will be slightly larger than the configured block size.
|Valid values
a|unsupported.dbms.block_size.strings, an integer which is minimum `0`
|Default value
m|+++0+++
|Internal
a|unsupported.dbms.block_size.strings is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.block_start_stop_database]]
.unsupported.dbms.block_start_stop_database
[cols="<1s,<4"]
|===
|Description
a|Enable or disable the ability to start and stop databases.
|Valid values
a|unsupported.dbms.block_start_stop_database, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.block_start_stop_database is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.bolt.inbound_message_throttle.high_watermark]]
.unsupported.dbms.bolt.inbound_message_throttle.high_watermark
[cols="<1s,<4"]
|===
|Description
a|When the number of queued inbound messages grows beyond this value, reading from underlying channel will be paused (no more inbound messages will be available) until queued number of messages drops below the configured low watermark value.
|Valid values
a|unsupported.dbms.bolt.inbound_message_throttle.high_watermark, an integer which is in the range `1` to `2147483647`
|Default value
m|+++300+++
|Internal
a|unsupported.dbms.bolt.inbound_message_throttle.high_watermark is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.bolt.inbound_message_throttle.low_watermark]]
.unsupported.dbms.bolt.inbound_message_throttle.low_watermark
[cols="<1s,<4"]
|===
|Description
a|When the number of queued inbound messages, previously reached configured high watermark value, drops below this value, reading from underlying channel will be enabled and any pending messages will start queuing again.
|Valid values
a|unsupported.dbms.bolt.inbound_message_throttle.low_watermark, an integer which is in the range `1` to `2147483647`
|Default value
m|+++100+++
|Internal
a|unsupported.dbms.bolt.inbound_message_throttle.low_watermark is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.bolt.netty_message_merge_cumulator]]
.unsupported.dbms.bolt.netty_message_merge_cumulator
[cols="<1s,<4"]
|===
|Description
a|Enable/disable the use of a merge cumulator for netty.
|Valid values
a|unsupported.dbms.bolt.netty_message_merge_cumulator, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.bolt.netty_message_merge_cumulator is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.bolt.netty_server_shutdown_quiet_period]]
.unsupported.dbms.bolt.netty_server_shutdown_quiet_period
[cols="<1s,<4"]
|===
|Description
a|Quiet period for netty shutdown.
|Valid values
a|unsupported.dbms.bolt.netty_server_shutdown_quiet_period, an integer
|Default value
m|+++5+++
|Internal
a|unsupported.dbms.bolt.netty_server_shutdown_quiet_period is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.bolt.netty_server_shutdown_timeout]]
.unsupported.dbms.bolt.netty_server_shutdown_timeout
[cols="<1s,<4"]
|===
|Description
a|Timeout for netty shutdown.
|Valid values
a|unsupported.dbms.bolt.netty_server_shutdown_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++15s+++
|Internal
a|unsupported.dbms.bolt.netty_server_shutdown_timeout is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.bolt.netty_server_use_epoll]]
.unsupported.dbms.bolt.netty_server_use_epoll
[cols="<1s,<4"]
|===
|Description
a|Enable/disable the use of Epoll for netty.
|Valid values
a|unsupported.dbms.bolt.netty_server_use_epoll, a boolean
|Default value
m|+++true+++
|Internal
a|unsupported.dbms.bolt.netty_server_use_epoll is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.bolt.outbound_buffer_throttle]]
.unsupported.dbms.bolt.outbound_buffer_throttle
[cols="<1s,<4"]
|===
|Description
a|Whether to apply network level outbound network buffer based throttling.
|Valid values
a|unsupported.dbms.bolt.outbound_buffer_throttle, a boolean
|Default value
m|+++true+++
|Internal
a|unsupported.dbms.bolt.outbound_buffer_throttle is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.bolt.outbound_buffer_throttle.high_watermark]]
.unsupported.dbms.bolt.outbound_buffer_throttle.high_watermark
[cols="<1s,<4"]
|===
|Description
a|When the size (in bytes) of outbound network buffers, used by bolt's network layer, grows beyond this value bolt channel will advertise itself as unwritable and will block related processing thread until it becomes writable again.
|Valid values
a|unsupported.dbms.bolt.outbound_buffer_throttle.high_watermark, an integer which is in the range `65536` to `2147483647`
|Default value
m|+++524288+++
|Internal
a|unsupported.dbms.bolt.outbound_buffer_throttle.high_watermark is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.bolt.outbound_buffer_throttle.low_watermark]]
.unsupported.dbms.bolt.outbound_buffer_throttle.low_watermark
[cols="<1s,<4"]
|===
|Description
a|When the size (in bytes) of outbound network buffers, previously advertised as unwritable, gets below this value bolt channel will re-advertise itself as writable and blocked processing thread will resume execution.
|Valid values
a|unsupported.dbms.bolt.outbound_buffer_throttle.low_watermark, an integer which is in the range `16384` to `2147483647`
|Default value
m|+++131072+++
|Internal
a|unsupported.dbms.bolt.outbound_buffer_throttle.low_watermark is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.bolt.outbound_buffer_throttle.max_duration]]
.unsupported.dbms.bolt.outbound_buffer_throttle.max_duration
[cols="<1s,<4"]
|===
|Description
a|When the total time outbound network buffer based throttle lock is held exceeds this value, the corresponding bolt channel will be aborted. Setting this to 0 will disable this behaviour.
|Valid values
a|unsupported.dbms.bolt.outbound_buffer_throttle.max_duration, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`) which is minimum `30s` or is `0s`
|Default value
m|+++15m+++
|Internal
a|unsupported.dbms.bolt.outbound_buffer_throttle.max_duration is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.checkpoint_log.rotation.keep.files]]
.unsupported.dbms.checkpoint_log.rotation.keep.files
[cols="<1s,<4"]
|===
|Description
a|Number of checkpoint logs files to keep.
|Valid values
a|unsupported.dbms.checkpoint_log.rotation.keep.files, an integer which is in the range `2` to `100`
|Default value
m|+++3+++
|Internal
a|unsupported.dbms.checkpoint_log.rotation.keep.files is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.checkpoint_log.rotation.size]]
.unsupported.dbms.checkpoint_log.rotation.size
[cols="<1s,<4"]
|===
|Description
a|Specifies at which file size the checkpoint log will auto-rotate. Minimum accepted value is 1 KiB.
|Valid values
a|unsupported.dbms.checkpoint_log.rotation.size, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`) which is minimum `1.00KiB`
|Default value
m|+++1.00MiB+++
|Internal
a|unsupported.dbms.checkpoint_log.rotation.size is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.config.command_evaluation_timeout]]
.unsupported.dbms.config.command_evaluation_timeout
[cols="<1s,<4"]
|===
|Description
a|Timeout for configuration command evaluation, per command.
|Valid values
a|unsupported.dbms.config.command_evaluation_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++30s+++
|Internal
a|unsupported.dbms.config.command_evaluation_timeout is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.counts_store_rotation_timeout]]
.unsupported.dbms.counts_store_rotation_timeout
[cols="<1s,<4"]
|===
|Description
a|Maximum time to wait for active transaction completion when rotating counts store.
|Valid values
a|unsupported.dbms.counts_store_rotation_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10m+++
|Internal
a|unsupported.dbms.counts_store_rotation_timeout is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.cypher_ip_blocklist]]
.unsupported.dbms.cypher_ip_blocklist
[cols="<1s,<4"]
|===
|Description
a|A list of CIDR-notation IPv4 or IPv6 addresses to block when accessing URLs.This list is checked when LOAD CSV or apoc.load.json is called.
|Valid values
a|unsupported.dbms.cypher_ip_blocklist, a ',' separated list with elements of type 'an ip with subnet in CDIR format. e.g. 127.168.0.1/8'.
|Default value
m|++++++
|Internal
a|unsupported.dbms.cypher_ip_blocklist is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.debug.page_cache_tracer_speed_reporting_threshold]]
.unsupported.dbms.debug.page_cache_tracer_speed_reporting_threshold
[cols="<1s,<4"]
|===
|Description
a|Reporting interval for page cache speed logging.
|Valid values
a|unsupported.dbms.debug.page_cache_tracer_speed_reporting_threshold, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++10s+++
|Internal
a|unsupported.dbms.debug.page_cache_tracer_speed_reporting_threshold is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.debug.print_page_buffer_allocation_trace]]
.unsupported.dbms.debug.print_page_buffer_allocation_trace
[cols="<1s,<4"]
|===
|Description
a|Print stack trace on failed native io buffer allocation.
|Valid values
a|unsupported.dbms.debug.print_page_buffer_allocation_trace, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.debug.print_page_buffer_allocation_trace is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.debug.trace_cursors]]
.unsupported.dbms.debug.trace_cursors
[cols="<1s,<4"]
|===
|Description
a|Trace unclosed cursors.
|Valid values
a|unsupported.dbms.debug.trace_cursors, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.debug.trace_cursors is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.debug.trace_tx_statement]]
.unsupported.dbms.debug.trace_tx_statement
[cols="<1s,<4"]
|===
|Description
a|Trace open/close transaction statements.
|Valid values
a|unsupported.dbms.debug.trace_tx_statement, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.debug.trace_tx_statement is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.debug.track_cursor_close]]
.unsupported.dbms.debug.track_cursor_close
[cols="<1s,<4"]
|===
|Description
a|Validate if cursors are properly closed.
|Valid values
a|unsupported.dbms.debug.track_cursor_close, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.debug.track_cursor_close is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.debug.track_tx_statement_close]]
.unsupported.dbms.debug.track_tx_statement_close
[cols="<1s,<4"]
|===
|Description
a|Validate if transaction statements are properly closed.
|Valid values
a|unsupported.dbms.debug.track_tx_statement_close, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.debug.track_tx_statement_close is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.directories.auth]]
.unsupported.dbms.directories.auth
[cols="<1s,<4"]
|===
|Description
a|Location of the auth store repository directory.
|Valid values
a|unsupported.dbms.directories.auth, a path. If relative it is resolved from dbms.directories.data
|Default value
m|+++dbms+++
|Internal
a|unsupported.dbms.directories.auth is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.directories.databases.root]]
.unsupported.dbms.directories.databases.root
[cols="<1s,<4"]
|===
|Description
a|Path of the databases directory.
|Valid values
a|unsupported.dbms.directories.databases.root, a path. If relative it is resolved from dbms.directories.data
|Default value
m|+++databases+++
|Internal
a|unsupported.dbms.directories.databases.root is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.directories.pid_file]]
.unsupported.dbms.directories.pid_file
[cols="<1s,<4"]
|===
|Description
a|Path of the pid file.
|Valid values
a|unsupported.dbms.directories.pid_file, a path. If relative it is resolved from dbms.directories.run
|Default value
m|+++neo4j.pid+++
|Internal
a|unsupported.dbms.directories.pid_file is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.directories.scripts]]
.unsupported.dbms.directories.scripts
[cols="<1s,<4"]
|===
|Description
a|Location of the database scripts directory.
|Valid values
a|unsupported.dbms.directories.scripts, a path. If relative it is resolved from dbms.directories.neo4j_home
|Default value
m|+++scripts+++
|Internal
a|unsupported.dbms.directories.scripts is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.directories.windows_tools]]
.unsupported.dbms.directories.windows_tools
[cols="<1s,<4"]
|===
|Description
a|Path of the lib directory.
|Valid values
a|unsupported.dbms.directories.windows_tools, a path. If relative it is resolved from dbms.directories.neo4j_home
|Default value
m|+++bin/tools+++
|Internal
a|unsupported.dbms.directories.windows_tools is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.discoverable_bolt_address]]
.unsupported.dbms.discoverable_bolt_address
[cols="<1s,<4"]
|===
|Description
a|Publicly discoverable bolt:// URI to use for Neo4j Drivers wanting to access the data in this particular database instance. Normally this is the same as the advertised address configured for the connector, but this allows manually overriding that default.
|Valid values
a|unsupported.dbms.discoverable_bolt_address, a URI
|Default value
m|Defaults to a bolt://-schemed version of the advertised address of the first found bolt connector.
|Internal
a|unsupported.dbms.discoverable_bolt_address is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.discoverable_bolt_routing_address]]
.unsupported.dbms.discoverable_bolt_routing_address
[cols="<1s,<4"]
|===
|Description
a|Publicly discoverable neo4j:// URI to use for Neo4j Drivers wanting to access a cluster or a single instance.
|Valid values
a|unsupported.dbms.discoverable_bolt_routing_address, a URI
|Default value
m|Defaults to empty on any deployment that is not a causal cluster core, and a neo4j://-schemed URI of the advertised address of the bolt connector.
|Internal
a|unsupported.dbms.discoverable_bolt_routing_address is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.dump_diagnostics]]
.unsupported.dbms.dump_diagnostics
[cols="<1s,<4"]
|===
|Description
a|Whether or not to dump system and database diagnostics. This takes a non-negligible amount of time to do and therefore test databases can disable this to reduce startup times.
|Valid values
a|unsupported.dbms.dump_diagnostics, a boolean
|Default value
m|+++true+++
|Internal
a|unsupported.dbms.dump_diagnostics is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.enable_transaction_heap_allocation_tracking]]
.unsupported.dbms.enable_transaction_heap_allocation_tracking
[cols="<1s,<4"]
|===
|Description
a|Track heap memory allocations for transactions.
|Valid values
a|unsupported.dbms.enable_transaction_heap_allocation_tracking, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.enable_transaction_heap_allocation_tracking is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.executiontime_limit.time]]
.unsupported.dbms.executiontime_limit.time
[cols="<1s,<4"]
|===
|Description
a|If execution time limiting is enabled in the database, this configures the maximum request execution time. Please use dbms.transaction.timeout instead.
|Valid values
a|unsupported.dbms.executiontime_limit.time, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Deprecated
a|The `unsupported.dbms.executiontime_limit.time` configuration setting has been deprecated.
|Internal
a|unsupported.dbms.executiontime_limit.time is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.extra_lock_verification]]
.unsupported.dbms.extra_lock_verification
[cols="<1s,<4"]
|===
|Description
a|Whether or not to do additional checks for locks when making changes as part of commit. This may be expensive to enable.
|Valid values
a|unsupported.dbms.extra_lock_verification, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.extra_lock_verification is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.force_small_id_cache]]
.unsupported.dbms.force_small_id_cache
[cols="<1s,<4"]
|===
|Description
a|Forces smaller ID cache, in order to preserve memory.
|Valid values
a|unsupported.dbms.force_small_id_cache, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.force_small_id_cache is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.http_paths_blacklist]]
.unsupported.dbms.http_paths_blacklist
[cols="<1s,<4"]
|===
|Description
a|Defines a blacklist of http paths that should not be accessed.
|Valid values
a|unsupported.dbms.http_paths_blacklist, a ',' separated list with elements of type 'a string'.
|Default value
m|++++++
|Internal
a|unsupported.dbms.http_paths_blacklist is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.idgenerator.log.enabled]]
.unsupported.dbms.idgenerator.log.enabled
[cols="<1s,<4"]
|===
|Description
a|Enable/disable logging for the id generator.
|Valid values
a|unsupported.dbms.idgenerator.log.enabled, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.idgenerator.log.enabled is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.idgenerator.log.prune_threshold]]
.unsupported.dbms.idgenerator.log.prune_threshold
[cols="<1s,<4"]
|===
|Description
a|Log file prune threshold for id generator logging.
|Valid values
a|unsupported.dbms.idgenerator.log.prune_threshold, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++2d+++
|Internal
a|unsupported.dbms.idgenerator.log.prune_threshold is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.idgenerator.log.rotation_threshold]]
.unsupported.dbms.idgenerator.log.rotation_threshold
[cols="<1s,<4"]
|===
|Description
a|Log file rotation threshold for id generator logging.
|Valid values
a|unsupported.dbms.idgenerator.log.rotation_threshold, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`)
|Default value
m|+++200.00MiB+++
|Internal
a|unsupported.dbms.idgenerator.log.rotation_threshold is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.archive_failed]]
.unsupported.dbms.index.archive_failed
[cols="<1s,<4"]
|===
|Description
a|Create an archive of an index before re-creating it if failing to load on startup.
|Valid values
a|unsupported.dbms.index.archive_failed, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.index.archive_failed is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.default_fulltext_provider]]
.unsupported.dbms.index.default_fulltext_provider
[cols="<1s,<4"]
|===
|Description
a|The default index provider used for managing full-text indexes. Only 'fulltext-1.0' is supported.
|Valid values
a|unsupported.dbms.index.default_fulltext_provider, a string
|Default value
m|+++fulltext-1.0+++
|Internal
a|unsupported.dbms.index.default_fulltext_provider is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.lucene.merge_factor]]
.unsupported.dbms.index.lucene.merge_factor
[cols="<1s,<4"]
|===
|Description
a|Setting for the matching lucene IndexWriterConfig config.
|Valid values
a|unsupported.dbms.index.lucene.merge_factor, an integer
|Default value
m|+++2+++
|Internal
a|unsupported.dbms.index.lucene.merge_factor is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.lucene.min_merge]]
.unsupported.dbms.index.lucene.min_merge
[cols="<1s,<4"]
|===
|Description
a|Setting for the matching lucene IndexWriterConfig config.
|Valid values
a|unsupported.dbms.index.lucene.min_merge, a double
|Default value
m|+++0.1+++
|Internal
a|unsupported.dbms.index.lucene.min_merge is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.lucene.nocfs.ratio]]
.unsupported.dbms.index.lucene.nocfs.ratio
[cols="<1s,<4"]
|===
|Description
a|Setting for the matching lucene IndexWriterConfig config.
|Valid values
a|unsupported.dbms.index.lucene.nocfs.ratio, a double
|Default value
m|+++1.0+++
|Internal
a|unsupported.dbms.index.lucene.nocfs.ratio is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.lucene.population_max_buffered_docs]]
.unsupported.dbms.index.lucene.population_max_buffered_docs
[cols="<1s,<4"]
|===
|Description
a|Setting for the matching lucene IndexWriterConfig config.
|Valid values
a|unsupported.dbms.index.lucene.population_max_buffered_docs, an integer
|Default value
m|+++-1+++
|Internal
a|unsupported.dbms.index.lucene.population_max_buffered_docs is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.lucene.population_ram_buffer_size]]
.unsupported.dbms.index.lucene.population_ram_buffer_size
[cols="<1s,<4"]
|===
|Description
a|Setting for the matching lucene IndexWriterConfig config.
|Valid values
a|unsupported.dbms.index.lucene.population_ram_buffer_size, a double
|Default value
m|+++50.0+++
|Internal
a|unsupported.dbms.index.lucene.population_ram_buffer_size is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.lucene.standard_ram_buffer_size]]
.unsupported.dbms.index.lucene.standard_ram_buffer_size
[cols="<1s,<4"]
|===
|Description
a|Setting for the matching lucene IndexWriterConfig config.
|Valid values
a|unsupported.dbms.index.lucene.standard_ram_buffer_size, a double
|Default value
m|+++16.0+++
|Internal
a|unsupported.dbms.index.lucene.standard_ram_buffer_size is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.lucene.writer_max_buffered_docs]]
.unsupported.dbms.index.lucene.writer_max_buffered_docs
[cols="<1s,<4"]
|===
|Description
a|Setting for the matching lucene IndexWriterConfig config.
|Valid values
a|unsupported.dbms.index.lucene.writer_max_buffered_docs, an integer
|Default value
m|+++100000+++
|Internal
a|unsupported.dbms.index.lucene.writer_max_buffered_docs is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.population_batch_max_byte_size]]
.unsupported.dbms.index.population_batch_max_byte_size
[cols="<1s,<4"]
|===
|Description
a|Max size for an index population batch.
|Valid values
a|unsupported.dbms.index.population_batch_max_byte_size, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`) which is maximum `2.00GiB`
|Default value
m|+++10.00MiB+++
|Internal
a|unsupported.dbms.index.population_batch_max_byte_size is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.population_print_debug]]
.unsupported.dbms.index.population_print_debug
[cols="<1s,<4"]
|===
|Description
a|Printing debug information on index population.
|Valid values
a|unsupported.dbms.index.population_print_debug, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.index.population_print_debug is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.population_queue_threshold]]
.unsupported.dbms.index.population_queue_threshold
[cols="<1s,<4"]
|===
|Description
a|Queue size for index population batched updates.
|Valid values
a|unsupported.dbms.index.population_queue_threshold, an integer
|Default value
m|+++20000+++
|Internal
a|unsupported.dbms.index.population_queue_threshold is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.populator_block_size]]
.unsupported.dbms.index.populator_block_size
[cols="<1s,<4"]
|===
|Description
a|Block/buffer size for index population.
|Valid values
a|unsupported.dbms.index.populator_block_size, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`) which is minimum `20B` and is maximum `2.00GiB`
|Default value
m|+++1.00MiB+++
|Internal
a|unsupported.dbms.index.populator_block_size is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.populator_merge_factor]]
.unsupported.dbms.index.populator_merge_factor
[cols="<1s,<4"]
|===
|Description
a|Merge factory for index population.
|Valid values
a|unsupported.dbms.index.populator_merge_factor, an integer
|Default value
m|+++8+++
|Internal
a|unsupported.dbms.index.populator_merge_factor is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.sampling.async_recovery]]
.unsupported.dbms.index.sampling.async_recovery
[cols="<1s,<4"]
|===
|Description
a|Enable asynchronous index sample recovery.
|Valid values
a|unsupported.dbms.index.sampling.async_recovery, a boolean
|Default value
m|+++true+++
|Internal
a|unsupported.dbms.index.sampling.async_recovery is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.sampling.async_recovery_wait]]
.unsupported.dbms.index.sampling.async_recovery_wait
[cols="<1s,<4"]
|===
|Description
a|Wait for asynchronous index sample recovery to finish.
|Valid values
a|unsupported.dbms.index.sampling.async_recovery_wait, a boolean. If unset the value is inherited from unsupported.dbms.index.sampling.async_recovery
|Internal
a|unsupported.dbms.index.sampling.async_recovery_wait is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.sampling.log_recovered_samples]]
.unsupported.dbms.index.sampling.log_recovered_samples
[cols="<1s,<4"]
|===
|Description
a|Logging information about recovered index samples.
|Valid values
a|unsupported.dbms.index.sampling.log_recovered_samples, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.index.sampling.log_recovered_samples is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.skip_default_indexes_on_creation]]
.unsupported.dbms.index.skip_default_indexes_on_creation
[cols="<1s,<4"]
|===
|Description
a|If 'true', new database will be created without token indexes for labels and relationships.
|Valid values
a|unsupported.dbms.index.skip_default_indexes_on_creation, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.index.skip_default_indexes_on_creation is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.spatial.curve.bottom_threshold]]
.unsupported.dbms.index.spatial.curve.bottom_threshold
[cols="<1s,<4"]
|===
|Description
a|When searching the spatial index we need to convert a 2D range in the quad tree into a set of 1D ranges on the underlying 1D space filling curve index. There is a balance to be made between many small 1D ranges that have few false positives, and fewer, larger 1D ranges that have more false positives. The former has a more efficient filtering of false positives, while the latter will have a more efficient search of the numerical index. The maximum depth to which the quad tree is processed when mapping 2D to 1D is based on the size of the search area compared to the size of the 2D tiles at that depth. When traversing the tree to this depth, we can stop early based on when the search envelope overlaps the current tile by more than a certain threshold. The threshold is calculated based on depth, from the `top_threshold` at the top of the tree to the `bottom_threshold` at the depth calculated by the area comparison. Setting the top to 0.99 and the bottom to 0.5, for example would mean that if we reached the maximum depth, and the search area overlapped the current tile by more than 50%, we would stop traversing the tree, and return the 1D range for that entire tile to the search set. If the overlap is even higher, we would stop higher in the tree. This technique reduces the number of 1D ranges passed to the underlying space filling curve index. Setting this value to zero turns off this feature.
|Valid values
a|unsupported.dbms.index.spatial.curve.bottom_threshold, a double
|Default value
m|+++0.0+++
|Internal
a|unsupported.dbms.index.spatial.curve.bottom_threshold is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.spatial.curve.extra_levels]]
.unsupported.dbms.index.spatial.curve.extra_levels
[cols="<1s,<4"]
|===
|Description
a|When searching the spatial index we need to convert a 2D range in the quad tree into a set of 1D ranges on the underlying 1D space filling curve index. There is a balance to be made between many small 1D ranges that have few false positives, and fewer, larger 1D ranges that have more false positives. The former has a more efficient filtering of false positives, while the latter will have a more efficient search of the numerical index. The maximum depth to which the quad tree is processed when mapping 2D to 1D is based on the size of the search area compared to the size of the 2D tiles at that depth. This setting will cause the algorithm to search deeper, reducing false positives.
|Valid values
a|unsupported.dbms.index.spatial.curve.extra_levels, an integer
|Default value
m|+++1+++
|Internal
a|unsupported.dbms.index.spatial.curve.extra_levels is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index.spatial.curve.top_threshold]]
.unsupported.dbms.index.spatial.curve.top_threshold
[cols="<1s,<4"]
|===
|Description
a|When searching the spatial index we need to convert a 2D range in the quad tree into a set of 1D ranges on the underlying 1D space filling curve index. There is a balance to be made between many small 1D ranges that have few false positives, and fewer, larger 1D ranges that have more false positives. The former has a more efficient filtering of false positives, while the latter will have a more efficient search of the numerical index. The maximum depth to which the quad tree is processed when mapping 2D to 1D is based on the size of the search area compared to the size of the 2D tiles at that depth. When traversing the tree to this depth, we can stop early based on when the search envelope overlaps the current tile by more than a certain threshold. The threshold is calculated based on depth, from the `top_threshold` at the top of the tree to the `bottom_threshold` at the depth calculated by the area comparison. Setting the top to 0.99 and the bottom to 0.5, for example would mean that if we reached the maximum depth, and the search area overlapped the current tile by more than 50%, we would stop traversing the tree, and return the 1D range for that entire tile to the search set. If the overlap is even higher, we would stop higher in the tree. This technique reduces the number of 1D ranges passed to the underlying space filling curve index. Setting this value to zero turns off this feature.
|Valid values
a|unsupported.dbms.index.spatial.curve.top_threshold, a double
|Default value
m|+++0.0+++
|Internal
a|unsupported.dbms.index.spatial.curve.top_threshold is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index_population.parallelism]]
.unsupported.dbms.index_population.parallelism
[cols="<1s,<4"]
|===
|Description
a|Set the maximum number of concurrent index populations across system. This also limit the number of threads used to scan store. Note that multiple indexes can be populated by a single index population if they were created in the same transaction. Zero means unrestricted.
|Valid values
a|unsupported.dbms.index_population.parallelism, an integer which is minimum `0`
|Default value
m|+++2+++
|Internal
a|unsupported.dbms.index_population.parallelism is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index_population.workers]]
.unsupported.dbms.index_population.workers
[cols="<1s,<4"]
|===
|Description
a|Set the number of threads used for each index population job. Those threads execute individual subtasks provided by index population main threads, see <<config_unsupported.dbms.index_population.parallelism,unsupported.dbms.index_population.parallelism>>.Zero means one thread per cpu core. Thus the maximum total number of index worker threads in the system is `unsupported.dbms.index_population.workers` * <<config_unsupported.dbms.index_population.parallelism,unsupported.dbms.index_population.parallelism>>.
|Valid values
a|unsupported.dbms.index_population.workers, an integer which is minimum `0`
|Default value
m|+++2+++
|Internal
a|unsupported.dbms.index_population.workers is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.index_sampling.parallelism]]
.unsupported.dbms.index_sampling.parallelism
[cols="<1s,<4"]
|===
|Description
a|Set the maximum number of threads that can concurrently be used to sample indexes. Zero means unrestricted.
|Valid values
a|unsupported.dbms.index_sampling.parallelism, an integer which is minimum `0`
|Default value
m|+++4+++
|Internal
a|unsupported.dbms.index_sampling.parallelism is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.initial_transaction_heap_grab_size]]
.unsupported.dbms.initial_transaction_heap_grab_size
[cols="<1s,<4"]
|===
|Description
a|Chunk size for heap memory reservation from the memory pool.
|Valid values
a|unsupported.dbms.initial_transaction_heap_grab_size, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`)
|Default value
m|+++2.00MiB+++
|Internal
a|unsupported.dbms.initial_transaction_heap_grab_size is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.io.controller.consider.external.enabled]]
.unsupported.dbms.io.controller.consider.external.enabled
[cols="<1s,<4"]
|===
|Description
a|Let the IO controller consider/ignore external IO.
|Valid values
a|unsupported.dbms.io.controller.consider.external.enabled, a boolean
|Dynamic a|true
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.io.controller.consider.external.enabled is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.kernel_id]]
.unsupported.dbms.kernel_id
[cols="<1s,<4"]
|===
|Description
a|An identifier that uniquely identifies this graph database instance within this JVM. Defaults to an auto-generated number depending on how many instance are started in this JVM.
|Valid values
a|unsupported.dbms.kernel_id, a string which matches the pattern `[a-zA-Z0-9]*` (has to be a valid kernel identifier)
|Internal
a|unsupported.dbms.kernel_id is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.large_cluster.enable]]
.unsupported.dbms.large_cluster.enable
[cols="<1s,<4"]
|===
|Description
a|Enablement of using of different Database allocators.
|Valid values
a|unsupported.dbms.large_cluster.enable, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.large_cluster.enable is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.lock_manager]]
.unsupported.dbms.lock_manager
[cols="<1s,<4"]
|===
|Description
a|Name of the lock manager to be used, as defined in the corresponding LocksFactory.
|Valid values
a|unsupported.dbms.lock_manager, a string
|Default value
m|+++forseti+++
|Internal
a|unsupported.dbms.lock_manager is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.lock_manager.verbose_deadlocks]]
.unsupported.dbms.lock_manager.verbose_deadlocks
[cols="<1s,<4"]
|===
|Description
a|Include additional information in deadlock descriptions.
|Valid values
a|unsupported.dbms.lock_manager.verbose_deadlocks, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.lock_manager.verbose_deadlocks is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.logs.query.heap_dump_enabled]]
.unsupported.dbms.logs.query.heap_dump_enabled
[cols="<1s,<4"]
|===
|Description
a|Create a heap dump just before the end of each query execution. The heap dump will be placed in log directory and the file name will contain the query id, to be correlated with an entry in the query log. Only live objects will be included to minimize the file size.
|Valid values
a|unsupported.dbms.logs.query.heap_dump_enabled, a boolean
|Dynamic a|true
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.logs.query.heap_dump_enabled is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.loopback_delete]]
.unsupported.dbms.loopback_delete
[cols="<1s,<4"]
|===
|Description
a|Whether or not to delete an existing file for use with the Unix Domain Socket based loopback interface. This improves the handling of the case where a previous hard shutdown was unable to delete the file.
|Valid values
a|unsupported.dbms.loopback_delete, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.loopback_delete is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.loopback_enabled]]
.unsupported.dbms.loopback_enabled
[cols="<1s,<4"]
|===
|Description
a|Enable or disable the bolt loopback connector. A user successfully authenticated over this will execute all queries with no security restrictions. This includes overriding the `<<config_unsupported.dbms.block_create_drop_database,unsupported.dbms.block_create_drop_database>>`, `<<config_unsupported.dbms.block_start_stop_database,unsupported.dbms.block_start_stop_database>>` and `<<config_unsupported.dbms.upgrade_restriction_enabled,unsupported.dbms.upgrade_restriction_enabled>>` settings.
|Valid values
a|unsupported.dbms.loopback_enabled, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.loopback_enabled is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.loopback_file]]
.unsupported.dbms.loopback_file
[cols="<1s,<4"]
|===
|Description
a|The absolute path of the file for use with the Unix Domain Socket based loopback interface. This file must be specified and will be created at runtime and deleted on shutdown.
|Valid values
a|unsupported.dbms.loopback_file, a path
|Internal
a|unsupported.dbms.loopback_file is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.lucene.ephemeral]]
.unsupported.dbms.lucene.ephemeral
[cols="<1s,<4"]
|===
|Description
a|Configure lucene to be in memory only, for test environment. This is set in code and should never be configured explicitly.
|Valid values
a|unsupported.dbms.lucene.ephemeral, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.lucene.ephemeral is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.max_http_request_header_size]]
.unsupported.dbms.max_http_request_header_size
[cols="<1s,<4"]
|===
|Description
a|Maximum request header size.
|Valid values
a|unsupported.dbms.max_http_request_header_size, an integer
|Default value
m|+++20480+++
|Internal
a|unsupported.dbms.max_http_request_header_size is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.max_http_response_header_size]]
.unsupported.dbms.max_http_response_header_size
[cols="<1s,<4"]
|===
|Description
a|Maximum response header size.
|Valid values
a|unsupported.dbms.max_http_response_header_size, an integer
|Default value
m|+++20480+++
|Internal
a|unsupported.dbms.max_http_response_header_size is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.memory.counts_store_max_cached_entries]]
.unsupported.dbms.memory.counts_store_max_cached_entries
[cols="<1s,<4"]
|===
|Description
a|The maximum number of cached entries in count store (based) stores.
|Valid values
a|unsupported.dbms.memory.counts_store_max_cached_entries, an integer
|Default value
m|+++1000000+++
|Internal
a|unsupported.dbms.memory.counts_store_max_cached_entries is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.memory.managed_network_buffers]]
.unsupported.dbms.memory.managed_network_buffers
[cols="<1s,<4"]
|===
|Description
a|Whether or not DBMS's byte buffer manager should be used for network stack buffers instead of each network library managing its buffers on its own.
|Valid values
a|unsupported.dbms.memory.managed_network_buffers, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.memory.managed_network_buffers is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.memory.pagecache.warmup.legacy_profile_loader]]
.unsupported.dbms.memory.pagecache.warmup.legacy_profile_loader
[cols="<1s,<4"]
|===
|Description
a|Enables legacy strategy for loading pages from a profile. This strategy uses an aggressive per-file parallelism which turns what is mostly sequential IO into random IO. As a result, in most environments, this strategy is slower and stresses the IO subsystem more than the default strategy.
|Valid values
a|unsupported.dbms.memory.pagecache.warmup.legacy_profile_loader, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.memory.pagecache.warmup.legacy_profile_loader is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.page.file.tracer]]
.unsupported.dbms.page.file.tracer
[cols="<1s,<4"]
|===
|Description
a|Enable per page file metrics collection in a default page cache and cursor tracer.
|Valid values
a|unsupported.dbms.page.file.tracer, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.page.file.tracer is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.query.snapshot]]
.unsupported.dbms.query.snapshot
[cols="<1s,<4"]
|===
|Description
a|Specifies if engine should run cypher query based on a snapshot of accessed data. Query will be restarted in case if concurrent modification of data will be detected.
|Valid values
a|unsupported.dbms.query.snapshot, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.query.snapshot is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.query.snapshot.retries]]
.unsupported.dbms.query.snapshot.retries
[cols="<1s,<4"]
|===
|Description
a|Specifies number or retries that query engine will do to execute query based on stable accessed data snapshot before giving up.
|Valid values
a|unsupported.dbms.query.snapshot.retries, an integer which is in the range `1` to `2147483647`
|Default value
m|+++5+++
|Internal
a|unsupported.dbms.query.snapshot.retries is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.query_execution_plan_cache_size]]
.unsupported.dbms.query_execution_plan_cache_size
[cols="<1s,<4"]
|===
|Description
a|Cypher keeps a cache of the conversion from logical plans to execution plans. This cache is mainly meant to avoid generating code multiple times if different queries use the same logical plan. Items are only evicted from the cache when all query caches are cleared, e.g. by calling `db.clearQueryCaches()`. The cache is allowed to grow up to this size. If the size is set to -1 (default), it will use the size configured for the query cache, that is `dbms.query_cache_size`Setting the size to 0 means disabling this cache.
|Valid values
a|unsupported.dbms.query_execution_plan_cache_size, an integer which is minimum `-1`
|Default value
m|+++-1+++
|Internal
a|unsupported.dbms.query_execution_plan_cache_size is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.readonly.failover]]
.unsupported.dbms.readonly.failover
[cols="<1s,<4"]
|===
|Description
a|Whether or database should switch to read only mode on disk space problems.
|Valid values
a|unsupported.dbms.readonly.failover, a boolean
|Dynamic a|true
|Default value
m|+++true+++
|Internal
a|unsupported.dbms.readonly.failover is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.recovery.enable_parallelism]]
.unsupported.dbms.recovery.enable_parallelism
[cols="<1s,<4"]
|===
|Description
a|Whether or not to use multiple threads whilst performing recovery. Provides performance improvement for some workloads.
|Valid values
a|unsupported.dbms.recovery.enable_parallelism, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.recovery.enable_parallelism is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.recovery.ignore_store_id_validation]]
.unsupported.dbms.recovery.ignore_store_id_validation
[cols="<1s,<4"]
|===
|Description
a|Ignore store id validation during recovery.
|Valid values
a|unsupported.dbms.recovery.ignore_store_id_validation, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.recovery.ignore_store_id_validation is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.report_configuration]]
.unsupported.dbms.report_configuration
[cols="<1s,<4"]
|===
|Description
a|Print out the effective Neo4j configuration after startup.
|Valid values
a|unsupported.dbms.report_configuration, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.report_configuration is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.reserved.page.header.bytes]]
.unsupported.dbms.reserved.page.header.bytes
[cols="<1s,<4"]
|===
|Description
a|Number of reserved header bytes in each page in page cache. Please note changing it for already existing store is not supported.
|Valid values
a|unsupported.dbms.reserved.page.header.bytes, an integer
|Default value
m|+++0+++
|Internal
a|unsupported.dbms.reserved.page.header.bytes is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.security.ldap.authorization.connection_pooling]]
.unsupported.dbms.security.ldap.authorization.connection_pooling
[cols="<1s,<4"]
|===
|Description
a|Set to true if connection pooling should be used for authorization searches using the system account.
|Valid values
a|unsupported.dbms.security.ldap.authorization.connection_pooling, a boolean
|Default value
m|+++true+++
|Internal
a|unsupported.dbms.security.ldap.authorization.connection_pooling is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.ssl.system.ignore_dot_files]]
.unsupported.dbms.ssl.system.ignore_dot_files
[cols="<1s,<4"]
|===
|Description
a|Don't try and read dot-prefixed files or dot-prefixed directories in ssl policy directories.
|Valid values
a|unsupported.dbms.ssl.system.ignore_dot_files, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.ssl.system.ignore_dot_files is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.storage.consistency_check_on_apply]]
.unsupported.dbms.storage.consistency_check_on_apply
[cols="<1s,<4"]
|===
|Description
a|Perform some data consistency checks on transaction apply.
|Valid values
a|unsupported.dbms.storage.consistency_check_on_apply, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.storage.consistency_check_on_apply is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.storage_engine]]
.unsupported.dbms.storage_engine
[cols="<1s,<4"]
|===
|Description
a|Name of storage engine to use when creating new databases (except system database). If null or empty string then a default will be used.This setting will not be used for loading existing databases, where instead the appropriate storage engine for the specific database will be used.
|Valid values
a|unsupported.dbms.storage_engine, a string
|Default value
m|+++record+++
|Internal
a|unsupported.dbms.storage_engine is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.strictly_prioritize_id_freelist]]
.unsupported.dbms.strictly_prioritize_id_freelist
[cols="<1s,<4"]
|===
|Description
a|Default value whether or not to strictly prioritize ids from freelist, as opposed to allocating from high id.Given a scenario where there are multiple concurrent calls to allocating IDsand there are free ids on the freelist, some perhaps cached, some not. Thread noticing that there are no free ids cached will try to acquirescanner lock and if it succeeds it will perform a scan and place found free ids in the cache and return. Otherwise:   If `false`: thread will allocate from high id and return, to not block id allocation request.   If `true` : thread will await lock released and check cache afterwards. If no id is cached even then it will allocate from high id.
|Valid values
a|unsupported.dbms.strictly_prioritize_id_freelist, a boolean
|Default value
m|+++true+++
|Internal
a|unsupported.dbms.strictly_prioritize_id_freelist is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.tokenscan.log.enabled]]
.unsupported.dbms.tokenscan.log.enabled
[cols="<1s,<4"]
|===
|Description
a|Enable/disable write log for token lookup indexes.
|Valid values
a|unsupported.dbms.tokenscan.log.enabled, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.tokenscan.log.enabled is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.tokenscan.log.prune_threshold]]
.unsupported.dbms.tokenscan.log.prune_threshold
[cols="<1s,<4"]
|===
|Description
a|Log file prune threshold for token lookup index write logging.
|Valid values
a|unsupported.dbms.tokenscan.log.prune_threshold, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++2d+++
|Internal
a|unsupported.dbms.tokenscan.log.prune_threshold is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.tokenscan.log.rotation_threshold]]
.unsupported.dbms.tokenscan.log.rotation_threshold
[cols="<1s,<4"]
|===
|Description
a|Log file rotation threshold for token lookup index write logging.
|Valid values
a|unsupported.dbms.tokenscan.log.rotation_threshold, a byte size (valid multipliers are `B`, `KiB`, `KB`, `K`, `kB`, `kb`, `k`, `MiB`, `MB`, `M`, `mB`, `mb`, `m`, `GiB`, `GB`, `G`, `gB`, `gb`, `g`, `TiB`, `TB`, `PiB`, `PB`, `EiB`, `EB`)
|Default value
m|+++200.00MiB+++
|Internal
a|unsupported.dbms.tokenscan.log.rotation_threshold is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.topology_graph.enable]]
.unsupported.dbms.topology_graph.enable
[cols="<1s,<4"]
|===
|Description
a|Turning off Topology graph.
|Valid values
a|unsupported.dbms.topology_graph.enable, a boolean
|Default value
m|+++true+++
|Internal
a|unsupported.dbms.topology_graph.enable is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.topology_graph_updater.enable]]
.unsupported.dbms.topology_graph_updater.enable
[cols="<1s,<4"]
|===
|Description
a|Turning off Topology graph updater - never turn it off!
|Valid values
a|unsupported.dbms.topology_graph_updater.enable, a boolean
|Default value
m|+++true+++
|Internal
a|unsupported.dbms.topology_graph_updater.enable is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.tracer]]
.unsupported.dbms.tracer
[cols="<1s,<4"]
|===
|Description
a|Name of the tracer factory to be used. Current implementations are: null, default & verbose.
|Valid values
a|unsupported.dbms.tracer, a string
|Internal
a|unsupported.dbms.tracer is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.transaction_start_timeout]]
.unsupported.dbms.transaction_start_timeout
[cols="<1s,<4"]
|===
|Description
a|The maximum amount of time to wait for the database to become available, when starting a new transaction.
|Valid values
a|unsupported.dbms.transaction_start_timeout, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++1s+++
|Internal
a|unsupported.dbms.transaction_start_timeout is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.tx.logs.dedicated.appender]]
.unsupported.dbms.tx.logs.dedicated.appender
[cols="<1s,<4"]
|===
|Description
a|Allow database to use dedicated transaction appender writer thread.
|Valid values
a|unsupported.dbms.tx.logs.dedicated.appender, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.tx.logs.dedicated.appender is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.tx_log.fail_on_corrupted_log_files]]
.unsupported.dbms.tx_log.fail_on_corrupted_log_files
[cols="<1s,<4"]
|===
|Description
a|If `true`, Neo4j will abort recovery if any errors are encountered in the logical log. Setting this to `false` will allow Neo4j to restore as much as possible from the corrupted log files and ignore the rest, but, the integrity of the database might be compromised.
|Valid values
a|unsupported.dbms.tx_log.fail_on_corrupted_log_files, a boolean
|Default value
m|+++true+++
|Internal
a|unsupported.dbms.tx_log.fail_on_corrupted_log_files is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.tx_log.presketch]]
.unsupported.dbms.tx_log.presketch
[cols="<1s,<4"]
|===
|Description
a|Enables sketching of next transaction log file in the background during reverse recovery.
|Valid values
a|unsupported.dbms.tx_log.presketch, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.tx_log.presketch is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.upgrade_restriction_enabled]]
.unsupported.dbms.upgrade_restriction_enabled
[cols="<1s,<4"]
|===
|Description
a|Enable or disable the ability to execute the `dbms.upgrade` procedure.
|Valid values
a|unsupported.dbms.upgrade_restriction_enabled, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.upgrade_restriction_enabled is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.uris.browser]]
.unsupported.dbms.uris.browser
[cols="<1s,<4"]
|===
|Description
a|URI to the browser home page.
|Valid values
a|unsupported.dbms.uris.browser, a URI
|Default value
m|+++/browser/+++
|Internal
a|unsupported.dbms.uris.browser is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.uris.db]]
.unsupported.dbms.uris.db
[cols="<1s,<4"]
|===
|Description
a|The start endpoint of database api.
|Valid values
a|unsupported.dbms.uris.db, a normalized relative URI
|Default value
m|+++/db+++
|Internal
a|unsupported.dbms.uris.db is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.uris.dbms]]
.unsupported.dbms.uris.dbms
[cols="<1s,<4"]
|===
|Description
a|The start endpoint of the dbms api.
|Valid values
a|unsupported.dbms.uris.dbms, a normalized relative URI
|Default value
m|+++/dbms+++
|Internal
a|unsupported.dbms.uris.dbms is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.uris.management]]
.unsupported.dbms.uris.management
[cols="<1s,<4"]
|===
|Description
a|The legacy manage endpoint. This is kept for back-compatibility purpose.
|Valid values
a|unsupported.dbms.uris.management, a normalized relative URI
|Default value
m|+++/db/manage+++
|Internal
a|unsupported.dbms.uris.management is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.uris.rest]]
.unsupported.dbms.uris.rest
[cols="<1s,<4"]
|===
|Description
a|The legacy data endpoint. This is kept for back-compatibility purpose.
|Valid values
a|unsupported.dbms.uris.rest, a normalized relative URI
|Default value
m|+++/db/data+++
|Internal
a|unsupported.dbms.uris.rest is an internal, unsupported setting.
|===

[[internal_unsupported.dbms.wadl_generation_enabled]]
.unsupported.dbms.wadl_generation_enabled
[cols="<1s,<4"]
|===
|Description
a|Toggle WADL generation. Matching the underlying jersey server config.
|Valid values
a|unsupported.dbms.wadl_generation_enabled, a boolean
|Default value
m|+++false+++
|Internal
a|unsupported.dbms.wadl_generation_enabled is an internal, unsupported setting.
|===

[[internal_unsupported.tools.batch_inserter.batch_size]]
.unsupported.tools.batch_inserter.batch_size
[cols="<1s,<4"]
|===
|Description
a|Specifies number of operations that batch inserter will try to group into one batch before flushing data into underlying storage.
|Valid values
a|unsupported.tools.batch_inserter.batch_size, an integer
|Default value
m|+++10000+++
|Internal
a|unsupported.tools.batch_inserter.batch_size is an internal, unsupported setting.
|===

[[internal_unsupported.vm_pause_monitor.measurement_duration]]
.unsupported.vm_pause_monitor.measurement_duration
[cols="<1s,<4"]
|===
|Description
a|VM pause monitor measurement duration.
|Valid values
a|unsupported.vm_pause_monitor.measurement_duration, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++200ms+++
|Internal
a|unsupported.vm_pause_monitor.measurement_duration is an internal, unsupported setting.
|===

[[internal_unsupported.vm_pause_monitor.stall_alert_threshold]]
.unsupported.vm_pause_monitor.stall_alert_threshold
[cols="<1s,<4"]
|===
|Description
a|Alert threshold for total pause time during one VM pause monitor measurement.
|Valid values
a|unsupported.vm_pause_monitor.stall_alert_threshold, a duration (Valid units are: `ns`, `s`, `ms`, `s`, `m`, `h` and `d`; default unit is `s`)
|Default value
m|+++200ms+++
|Internal
a|unsupported.vm_pause_monitor.stall_alert_threshold is an internal, unsupported setting.
|===

