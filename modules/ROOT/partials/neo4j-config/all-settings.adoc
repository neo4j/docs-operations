// tag::settings-reference-all-settings[]
[[settings-reference-all-settings]]
.All settings
ifndef::nonhtmloutput[]
[options="header"]
|===
|Name|Description
|<<config_bolt.ssl_policy,bolt.ssl_policy>>|Specify the SSL policy to use for the encrypted bolt connections.
|<<config_browser.allow_outgoing_connections,browser.allow_outgoing_connections>>|Configure the policy for outgoing Neo4j Browser connections.
|<<config_browser.credential_timeout,browser.credential_timeout>>|Configure the Neo4j Browser to time out logged in users after this idle period.
|<<config_browser.post_connect_cmd,browser.post_connect_cmd>>|Commands to be run when Neo4j Browser successfully connects to this server.
|<<config_browser.remote_content_hostname_whitelist,browser.remote_content_hostname_whitelist>>|Whitelist of hosts for the Neo4j Browser to be allowed to fetch content from.
|<<config_browser.retain_connection_credentials,browser.retain_connection_credentials>>|Configure the Neo4j Browser to store or not store user credentials.
|<<config_causal_clustering.array_block_id_allocation_size,causal_clustering.array_block_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of ARRAY_BLOCK IDs.
|<<config_causal_clustering.catch_up_client_inactivity_timeout,causal_clustering.catch_up_client_inactivity_timeout>>|The catch up protocol times out if the given duration elapses with no network activity.
|<<config_causal_clustering.catchup_batch_size,causal_clustering.catchup_batch_size>>|The maximum batch size when catching up (in unit of entries).
|<<config_causal_clustering.cluster_allow_reads_on_followers,causal_clustering.cluster_allow_reads_on_followers>>|Configure if the `dbms.cluster.routing.getServers()` procedure should include followers as read endpoints or return only read replicas.
|<<config_causal_clustering.cluster_binding_timeout,causal_clustering.cluster_binding_timeout>>|The time allowed after the Causal Clustering components start for a Neo4j Core Server to either join a cluster or form a new cluster with the other Neo4j Core Servers provided by `causal_clustering.initial_discovery_members`.
|<<config_causal_clustering.cluster_routing_ttl,causal_clustering.cluster_routing_ttl>>|How long drivers should cache the data from the `dbms.cluster.routing.getServers()` procedure.
|<<config_causal_clustering.cluster_topology_refresh,causal_clustering.cluster_topology_refresh>>|Time between scanning the cluster to refresh current server's view of topology.
|<<config_causal_clustering.connect-randomly-to-server-group,causal_clustering.connect-randomly-to-server-group>>|Comma separated list of groups to be used by the connect-randomly-to-server-group selection strategy.
|<<config_causal_clustering.database,causal_clustering.database>>|The name of the database being hosted by this server instance.
|<<config_causal_clustering.disable_middleware_logging,causal_clustering.disable_middleware_logging>>|Prevents the network middleware from dumping its own logs.
|<<config_causal_clustering.discovery_advertised_address,causal_clustering.discovery_advertised_address>>|Advertised cluster member discovery management communication.
|<<config_causal_clustering.discovery_listen_address,causal_clustering.discovery_listen_address>>|Host and port to bind the cluster member discovery management communication.
|<<config_causal_clustering.discovery_type,causal_clustering.discovery_type>>|Configure the discovery type used for cluster name resolution.
|<<config_causal_clustering.enable_pre_voting,causal_clustering.enable_pre_voting>>|Enable pre-voting extension to the Raft protocol (this is breaking and must match between the core cluster members).
|<<config_causal_clustering.expected_core_cluster_size,causal_clustering.expected_core_cluster_size>>|Expected number of Core machines in the cluster before startup.
|<<config_causal_clustering.global_session_tracker_state_size,causal_clustering.global_session_tracker_state_size>>|The maximum file size before the global session tracker state file is rotated (in unit of entries).
|<<config_causal_clustering.handshake_timeout,causal_clustering.handshake_timeout>>|Time out for protocol negotiation handshake.
|<<config_causal_clustering.id_alloc_state_size,causal_clustering.id_alloc_state_size>>|The maximum file size before the ID allocation file is rotated (in unit of entries).
|<<config_causal_clustering.in_flight_cache.max_bytes,causal_clustering.in_flight_cache.max_bytes>>|The maximum number of bytes in the in-flight cache.
|<<config_causal_clustering.in_flight_cache.max_entries,causal_clustering.in_flight_cache.max_entries>>|The maximum number of entries in the in-flight cache.
|<<config_causal_clustering.in_flight_cache.type,causal_clustering.in_flight_cache.type>>|Type of in-flight cache.
|<<config_causal_clustering.initial_discovery_members,causal_clustering.initial_discovery_members>>|A comma-separated list of other members of the cluster to join.
|<<config_causal_clustering.join_catch_up_timeout,causal_clustering.join_catch_up_timeout>>|Time out for a new member to catch up.
|<<config_causal_clustering.kubernetes.address,causal_clustering.kubernetes.address>>|Address for Kubernetes API.
|<<config_causal_clustering.kubernetes.ca_crt,causal_clustering.kubernetes.ca_crt>>|File location of CA certificate for Kubernetes API.
|<<config_causal_clustering.kubernetes.label_selector,causal_clustering.kubernetes.label_selector>>|LabelSelector for Kubernetes API.
|<<config_causal_clustering.kubernetes.namespace,causal_clustering.kubernetes.namespace>>|File location of namespace for Kubernetes API.
|<<config_causal_clustering.kubernetes.service_port_name,causal_clustering.kubernetes.service_port_name>>|Service port name for discovery for Kubernetes API.
|<<config_causal_clustering.kubernetes.token,causal_clustering.kubernetes.token>>|File location of token for Kubernetes API.
|<<config_causal_clustering.label_token_id_allocation_size,causal_clustering.label_token_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of LABEL_TOKEN IDs.
|<<config_causal_clustering.label_token_name_id_allocation_size,causal_clustering.label_token_name_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of LABEL_TOKEN_NAME IDs.
|<<config_causal_clustering.last_applied_state_size,causal_clustering.last_applied_state_size>>|The maximum file size before the storage file is rotated (in unit of entries).
|<<config_causal_clustering.leader_election_timeout,causal_clustering.leader_election_timeout>>|The time limit within which a new leader election will occur if no messages are received.
|<<config_causal_clustering.load_balancing.config,causal_clustering.load_balancing.config>>|The configuration must be valid for the configured plugin and usually existsunder matching subkeys, e.g.
|<<config_causal_clustering.load_balancing.plugin,causal_clustering.load_balancing.plugin>>|The load balancing plugin to use.
|<<config_causal_clustering.load_balancing.shuffle,causal_clustering.load_balancing.shuffle>>|Enables shuffling of the returned load balancing result.
|<<config_causal_clustering.log_shipping_max_lag,causal_clustering.log_shipping_max_lag>>|The maximum lag allowed before log shipping pauses (in unit of entries).
|<<config_causal_clustering.middleware_logging.level,causal_clustering.middleware_logging.level>>|The level of middleware logging.
|<<config_causal_clustering.minimum_core_cluster_size_at_formation,causal_clustering.minimum_core_cluster_size_at_formation>>|Minimum number of Core machines initially required to form a cluster.
|<<config_causal_clustering.minimum_core_cluster_size_at_runtime,causal_clustering.minimum_core_cluster_size_at_runtime>>|The minimum size of the dynamically adjusted voting set (which only core members may be a part of).
|<<config_causal_clustering.multi_dc_license,causal_clustering.multi_dc_license>>|Enable multi-data center features.
|<<config_causal_clustering.neostore_block_id_allocation_size,causal_clustering.neostore_block_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of NEOSTORE_BLOCK IDs.
|<<config_causal_clustering.node_id_allocation_size,causal_clustering.node_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of NODE IDs.
|<<config_causal_clustering.node_labels_id_allocation_size,causal_clustering.node_labels_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of NODE_LABELS IDs.
|<<config_causal_clustering.property_id_allocation_size,causal_clustering.property_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of PROPERTY IDs.
|<<config_causal_clustering.property_key_token_id_allocation_size,causal_clustering.property_key_token_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of PROPERTY_KEY_TOKEN IDs.
|<<config_causal_clustering.property_key_token_name_id_allocation_size,causal_clustering.property_key_token_name_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of PROPERTY_KEY_TOKEN_NAME IDs.
|<<config_causal_clustering.protocol_implementations.catchup,causal_clustering.protocol_implementations.catchup>>|Catchup protocol implementation versions that this instance will allow in negotiation as a comma-separated list.
|<<config_causal_clustering.protocol_implementations.compression,causal_clustering.protocol_implementations.compression>>|Network compression algorithms that this instance will allow in negotiation as a comma-separated list.
|<<config_causal_clustering.protocol_implementations.raft,causal_clustering.protocol_implementations.raft>>|Raft protocol implementation versions that this instance will allow in negotiation as a comma-separated list.
|<<config_causal_clustering.pull_interval,causal_clustering.pull_interval>>|Interval of pulling updates from cores.
|<<config_causal_clustering.raft_advertised_address,causal_clustering.raft_advertised_address>>|Advertised hostname/IP address and port for the RAFT server.
|<<config_causal_clustering.raft_in_queue_max_batch_bytes,causal_clustering.raft_in_queue_max_batch_bytes>>|Largest batch processed by RAFT in bytes.
|<<config_causal_clustering.raft_in_queue_max_bytes,causal_clustering.raft_in_queue_max_bytes>>|Maximum number of bytes in the RAFT in-queue.
|<<config_causal_clustering.raft_listen_address,causal_clustering.raft_listen_address>>|Network interface and port for the RAFT server to listen on.
|<<config_causal_clustering.raft_log_implementation,causal_clustering.raft_log_implementation>>|RAFT log implementation.
|<<config_causal_clustering.raft_log_prune_strategy,causal_clustering.raft_log_prune_strategy>>|RAFT log pruning strategy.
|<<config_causal_clustering.raft_log_pruning_frequency,causal_clustering.raft_log_pruning_frequency>>|RAFT log pruning frequency.
|<<config_causal_clustering.raft_log_reader_pool_size,causal_clustering.raft_log_reader_pool_size>>|RAFT log reader pool size.
|<<config_causal_clustering.raft_log_rotation_size,causal_clustering.raft_log_rotation_size>>|RAFT log rotation size.
|<<config_causal_clustering.raft_membership_state_size,causal_clustering.raft_membership_state_size>>|The maximum file size before the membership state file is rotated (in unit of entries).
|<<config_causal_clustering.raft_term_state_size,causal_clustering.raft_term_state_size>>|The maximum file size before the term state file is rotated (in unit of entries).
|<<config_causal_clustering.raft_vote_state_size,causal_clustering.raft_vote_state_size>>|The maximum file size before the vote state file is rotated (in unit of entries).
|<<config_causal_clustering.read_replica_time_to_live,causal_clustering.read_replica_time_to_live>>|Time To Live before read replica is considered unavailable.
|<<config_causal_clustering.reconnection_backoff,causal_clustering.reconnection_backoff>>|Minimum time between connection attempts.
|<<config_causal_clustering.refuse_to_be_leader,causal_clustering.refuse_to_be_leader>>|Prevents the current instance from volunteering to become Raft leader.
|<<config_causal_clustering.relationship_group_id_allocation_size,causal_clustering.relationship_group_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of RELATIONSHIP_GROUP IDs.
|<<config_causal_clustering.relationship_id_allocation_size,causal_clustering.relationship_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of RELATIONSHIP IDs.
|<<config_causal_clustering.relationship_type_token_id_allocation_size,causal_clustering.relationship_type_token_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of RELATIONSHIP_TYPE_TOKEN IDs.
|<<config_causal_clustering.relationship_type_token_name_id_allocation_size,causal_clustering.relationship_type_token_name_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of RELATIONSHIP_TYPE_TOKEN_NAME IDs.
|<<config_causal_clustering.replicated_lock_token_state_size,causal_clustering.replicated_lock_token_state_size>>|The maximum file size before the replicated lock token state file is rotated (in unit of entries).
|<<config_causal_clustering.replication_retry_timeout_base,causal_clustering.replication_retry_timeout_base>>|The initial timeout until replication is retried.
|<<config_causal_clustering.replication_retry_timeout_limit,causal_clustering.replication_retry_timeout_limit>>|The upper limit for the exponentially incremented retry timeout.
|<<config_causal_clustering.schema_id_allocation_size,causal_clustering.schema_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of SCHEMA IDs.
|<<config_causal_clustering.server_groups,causal_clustering.server_groups>>|A list of group names for the server used when configuring load balancing and replication policies.
|<<config_causal_clustering.ssl_policy,causal_clustering.ssl_policy>>|Name of the SSL policy to be used by the clustering, as defined under the dbms.ssl.policy.* settings.
|<<config_causal_clustering.state_machine_apply_max_batch_size,causal_clustering.state_machine_apply_max_batch_size>>|The maximum number of operations to be batched during applications of operations in the state machines.
|<<config_causal_clustering.state_machine_flush_window_size,causal_clustering.state_machine_flush_window_size>>|The number of operations to be processed before the state machines flush to disk.
|<<config_causal_clustering.store_copy_max_retry_time_per_request,causal_clustering.store_copy_max_retry_time_per_request>>|Maximum retry time per request during store copy.
|<<config_causal_clustering.string_block_id_allocation_size,causal_clustering.string_block_id_allocation_size>>|The size of the ID allocation requests Core servers will make when they run out of STRING_BLOCK IDs.
|<<config_causal_clustering.transaction_advertised_address,causal_clustering.transaction_advertised_address>>|Advertised hostname/IP address and port for the transaction shipping server.
|<<config_causal_clustering.transaction_listen_address,causal_clustering.transaction_listen_address>>|Network interface and port for the transaction shipping server to listen on.
|<<config_causal_clustering.unknown_address_logging_throttle,causal_clustering.unknown_address_logging_throttle>>|Throttle limit for logging unknown cluster member address.
|<<config_causal_clustering.upstream_selection_strategy,causal_clustering.upstream_selection_strategy>>|An ordered list in descending preference of the strategy which read replicas use to choose the upstream server from which to pull transactional updates.
|<<config_causal_clustering.user_defined_upstream_strategy,causal_clustering.user_defined_upstream_strategy>>|Configuration of a user-defined upstream selection strategy.
|<<config_cypher.default_language_version,cypher.default_language_version>>|Set this to specify the default parser (language version).
|<<config_cypher.forbid_exhaustive_shortestpath,cypher.forbid_exhaustive_shortestpath>>|This setting is associated with performance optimization.
|<<config_cypher.forbid_shortestpath_common_nodes,cypher.forbid_shortestpath_common_nodes>>|This setting is associated with performance optimization.
|<<config_cypher.hints_error,cypher.hints_error>>|Set this to specify the behavior when Cypher planner or runtime hints cannot be fulfilled.
|<<config_cypher.lenient_create_relationship,cypher.lenient_create_relationship>>|Set this to change the behavior for Cypher create relationship when the start or end node is missing.
|<<config_cypher.min_replan_interval,cypher.min_replan_interval>>|The minimum time between possible cypher query replanning events.
|<<config_cypher.planner,cypher.planner>>|Set this to specify the default planner for the default language version.
|<<config_cypher.statistics_divergence_threshold,cypher.statistics_divergence_threshold>>|The threshold when a plan is considered stale.
|<<config_db.temporal.timezone,db.temporal.timezone>>|Database timezone for temporal functions.
|<<config_dbms.active_database,dbms.active_database>>|Name of the database to load.
|<<config_dbms.allow_format_migration,dbms.allow_format_migration>>|Whether to allow a store upgrade in case the current version of the database starts against an older store version.
|<<config_dbms.allow_upgrade,dbms.allow_upgrade>>|Whether to allow an upgrade in case the current version of the database starts against an older version.
|<<config_dbms.backup.address,dbms.backup.address>>|Listening server for online backups.
|<<config_dbms.backup.enabled,dbms.backup.enabled>>|Enable support for running online backups.
|<<config_dbms.backup.ssl_policy,dbms.backup.ssl_policy>>|Name of the SSL policy to be used by backup, as defined under the dbms.ssl.policy.* settings.
|<<config_dbms.checkpoint,dbms.checkpoint>>|Configures the general policy for when check-points should occur.
|<<config_dbms.checkpoint.interval.time,dbms.checkpoint.interval.time>>|Configures the time interval between check-points.
|<<config_dbms.checkpoint.interval.tx,dbms.checkpoint.interval.tx>>|Configures the transaction interval between check-points.
|<<config_dbms.checkpoint.iops.limit,dbms.checkpoint.iops.limit>>|Limit the number of IOs the background checkpoint process will consume per second.
|<<config_dbms.config.strict_validation,dbms.config.strict_validation>>|A strict configuration validation will prevent the database from starting up if unknown configuration options are specified in the neo4j settings namespace (such as dbms., ha., cypher., etc).
|<<config_dbms.connector.bolt.advertised_address,dbms.connector.bolt.advertised_address>>|Advertised address for this connector.
|<<config_dbms.connector.bolt.enabled,dbms.connector.bolt.enabled>>|Enable this connector.
|<<config_dbms.connector.bolt.listen_address,dbms.connector.bolt.listen_address>>|Address the connector should bind to.
|<<config_dbms.connector.bolt.thread_pool_keep_alive,dbms.connector.bolt.thread_pool_keep_alive>>|The maximum time an idle thread in the thread pool bound to this connector will wait for new tasks.
|<<config_dbms.connector.bolt.thread_pool_max_size,dbms.connector.bolt.thread_pool_max_size>>|The maximum number of threads allowed in the thread pool bound to this connector.
|<<config_dbms.connector.bolt.thread_pool_min_size,dbms.connector.bolt.thread_pool_min_size>>|The number of threads to keep in the thread pool bound to this connector, even if they are idle.
|<<config_dbms.connector.bolt.tls_level,dbms.connector.bolt.tls_level>>|Encryption level to require this connector to use.
|<<config_dbms.connector.http.advertised_address,dbms.connector.http.advertised_address>>|Advertised address for this connector.
|<<config_dbms.connector.http.enabled,dbms.connector.http.enabled>>|Enable this connector.
|<<config_dbms.connector.http.listen_address,dbms.connector.http.listen_address>>|Address the connector should bind to.
|<<config_dbms.connector.https.advertised_address,dbms.connector.https.advertised_address>>|Advertised address for this connector.
|<<config_dbms.connector.https.enabled,dbms.connector.https.enabled>>|Enable this connector.
|<<config_dbms.connector.https.listen_address,dbms.connector.https.listen_address>>|Address the connector should bind to.
|<<config_dbms.connectors.default_advertised_address,dbms.connectors.default_advertised_address>>|Default hostname or IP address the server uses to advertise itself to its connectors.
|<<config_dbms.connectors.default_listen_address,dbms.connectors.default_listen_address>>|Default network interface to listen for incoming connections.
|<<config_dbms.db.timezone,dbms.db.timezone>>|Database timezone.
|<<config_dbms.directories.certificates,dbms.directories.certificates>>|Directory for storing certificates to be used by Neo4j for TLS connections.
|<<config_dbms.directories.data,dbms.directories.data>>|Path of the data directory.
|<<config_dbms.directories.import,dbms.directories.import>>|Sets the root directory for file URLs used with the Cypher `LOAD CSV` clause.
|<<config_dbms.directories.lib,dbms.directories.lib>>|Path of the lib directory.
|<<config_dbms.directories.logs,dbms.directories.logs>>|Path of the logs directory.
|<<config_dbms.directories.metrics,dbms.directories.metrics>>|The target location of the CSV files: a path to a directory wherein a CSV file per reported field  will be written.
|<<config_dbms.directories.plugins,dbms.directories.plugins>>|Location of the database plugin directory.
|<<config_dbms.directories.run,dbms.directories.run>>|Path of the run directory.
|<<config_dbms.directories.tx_log,dbms.directories.tx_log>>|Location where Neo4j keeps the logical transaction logs.
|<<config_dbms.filewatcher.enabled,dbms.filewatcher.enabled>>|Allows the enabling or disabling of the file watcher service.
|<<config_dbms.ids.reuse.types.override,dbms.ids.reuse.types.override>>|Specified names of id types (comma separated) that should be reused.
|<<config_dbms.import.csv.buffer_size,dbms.import.csv.buffer_size>>|The size of the internal buffer in bytes used by `LOAD CSV`.
|<<config_dbms.import.csv.legacy_quote_escaping,dbms.import.csv.legacy_quote_escaping>>|Selects whether to conform to the standard https://tools.ietf.org/html/rfc4180 for interpreting escaped quotation characters in CSV files loaded using `LOAD CSV`.
|<<config_dbms.index.default_schema_provider,dbms.index.default_schema_provider>>|Index provider to use for newly created schema indexes.
|<<config_dbms.index.fulltext.default_analyzer,dbms.index.fulltext.default_analyzer>>|The name of the analyzer that the fulltext indexes should use by default.
|<<config_dbms.index.fulltext.eventually_consistent,dbms.index.fulltext.eventually_consistent>>|Whether or not fulltext indexes should be eventually consistent by default or not.
|<<config_dbms.index.fulltext.eventually_consistent_index_update_queue_max_length,dbms.index.fulltext.eventually_consistent_index_update_queue_max_length>>|The eventually_consistent mode of the fulltext indexes works by queueing up index updates to be applied later in a background thread.
|<<config_dbms.index_sampling.background_enabled,dbms.index_sampling.background_enabled>>|Enable or disable background index sampling.
|<<config_dbms.index_sampling.buffer_size,dbms.index_sampling.buffer_size>>|Size of buffer used by index sampling.
|<<config_dbms.index_sampling.sample_size_limit,dbms.index_sampling.sample_size_limit>>|Index sampling chunk size limit.
|<<config_dbms.index_sampling.update_percentage,dbms.index_sampling.update_percentage>>|Percentage of index updates of total index size required before sampling of a given index is triggered.
|<<config_dbms.index_searcher_cache_size,dbms.index_searcher_cache_size>>|The maximum number of open Lucene index searchers.
|<<config_dbms.jvm.additional,dbms.jvm.additional>>|Additional JVM arguments.
|<<config_dbms.lock.acquisition.timeout,dbms.lock.acquisition.timeout>>|The maximum time interval within which lock should be acquired.
|<<config_dbms.logs.debug.level,dbms.logs.debug.level>>|Debug log level threshold.
|<<config_dbms.logs.debug.path,dbms.logs.debug.path>>|Path to the debug log file.
|<<config_dbms.logs.debug.rotation.delay,dbms.logs.debug.rotation.delay>>|Minimum time interval after last rotation of the debug log before it may be rotated again.
|<<config_dbms.logs.debug.rotation.keep_number,dbms.logs.debug.rotation.keep_number>>|Maximum number of history files for the debug log.
|<<config_dbms.logs.debug.rotation.size,dbms.logs.debug.rotation.size>>|Threshold for rotation of the debug log.
|<<config_dbms.logs.gc.enabled,dbms.logs.gc.enabled>>|Enable GC Logging.
|<<config_dbms.logs.gc.options,dbms.logs.gc.options>>|GC Logging Options.
|<<config_dbms.logs.gc.rotation.keep_number,dbms.logs.gc.rotation.keep_number>>|Number of GC logs to keep.
|<<config_dbms.logs.gc.rotation.size,dbms.logs.gc.rotation.size>>|Size of each GC log that is kept.
|<<config_dbms.logs.http.enabled,dbms.logs.http.enabled>>|Enable HTTP request logging.
|<<config_dbms.logs.http.path,dbms.logs.http.path>>|Path to HTTP request log.
|<<config_dbms.logs.http.rotation.keep_number,dbms.logs.http.rotation.keep_number>>|Number of HTTP logs to keep.
|<<config_dbms.logs.http.rotation.size,dbms.logs.http.rotation.size>>|Size of each HTTP log that is kept.
|<<config_dbms.logs.query.allocation_logging_enabled,dbms.logs.query.allocation_logging_enabled>>|Log allocated bytes for the executed queries being logged.
|<<config_dbms.logs.query.enabled,dbms.logs.query.enabled>>|Log executed queries that take longer than the configured threshold, dbms.logs.query.threshold.
|<<config_dbms.logs.query.page_logging_enabled,dbms.logs.query.page_logging_enabled>>|Log page hits and page faults for the executed queries being logged.
|<<config_dbms.logs.query.parameter_logging_enabled,dbms.logs.query.parameter_logging_enabled>>|Log parameters for the executed queries being logged.
|<<config_dbms.logs.query.path,dbms.logs.query.path>>|Path to the query log file.
|<<config_dbms.logs.query.rotation.keep_number,dbms.logs.query.rotation.keep_number>>|Maximum number of history files for the query log.
|<<config_dbms.logs.query.rotation.size,dbms.logs.query.rotation.size>>|The file size in bytes at which the query log will auto-rotate.
|<<config_dbms.logs.query.runtime_logging_enabled,dbms.logs.query.runtime_logging_enabled>>|Logs which runtime that was used to run the query.
|<<config_dbms.logs.query.threshold,dbms.logs.query.threshold>>|If the execution of query takes more time than this threshold, the query is logged - provided query logging is enabled.
|<<config_dbms.logs.query.time_logging_enabled,dbms.logs.query.time_logging_enabled>>|Log detailed time information for the executed queries being logged.
|<<config_dbms.logs.security.level,dbms.logs.security.level>>|Security log level threshold.
|<<config_dbms.logs.security.path,dbms.logs.security.path>>|Path to the security log file.
|<<config_dbms.logs.security.rotation.delay,dbms.logs.security.rotation.delay>>|Minimum time interval after last rotation of the security log before it may be rotated again.
|<<config_dbms.logs.security.rotation.keep_number,dbms.logs.security.rotation.keep_number>>|Maximum number of history files for the security log.
|<<config_dbms.logs.security.rotation.size,dbms.logs.security.rotation.size>>|Threshold for rotation of the security log.
|<<config_dbms.logs.timezone,dbms.logs.timezone>>|Database logs timezone.
|<<config_dbms.logs.user.path,dbms.logs.user.path>>|Path to the user log file.
|<<config_dbms.logs.user.rotation.delay,dbms.logs.user.rotation.delay>>|Minimum time interval after last rotation of the user log before it may be rotated again.
|<<config_dbms.logs.user.rotation.keep_number,dbms.logs.user.rotation.keep_number>>|Maximum number of history files for the user log.
|<<config_dbms.logs.user.rotation.size,dbms.logs.user.rotation.size>>|Threshold for rotation of the user log.
|<<config_dbms.logs.user.stdout_enabled,dbms.logs.user.stdout_enabled>>|Send user logs to the process stdout.
|<<config_dbms.memory.heap.initial_size,dbms.memory.heap.initial_size>>|Initial heap size.
|<<config_dbms.memory.heap.max_size,dbms.memory.heap.max_size>>|Maximum heap size.
|<<config_dbms.memory.pagecache.size,dbms.memory.pagecache.size>>|The amount of memory to use for mapping the store files, in bytes (or kilobytes with the 'k' suffix, megabytes with 'm' and gigabytes with 'g').
|<<config_dbms.memory.pagecache.swapper,dbms.memory.pagecache.swapper>>|Specify which page swapper to use for doing paged IO.
|<<config_dbms.mode,dbms.mode>>|Configure the operating mode of the database -- 'SINGLE' for stand-alone operation, 'HA' for operating as a member in an HA cluster, 'ARBITER' for a cluster member with no database in an HA cluster, 'CORE' for operating as a core member of a Causal Cluster, or 'READ_REPLICA' for operating as a read replica member of a Causal Cluster.
|<<config_dbms.netty.ssl.provider,dbms.netty.ssl.provider>>|Netty SSL provider.
|<<config_dbms.procedures.kill_query_verbose,dbms.procedures.kill_query_verbose>>|Specifies whether or not dbms.killQueries produces a verbose output, with information about which queries were not found.
|<<config_dbms.query_cache_size,dbms.query_cache_size>>|The number of Cypher query execution plans that are cached.
|<<config_dbms.read_only,dbms.read_only>>|Only allow read operations from this Neo4j instance.
|<<config_dbms.record_format,dbms.record_format>>|Database record format.
|<<config_dbms.relationship_grouping_threshold,dbms.relationship_grouping_threshold>>|Relationship count threshold for considering a node to be dense.
|<<config_dbms.rest.transaction.idle_timeout,dbms.rest.transaction.idle_timeout>>|Timeout for idle transactions in the REST endpoint.
|<<config_dbms.security.allow_csv_import_from_file_urls,dbms.security.allow_csv_import_from_file_urls>>|Determines if Cypher will allow using file URLs when loading data using `LOAD CSV`.
|<<config_dbms.security.auth_cache_max_capacity,dbms.security.auth_cache_max_capacity>>|The maximum capacity for authentication and authorization caches (respectively).
|<<config_dbms.security.auth_cache_ttl,dbms.security.auth_cache_ttl>>|The time to live (TTL) for cached authentication and authorization info when using external auth providers (LDAP or plugin).
|<<config_dbms.security.auth_cache_use_ttl,dbms.security.auth_cache_use_ttl>>|Enable time-based eviction of the authentication and authorization info cache for external auth providers (LDAP or plugin).
|<<config_dbms.security.auth_enabled,dbms.security.auth_enabled>>|Enable auth requirement to access Neo4j.
|<<config_dbms.security.auth_lock_time,dbms.security.auth_lock_time>>|The amount of time user account should be locked after a configured number of unsuccessful authentication attempts.
|<<config_dbms.security.auth_max_failed_attempts,dbms.security.auth_max_failed_attempts>>|The maximum number of unsuccessful authentication attempts before imposing a user lock for the configured amount of time.The locked out user will not be able to log in until the lock period expires, even if correct credentials are provided.
|<<config_dbms.security.auth_provider,dbms.security.auth_provider>>|The authentication and authorization provider that contains both the users and roles.
|<<config_dbms.security.causal_clustering_status_auth_enabled,dbms.security.causal_clustering_status_auth_enabled>>|Require authorization for access to the Causal Clustering status endpoints.
|<<config_dbms.security.ha_status_auth_enabled,dbms.security.ha_status_auth_enabled>>|Require authorization for access to the HA status endpoints.
|<<config_dbms.security.http_access_control_allow_origin,dbms.security.http_access_control_allow_origin>>|Value of the Access-Control-Allow-Origin header sent over any HTTP or HTTPS connector.
|<<config_dbms.security.http_authorization_classes,dbms.security.http_authorization_classes>>|Comma-separated list of custom security rules for Neo4j to use.
|<<config_dbms.security.http_strict_transport_security,dbms.security.http_strict_transport_security>>|Value of the HTTP Strict-Transport-Security (HSTS) response header.
|<<config_dbms.security.ldap.authentication.cache_enabled,dbms.security.ldap.authentication.cache_enabled>>|Determines if the result of authentication via the LDAP server should be cached or not.
|<<config_dbms.security.ldap.authentication.mechanism,dbms.security.ldap.authentication.mechanism>>|LDAP authentication mechanism.
|<<config_dbms.security.ldap.authentication.use_samaccountname,dbms.security.ldap.authentication.use_samaccountname>>|Perform authentication with sAMAccountName instead of DN.
Using this setting requires `dbms.security.ldap.authorization.system_username` and dbms.security.ldap.authorization.system_password to be used since there is no way to log in through ldap directly with the sAMAccountName, instead the login name will be resolved to a DN that will be used to log in with.
|<<config_dbms.security.ldap.authentication.user_dn_template,dbms.security.ldap.authentication.user_dn_template>>|LDAP user DN template.
|<<config_dbms.security.ldap.authorization.group_membership_attributes,dbms.security.ldap.authorization.group_membership_attributes>>|A list of attribute names on a user object that contains groups to be used for mapping to roles when LDAP authorization is enabled.
|<<config_dbms.security.ldap.authorization.group_to_role_mapping,dbms.security.ldap.authorization.group_to_role_mapping>>|An authorization mapping from LDAP group names to Neo4j role names.
|<<config_dbms.security.ldap.authorization.system_password,dbms.security.ldap.authorization.system_password>>|An LDAP system account password to use for authorization searches when `dbms.security.ldap.authorization.use_system_account` is `true`.
|<<config_dbms.security.ldap.authorization.system_username,dbms.security.ldap.authorization.system_username>>|An LDAP system account username to use for authorization searches when `dbms.security.ldap.authorization.use_system_account` is `true`.
|<<config_dbms.security.ldap.authorization.use_system_account,dbms.security.ldap.authorization.use_system_account>>|Perform LDAP search for authorization info using a system account instead of the user's own account.
If this is set to `false` (default), the search for group membership will be performed directly after authentication using the LDAP context bound with the user's own account.
|<<config_dbms.security.ldap.authorization.user_search_base,dbms.security.ldap.authorization.user_search_base>>|The name of the base object or named context to search for user objects when LDAP authorization is enabled.
|<<config_dbms.security.ldap.authorization.user_search_filter,dbms.security.ldap.authorization.user_search_filter>>|The LDAP search filter to search for a user principal when LDAP authorization is enabled.
|<<config_dbms.security.ldap.connection_timeout,dbms.security.ldap.connection_timeout>>|The timeout for establishing an LDAP connection.
|<<config_dbms.security.ldap.host,dbms.security.ldap.host>>|URL of LDAP server to use for authentication and authorization.
|<<config_dbms.security.ldap.read_timeout,dbms.security.ldap.read_timeout>>|The timeout for an LDAP read request (i.e.
|<<config_dbms.security.ldap.referral,dbms.security.ldap.referral>>|The LDAP referral behavior when creating a connection.
|<<config_dbms.security.ldap.use_starttls,dbms.security.ldap.use_starttls>>|Use secure communication with the LDAP server using opportunistic TLS.
|<<config_dbms.security.log_successful_authentication,dbms.security.log_successful_authentication>>|Set to log successful authentication events to the security log.
|<<config_dbms.security.procedures.default_allowed,dbms.security.procedures.default_allowed>>|The default role that can execute all procedures and user-defined functions that are not covered by the `dbms.security.procedures.roles` setting.
|<<config_dbms.security.procedures.roles,dbms.security.procedures.roles>>|This provides a finer level of control over which roles can execute procedures than the `dbms.security.procedures.default_allowed` setting.
|<<config_dbms.security.procedures.unrestricted,dbms.security.procedures.unrestricted>>|A list of procedures and user defined functions (comma separated) that are allowed full access to the database.
|<<config_dbms.security.procedures.whitelist,dbms.security.procedures.whitelist>>|A list of procedures (comma separated) that are to be loaded.
|<<config_dbms.security.property_level.blacklist,dbms.security.property_level.blacklist>>|An authorization mapping for property level access for roles.
|<<config_dbms.security.property_level.enabled,dbms.security.property_level.enabled>>|Set to true to enable property level security.
|<<config_dbms.shutdown_transaction_end_timeout,dbms.shutdown_transaction_end_timeout>>|The maximum amount of time to wait for running transactions to complete before allowing initiated database shutdown to continue.
|<<config_dbms.ssl.policy.-policyname-.allow_key_generation,dbms.ssl.policy.<policyname>.allow_key_generation>>|Allows the generation of a private key and associated self-signed certificate.
|<<config_dbms.ssl.policy.-policyname-.base_directory,dbms.ssl.policy.<policyname>.base_directory>>|The mandatory base directory for cryptographic objects of this policy.
|<<config_dbms.ssl.policy.-policyname-.ciphers,dbms.ssl.policy.<policyname>.ciphers>>|Restrict allowed ciphers.
|<<config_dbms.ssl.policy.-policyname-.client_auth,dbms.ssl.policy.<policyname>.client_auth>>|Client authentication stance.
|<<config_dbms.ssl.policy.-policyname-.private_key,dbms.ssl.policy.<policyname>.private_key>>|Private PKCS#8 key in PEM format.
|<<config_dbms.ssl.policy.-policyname-.public_certificate,dbms.ssl.policy.<policyname>.public_certificate>>|X.509 certificate (chain) of this server in PEM format.
|<<config_dbms.ssl.policy.-policyname-.revoked_dir,dbms.ssl.policy.<policyname>.revoked_dir>>|Path to directory of CRLs (Certificate Revocation Lists) in PEM format.
|<<config_dbms.ssl.policy.-policyname-.tls_versions,dbms.ssl.policy.<policyname>.tls_versions>>|Restrict allowed TLS protocol versions.
|<<config_dbms.ssl.policy.-policyname-.trust_all,dbms.ssl.policy.<policyname>.trust_all>>|Makes this policy trust all remote parties.
|<<config_dbms.ssl.policy.-policyname-.trusted_dir,dbms.ssl.policy.<policyname>.trusted_dir>>|Path to directory of X.509 certificates in PEM format for trusted parties.
|<<config_dbms.ssl.policy.-policyname-.verify_hostname,dbms.ssl.policy.<policyname>.verify_hostname>>|When true, this node will verify the hostname of every other instance it connects to by comparing the address it used to connect with it and the patterns described in the remote hosts public certificate Subject Alternative Names.
|<<config_dbms.threads.worker_count,dbms.threads.worker_count>>|Number of Neo4j worker threads.
|<<config_dbms.track_query_allocation,dbms.track_query_allocation>>|Enables or disables tracking of how many bytes are allocated by the execution of a query.
|<<config_dbms.track_query_cpu_time,dbms.track_query_cpu_time>>|Enables or disables tracking of how much time a query spends actively executing on the CPU.
|<<config_dbms.transaction.bookmark_ready_timeout,dbms.transaction.bookmark_ready_timeout>>|The maximum amount of time to wait for the database state represented by the bookmark.
|<<config_dbms.transaction.monitor.check.interval,dbms.transaction.monitor.check.interval>>|Configures the time interval between transaction monitor checks.
|<<config_dbms.transaction.timeout,dbms.transaction.timeout>>|The maximum time interval of a transaction within which it should be completed.
|<<config_dbms.tx_log.rotation.retention_policy,dbms.tx_log.rotation.retention_policy>>|Make Neo4j keep the logical transaction logs for being able to backup the database.
|<<config_dbms.tx_log.rotation.size,dbms.tx_log.rotation.size>>|Specifies at which file size the logical log will auto-rotate.
|<<config_dbms.tx_state.max_off_heap_memory,dbms.tx_state.max_off_heap_memory>>|The maximum amount of off-heap memory that can be used to store transaction state data; it's a total amount of memory shared across all active transactions.
|<<config_dbms.tx_state.memory_allocation,dbms.tx_state.memory_allocation>>|Defines whether memory for transaction state should be allocated on- or off-heap.
|<<config_dbms.tx_state.off_heap.block_cache_size,dbms.tx_state.off_heap.block_cache_size>>|Defines the size of the off-heap memory blocks cache.
|<<config_dbms.tx_state.off_heap.max_cacheable_block_size,dbms.tx_state.off_heap.max_cacheable_block_size>>|Defines the maximum size of an off-heap memory block that can be cached to speed up allocations for transaction state data.
|<<config_dbms.udc.enabled,dbms.udc.enabled>>|Enable the UDC extension.
|<<config_dbms.unmanaged_extension_classes,dbms.unmanaged_extension_classes>>|Comma-separated list of <classname>=<mount point> for unmanaged extensions.
|<<config_dbms.windows_service_name,dbms.windows_service_name>>|Name of the Windows Service.
|<<config_ha.allow_init_cluster,ha.allow_init_cluster>>|Whether to allow this instance to create a cluster if unable to join.
|<<config_ha.branched_data_copying_strategy,ha.branched_data_copying_strategy>>|Strategy for how to order handling of branched data on slaves and copying of the store from the master.
|<<config_ha.branched_data_policy,ha.branched_data_policy>>|Policy for how to handle branched data.
|<<config_ha.broadcast_timeout,ha.broadcast_timeout>>|Timeout for broadcasting values in cluster.
|<<config_ha.configuration_timeout,ha.configuration_timeout>>|Timeout for waiting for configuration from an existing cluster member during cluster join.
|<<config_ha.data_chunk_size,ha.data_chunk_size>>|Max size of the data chunks that flows between master and slaves in HA.
|<<config_ha.default_timeout,ha.default_timeout>>|Default timeout used for clustering timeouts.
|<<config_ha.election_timeout,ha.election_timeout>>|Timeout for waiting for other members to finish a role election.
|<<config_ha.heartbeat_interval,ha.heartbeat_interval>>|How often heartbeat messages should be sent.
|<<config_ha.heartbeat_timeout,ha.heartbeat_timeout>>|How long to wait for heartbeats from other instances before marking them as suspects for failure.
|<<config_ha.host.coordination,ha.host.coordination>>|Host and port to bind the cluster management communication.
|<<config_ha.host.data,ha.host.data>>|Hostname and port to bind the HA server.
|<<config_ha.initial_hosts,ha.initial_hosts>>|A comma-separated list of other members of the cluster to join.
|<<config_ha.internal_role_switch_timeout,ha.internal_role_switch_timeout>>|Timeout for waiting for internal conditions during state switch, like for transactions to complete, before switching to master or slave.
|<<config_ha.join_timeout,ha.join_timeout>>|Timeout for joining a cluster.
|<<config_ha.learn_timeout,ha.learn_timeout>>|Timeout for learning values.
|<<config_ha.leave_timeout,ha.leave_timeout>>|Timeout for waiting for cluster leave to finish.
|<<config_ha.max_acceptors,ha.max_acceptors>>|Maximum number of servers to involve when agreeing to membership changes.
|<<config_ha.max_channels_per_slave,ha.max_channels_per_slave>>|Maximum number of connections a slave can have to the master.
|<<config_ha.paxos_timeout,ha.paxos_timeout>>|Default value for all Paxos timeouts.
|<<config_ha.phase1_timeout,ha.phase1_timeout>>|Timeout for Paxos phase 1.
|<<config_ha.phase2_timeout,ha.phase2_timeout>>|Timeout for Paxos phase 2.
|<<config_ha.pull_batch_size,ha.pull_batch_size>>|Size of batches of transactions applied on slaves when pulling from master.
|<<config_ha.pull_interval,ha.pull_interval>>|Interval of pulling updates from master.
|<<config_ha.role_switch_timeout,ha.role_switch_timeout>>|Timeout for request threads waiting for instance to become master or slave.
|<<config_ha.server_id,ha.server_id>>|Id for a cluster instance.
|<<config_ha.slave_lock_timeout,ha.slave_lock_timeout>>|Timeout for taking remote (write) locks on slaves.
|<<config_ha.slave_only,ha.slave_only>>|Whether this instance should only participate as slave in cluster.
|<<config_ha.slave_read_timeout,ha.slave_read_timeout>>|How long a slave will wait for response from master before giving up.
|<<config_ha.tx_push_factor,ha.tx_push_factor>>|The amount of slaves the master will ask to replicate a committed transaction.
|<<config_ha.tx_push_strategy,ha.tx_push_strategy>>|Push strategy of a transaction to a slave during commit.
|<<config_https.ssl_policy,https.ssl_policy>>|SSL policy name.
|<<config_metrics.bolt.messages.enabled,metrics.bolt.messages.enabled>>|Enable reporting metrics about Bolt Protocol message processing.
|<<config_metrics.csv.enabled,metrics.csv.enabled>>|Set to `true` to enable exporting metrics to CSV files.
|<<config_metrics.csv.interval,metrics.csv.interval>>|The reporting interval for the CSV files.
|<<config_metrics.csv.rotation.keep_number,metrics.csv.rotation.keep_number>>|Maximum number of history files for the csv files.
|<<config_metrics.csv.rotation.size,metrics.csv.rotation.size>>|The file size in bytes at which the csv files will auto-rotate.
|<<config_metrics.cypher.replanning.enabled,metrics.cypher.replanning.enabled>>|Enable reporting metrics about number of occurred replanning events.
|<<config_metrics.enabled,metrics.enabled>>|The default enablement value for all the supported metrics.
|<<config_metrics.graphite.enabled,metrics.graphite.enabled>>|Set to `true` to enable exporting metrics to Graphite.
|<<config_metrics.graphite.interval,metrics.graphite.interval>>|The reporting interval for Graphite.
|<<config_metrics.graphite.server,metrics.graphite.server>>|The hostname or IP address of the Graphite server.
|<<config_metrics.jvm.buffers.enabled,metrics.jvm.buffers.enabled>>|Enable reporting metrics about the buffer pools.
|<<config_metrics.jvm.gc.enabled,metrics.jvm.gc.enabled>>|Enable reporting metrics about the duration of garbage collections.
|<<config_metrics.jvm.memory.enabled,metrics.jvm.memory.enabled>>|Enable reporting metrics about the memory usage.
|<<config_metrics.jvm.threads.enabled,metrics.jvm.threads.enabled>>|Enable reporting metrics about the current number of threads running.
|<<config_metrics.neo4j.causal_clustering.enabled,metrics.neo4j.causal_clustering.enabled>>|Enable reporting metrics about Causal Clustering mode.
|<<config_metrics.neo4j.checkpointing.enabled,metrics.neo4j.checkpointing.enabled>>|Enable reporting metrics about Neo4j check pointing.
|<<config_metrics.neo4j.cluster.enabled,metrics.neo4j.cluster.enabled>>|Enable reporting metrics about HA cluster info.
|<<config_metrics.neo4j.counts.enabled,metrics.neo4j.counts.enabled>>|Enable reporting metrics about approximately how many entities are in the database.
|<<config_metrics.neo4j.enabled,metrics.neo4j.enabled>>|The default enablement value for all Neo4j specific support metrics.
|<<config_metrics.neo4j.logrotation.enabled,metrics.neo4j.logrotation.enabled>>|Enable reporting metrics about the Neo4j log rotation.
|<<config_metrics.neo4j.network.enabled,metrics.neo4j.network.enabled>>|Enable reporting metrics about the network usage.
|<<config_metrics.neo4j.pagecache.enabled,metrics.neo4j.pagecache.enabled>>|Enable reporting metrics about the Neo4j page cache.
|<<config_metrics.neo4j.server.enabled,metrics.neo4j.server.enabled>>|Enable reporting metrics about Server threading info.
|<<config_metrics.neo4j.tx.enabled,metrics.neo4j.tx.enabled>>|Enable reporting metrics about transactions.
|<<config_metrics.prefix,metrics.prefix>>|A common prefix for the reported metrics field names.
|<<config_metrics.prometheus.enabled,metrics.prometheus.enabled>>|Set to `true` to enable the Prometheus endpoint.
|<<config_metrics.prometheus.endpoint,metrics.prometheus.endpoint>>|The hostname and port to use as Prometheus endpoint.
|<<config_tools.consistency_checker.check_graph,tools.consistency_checker.check_graph>>|This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead.
|<<config_tools.consistency_checker.check_index_structure,tools.consistency_checker.check_index_structure>>|This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead.
|<<config_tools.consistency_checker.check_indexes,tools.consistency_checker.check_indexes>>|This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead.
|<<config_tools.consistency_checker.check_label_scan_store,tools.consistency_checker.check_label_scan_store>>|This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead.
|<<config_tools.consistency_checker.check_property_owners,tools.consistency_checker.check_property_owners>>|This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead.
|===
endif::nonhtmloutput[]

ifdef::nonhtmloutput[]
* <<config_bolt.ssl_policy,bolt.ssl_policy>>: Specify the SSL policy to use for the encrypted bolt connections.
* <<config_browser.allow_outgoing_connections,browser.allow_outgoing_connections>>: Configure the policy for outgoing Neo4j Browser connections.
* <<config_browser.credential_timeout,browser.credential_timeout>>: Configure the Neo4j Browser to time out logged in users after this idle period.
* <<config_browser.post_connect_cmd,browser.post_connect_cmd>>: Commands to be run when Neo4j Browser successfully connects to this server.
* <<config_browser.remote_content_hostname_whitelist,browser.remote_content_hostname_whitelist>>: Whitelist of hosts for the Neo4j Browser to be allowed to fetch content from.
* <<config_browser.retain_connection_credentials,browser.retain_connection_credentials>>: Configure the Neo4j Browser to store or not store user credentials.
* <<config_causal_clustering.array_block_id_allocation_size,causal_clustering.array_block_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of ARRAY_BLOCK IDs.
* <<config_causal_clustering.catch_up_client_inactivity_timeout,causal_clustering.catch_up_client_inactivity_timeout>>: The catch up protocol times out if the given duration elapses with no network activity.
* <<config_causal_clustering.catchup_batch_size,causal_clustering.catchup_batch_size>>: The maximum batch size when catching up (in unit of entries).
* <<config_causal_clustering.cluster_allow_reads_on_followers,causal_clustering.cluster_allow_reads_on_followers>>: Configure if the `dbms.cluster.routing.getServers()` procedure should include followers as read endpoints or return only read replicas.
* <<config_causal_clustering.cluster_binding_timeout,causal_clustering.cluster_binding_timeout>>: The time allowed after the Causal Clustering components start for a Neo4j Core Server to either join a cluster or form a new cluster with the other Neo4j Core Servers provided by `causal_clustering.initial_discovery_members`.
* <<config_causal_clustering.cluster_routing_ttl,causal_clustering.cluster_routing_ttl>>: How long drivers should cache the data from the `dbms.cluster.routing.getServers()` procedure.
* <<config_causal_clustering.cluster_topology_refresh,causal_clustering.cluster_topology_refresh>>: Time between scanning the cluster to refresh current server's view of topology.
* <<config_causal_clustering.connect-randomly-to-server-group,causal_clustering.connect-randomly-to-server-group>>: Comma separated list of groups to be used by the connect-randomly-to-server-group selection strategy.
* <<config_causal_clustering.database,causal_clustering.database>>: The name of the database being hosted by this server instance.
* <<config_causal_clustering.disable_middleware_logging,causal_clustering.disable_middleware_logging>>: Prevents the network middleware from dumping its own logs.
* <<config_causal_clustering.discovery_advertised_address,causal_clustering.discovery_advertised_address>>: Advertised cluster member discovery management communication.
* <<config_causal_clustering.discovery_listen_address,causal_clustering.discovery_listen_address>>: Host and port to bind the cluster member discovery management communication.
* <<config_causal_clustering.discovery_type,causal_clustering.discovery_type>>: Configure the discovery type used for cluster name resolution.
* <<config_causal_clustering.enable_pre_voting,causal_clustering.enable_pre_voting>>: Enable pre-voting extension to the Raft protocol (this is breaking and must match between the core cluster members).
* <<config_causal_clustering.expected_core_cluster_size,causal_clustering.expected_core_cluster_size>>: Expected number of Core machines in the cluster before startup.
* <<config_causal_clustering.global_session_tracker_state_size,causal_clustering.global_session_tracker_state_size>>: The maximum file size before the global session tracker state file is rotated (in unit of entries).
* <<config_causal_clustering.handshake_timeout,causal_clustering.handshake_timeout>>: Time out for protocol negotiation handshake.
* <<config_causal_clustering.id_alloc_state_size,causal_clustering.id_alloc_state_size>>: The maximum file size before the ID allocation file is rotated (in unit of entries).
* <<config_causal_clustering.in_flight_cache.max_bytes,causal_clustering.in_flight_cache.max_bytes>>: The maximum number of bytes in the in-flight cache.
* <<config_causal_clustering.in_flight_cache.max_entries,causal_clustering.in_flight_cache.max_entries>>: The maximum number of entries in the in-flight cache.
* <<config_causal_clustering.in_flight_cache.type,causal_clustering.in_flight_cache.type>>: Type of in-flight cache.
* <<config_causal_clustering.initial_discovery_members,causal_clustering.initial_discovery_members>>: A comma-separated list of other members of the cluster to join.
* <<config_causal_clustering.join_catch_up_timeout,causal_clustering.join_catch_up_timeout>>: Time out for a new member to catch up.
* <<config_causal_clustering.kubernetes.address,causal_clustering.kubernetes.address>>: Address for Kubernetes API.
* <<config_causal_clustering.kubernetes.ca_crt,causal_clustering.kubernetes.ca_crt>>: File location of CA certificate for Kubernetes API.
* <<config_causal_clustering.kubernetes.label_selector,causal_clustering.kubernetes.label_selector>>: LabelSelector for Kubernetes API.
* <<config_causal_clustering.kubernetes.namespace,causal_clustering.kubernetes.namespace>>: File location of namespace for Kubernetes API.
* <<config_causal_clustering.kubernetes.service_port_name,causal_clustering.kubernetes.service_port_name>>: Service port name for discovery for Kubernetes API.
* <<config_causal_clustering.kubernetes.token,causal_clustering.kubernetes.token>>: File location of token for Kubernetes API.
* <<config_causal_clustering.label_token_id_allocation_size,causal_clustering.label_token_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of LABEL_TOKEN IDs.
* <<config_causal_clustering.label_token_name_id_allocation_size,causal_clustering.label_token_name_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of LABEL_TOKEN_NAME IDs.
* <<config_causal_clustering.last_applied_state_size,causal_clustering.last_applied_state_size>>: The maximum file size before the storage file is rotated (in unit of entries).
* <<config_causal_clustering.leader_election_timeout,causal_clustering.leader_election_timeout>>: The time limit within which a new leader election will occur if no messages are received.
* <<config_causal_clustering.load_balancing.config,causal_clustering.load_balancing.config>>: The configuration must be valid for the configured plugin and usually existsunder matching subkeys, e.g.
* <<config_causal_clustering.load_balancing.plugin,causal_clustering.load_balancing.plugin>>: The load balancing plugin to use.
* <<config_causal_clustering.load_balancing.shuffle,causal_clustering.load_balancing.shuffle>>: Enables shuffling of the returned load balancing result.
* <<config_causal_clustering.log_shipping_max_lag,causal_clustering.log_shipping_max_lag>>: The maximum lag allowed before log shipping pauses (in unit of entries).
* <<config_causal_clustering.middleware_logging.level,causal_clustering.middleware_logging.level>>: The level of middleware logging.
* <<config_causal_clustering.minimum_core_cluster_size_at_formation,causal_clustering.minimum_core_cluster_size_at_formation>>: Minimum number of Core machines initially required to form a cluster.
* <<config_causal_clustering.minimum_core_cluster_size_at_runtime,causal_clustering.minimum_core_cluster_size_at_runtime>>: The minimum size of the dynamically adjusted voting set (which only core members may be a part of).
* <<config_causal_clustering.multi_dc_license,causal_clustering.multi_dc_license>>: Enable multi-data center features.
* <<config_causal_clustering.neostore_block_id_allocation_size,causal_clustering.neostore_block_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of NEOSTORE_BLOCK IDs.
* <<config_causal_clustering.node_id_allocation_size,causal_clustering.node_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of NODE IDs.
* <<config_causal_clustering.node_labels_id_allocation_size,causal_clustering.node_labels_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of NODE_LABELS IDs.
* <<config_causal_clustering.property_id_allocation_size,causal_clustering.property_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of PROPERTY IDs.
* <<config_causal_clustering.property_key_token_id_allocation_size,causal_clustering.property_key_token_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of PROPERTY_KEY_TOKEN IDs.
* <<config_causal_clustering.property_key_token_name_id_allocation_size,causal_clustering.property_key_token_name_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of PROPERTY_KEY_TOKEN_NAME IDs.
* <<config_causal_clustering.protocol_implementations.catchup,causal_clustering.protocol_implementations.catchup>>: Catchup protocol implementation versions that this instance will allow in negotiation as a comma-separated list.
* <<config_causal_clustering.protocol_implementations.compression,causal_clustering.protocol_implementations.compression>>: Network compression algorithms that this instance will allow in negotiation as a comma-separated list.
* <<config_causal_clustering.protocol_implementations.raft,causal_clustering.protocol_implementations.raft>>: Raft protocol implementation versions that this instance will allow in negotiation as a comma-separated list.
* <<config_causal_clustering.pull_interval,causal_clustering.pull_interval>>: Interval of pulling updates from cores.
* <<config_causal_clustering.raft_advertised_address,causal_clustering.raft_advertised_address>>: Advertised hostname/IP address and port for the RAFT server.
* <<config_causal_clustering.raft_in_queue_max_batch_bytes,causal_clustering.raft_in_queue_max_batch_bytes>>: Largest batch processed by RAFT in bytes.
* <<config_causal_clustering.raft_in_queue_max_bytes,causal_clustering.raft_in_queue_max_bytes>>: Maximum number of bytes in the RAFT in-queue.
* <<config_causal_clustering.raft_listen_address,causal_clustering.raft_listen_address>>: Network interface and port for the RAFT server to listen on.
* <<config_causal_clustering.raft_log_implementation,causal_clustering.raft_log_implementation>>: RAFT log implementation.
* <<config_causal_clustering.raft_log_prune_strategy,causal_clustering.raft_log_prune_strategy>>: RAFT log pruning strategy.
* <<config_causal_clustering.raft_log_pruning_frequency,causal_clustering.raft_log_pruning_frequency>>: RAFT log pruning frequency.
* <<config_causal_clustering.raft_log_reader_pool_size,causal_clustering.raft_log_reader_pool_size>>: RAFT log reader pool size.
* <<config_causal_clustering.raft_log_rotation_size,causal_clustering.raft_log_rotation_size>>: RAFT log rotation size.
* <<config_causal_clustering.raft_membership_state_size,causal_clustering.raft_membership_state_size>>: The maximum file size before the membership state file is rotated (in unit of entries).
* <<config_causal_clustering.raft_term_state_size,causal_clustering.raft_term_state_size>>: The maximum file size before the term state file is rotated (in unit of entries).
* <<config_causal_clustering.raft_vote_state_size,causal_clustering.raft_vote_state_size>>: The maximum file size before the vote state file is rotated (in unit of entries).
* <<config_causal_clustering.read_replica_time_to_live,causal_clustering.read_replica_time_to_live>>: Time To Live before read replica is considered unavailable.
* <<config_causal_clustering.reconnection_backoff,causal_clustering.reconnection_backoff>>: Minimum time between connection attempts.
* <<config_causal_clustering.refuse_to_be_leader,causal_clustering.refuse_to_be_leader>>: Prevents the current instance from volunteering to become Raft leader.
* <<config_causal_clustering.relationship_group_id_allocation_size,causal_clustering.relationship_group_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of RELATIONSHIP_GROUP IDs.
* <<config_causal_clustering.relationship_id_allocation_size,causal_clustering.relationship_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of RELATIONSHIP IDs.
* <<config_causal_clustering.relationship_type_token_id_allocation_size,causal_clustering.relationship_type_token_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of RELATIONSHIP_TYPE_TOKEN IDs.
* <<config_causal_clustering.relationship_type_token_name_id_allocation_size,causal_clustering.relationship_type_token_name_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of RELATIONSHIP_TYPE_TOKEN_NAME IDs.
* <<config_causal_clustering.replicated_lock_token_state_size,causal_clustering.replicated_lock_token_state_size>>: The maximum file size before the replicated lock token state file is rotated (in unit of entries).
* <<config_causal_clustering.replication_retry_timeout_base,causal_clustering.replication_retry_timeout_base>>: The initial timeout until replication is retried.
* <<config_causal_clustering.replication_retry_timeout_limit,causal_clustering.replication_retry_timeout_limit>>: The upper limit for the exponentially incremented retry timeout.
* <<config_causal_clustering.schema_id_allocation_size,causal_clustering.schema_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of SCHEMA IDs.
* <<config_causal_clustering.server_groups,causal_clustering.server_groups>>: A list of group names for the server used when configuring load balancing and replication policies.
* <<config_causal_clustering.ssl_policy,causal_clustering.ssl_policy>>: Name of the SSL policy to be used by the clustering, as defined under the dbms.ssl.policy.* settings.
* <<config_causal_clustering.state_machine_apply_max_batch_size,causal_clustering.state_machine_apply_max_batch_size>>: The maximum number of operations to be batched during applications of operations in the state machines.
* <<config_causal_clustering.state_machine_flush_window_size,causal_clustering.state_machine_flush_window_size>>: The number of operations to be processed before the state machines flush to disk.
* <<config_causal_clustering.store_copy_max_retry_time_per_request,causal_clustering.store_copy_max_retry_time_per_request>>: Maximum retry time per request during store copy.
* <<config_causal_clustering.string_block_id_allocation_size,causal_clustering.string_block_id_allocation_size>>: The size of the ID allocation requests Core servers will make when they run out of STRING_BLOCK IDs.
* <<config_causal_clustering.transaction_advertised_address,causal_clustering.transaction_advertised_address>>: Advertised hostname/IP address and port for the transaction shipping server.
* <<config_causal_clustering.transaction_listen_address,causal_clustering.transaction_listen_address>>: Network interface and port for the transaction shipping server to listen on.
* <<config_causal_clustering.unknown_address_logging_throttle,causal_clustering.unknown_address_logging_throttle>>: Throttle limit for logging unknown cluster member address.
* <<config_causal_clustering.upstream_selection_strategy,causal_clustering.upstream_selection_strategy>>: An ordered list in descending preference of the strategy which read replicas use to choose the upstream server from which to pull transactional updates.
* <<config_causal_clustering.user_defined_upstream_strategy,causal_clustering.user_defined_upstream_strategy>>: Configuration of a user-defined upstream selection strategy.
* <<config_cypher.default_language_version,cypher.default_language_version>>: Set this to specify the default parser (language version).
* <<config_cypher.forbid_exhaustive_shortestpath,cypher.forbid_exhaustive_shortestpath>>: This setting is associated with performance optimization.
* <<config_cypher.forbid_shortestpath_common_nodes,cypher.forbid_shortestpath_common_nodes>>: This setting is associated with performance optimization.
* <<config_cypher.hints_error,cypher.hints_error>>: Set this to specify the behavior when Cypher planner or runtime hints cannot be fulfilled.
* <<config_cypher.lenient_create_relationship,cypher.lenient_create_relationship>>: Set this to change the behavior for Cypher create relationship when the start or end node is missing.
* <<config_cypher.min_replan_interval,cypher.min_replan_interval>>: The minimum time between possible cypher query replanning events.
* <<config_cypher.planner,cypher.planner>>: Set this to specify the default planner for the default language version.
* <<config_cypher.statistics_divergence_threshold,cypher.statistics_divergence_threshold>>: The threshold when a plan is considered stale.
* <<config_db.temporal.timezone,db.temporal.timezone>>: Database timezone for temporal functions.
* <<config_dbms.active_database,dbms.active_database>>: Name of the database to load.
* <<config_dbms.allow_format_migration,dbms.allow_format_migration>>: Whether to allow a store upgrade in case the current version of the database starts against an older store version.
* <<config_dbms.allow_upgrade,dbms.allow_upgrade>>: Whether to allow an upgrade in case the current version of the database starts against an older version.
* <<config_dbms.backup.address,dbms.backup.address>>: Listening server for online backups.
* <<config_dbms.backup.enabled,dbms.backup.enabled>>: Enable support for running online backups.
* <<config_dbms.backup.ssl_policy,dbms.backup.ssl_policy>>: Name of the SSL policy to be used by backup, as defined under the dbms.ssl.policy.* settings.
* <<config_dbms.checkpoint,dbms.checkpoint>>: Configures the general policy for when check-points should occur.
* <<config_dbms.checkpoint.interval.time,dbms.checkpoint.interval.time>>: Configures the time interval between check-points.
* <<config_dbms.checkpoint.interval.tx,dbms.checkpoint.interval.tx>>: Configures the transaction interval between check-points.
* <<config_dbms.checkpoint.iops.limit,dbms.checkpoint.iops.limit>>: Limit the number of IOs the background checkpoint process will consume per second.
* <<config_dbms.config.strict_validation,dbms.config.strict_validation>>: A strict configuration validation will prevent the database from starting up if unknown configuration options are specified in the neo4j settings namespace (such as dbms., ha., cypher., etc).
* <<config_dbms.connector.bolt.advertised_address,dbms.connector.bolt.advertised_address>>: Advertised address for this connector.
* <<config_dbms.connector.bolt.enabled,dbms.connector.bolt.enabled>>: Enable this connector.
* <<config_dbms.connector.bolt.listen_address,dbms.connector.bolt.listen_address>>: Address the connector should bind to.
* <<config_dbms.connector.bolt.thread_pool_keep_alive,dbms.connector.bolt.thread_pool_keep_alive>>: The maximum time an idle thread in the thread pool bound to this connector will wait for new tasks.
* <<config_dbms.connector.bolt.thread_pool_max_size,dbms.connector.bolt.thread_pool_max_size>>: The maximum number of threads allowed in the thread pool bound to this connector.
* <<config_dbms.connector.bolt.thread_pool_min_size,dbms.connector.bolt.thread_pool_min_size>>: The number of threads to keep in the thread pool bound to this connector, even if they are idle.
* <<config_dbms.connector.bolt.tls_level,dbms.connector.bolt.tls_level>>: Encryption level to require this connector to use.
* <<config_dbms.connector.http.advertised_address,dbms.connector.http.advertised_address>>: Advertised address for this connector.
* <<config_dbms.connector.http.enabled,dbms.connector.http.enabled>>: Enable this connector.
* <<config_dbms.connector.http.listen_address,dbms.connector.http.listen_address>>: Address the connector should bind to.
* <<config_dbms.connector.https.advertised_address,dbms.connector.https.advertised_address>>: Advertised address for this connector.
* <<config_dbms.connector.https.enabled,dbms.connector.https.enabled>>: Enable this connector.
* <<config_dbms.connector.https.listen_address,dbms.connector.https.listen_address>>: Address the connector should bind to.
* <<config_dbms.connectors.default_advertised_address,dbms.connectors.default_advertised_address>>: Default hostname or IP address the server uses to advertise itself to its connectors.
* <<config_dbms.connectors.default_listen_address,dbms.connectors.default_listen_address>>: Default network interface to listen for incoming connections.
* <<config_dbms.db.timezone,dbms.db.timezone>>: Database timezone.
* <<config_dbms.directories.certificates,dbms.directories.certificates>>: Directory for storing certificates to be used by Neo4j for TLS connections.
* <<config_dbms.directories.data,dbms.directories.data>>: Path of the data directory.
* <<config_dbms.directories.import,dbms.directories.import>>: Sets the root directory for file URLs used with the Cypher `LOAD CSV` clause.
* <<config_dbms.directories.lib,dbms.directories.lib>>: Path of the lib directory.
* <<config_dbms.directories.logs,dbms.directories.logs>>: Path of the logs directory.
* <<config_dbms.directories.metrics,dbms.directories.metrics>>: The target location of the CSV files: a path to a directory wherein a CSV file per reported field  will be written.
* <<config_dbms.directories.plugins,dbms.directories.plugins>>: Location of the database plugin directory.
* <<config_dbms.directories.run,dbms.directories.run>>: Path of the run directory.
* <<config_dbms.directories.tx_log,dbms.directories.tx_log>>: Location where Neo4j keeps the logical transaction logs.
* <<config_dbms.filewatcher.enabled,dbms.filewatcher.enabled>>: Allows the enabling or disabling of the file watcher service.
* <<config_dbms.ids.reuse.types.override,dbms.ids.reuse.types.override>>: Specified names of id types (comma separated) that should be reused.
* <<config_dbms.import.csv.buffer_size,dbms.import.csv.buffer_size>>: The size of the internal buffer in bytes used by `LOAD CSV`.
* <<config_dbms.import.csv.legacy_quote_escaping,dbms.import.csv.legacy_quote_escaping>>: Selects whether to conform to the standard https://tools.ietf.org/html/rfc4180 for interpreting escaped quotation characters in CSV files loaded using `LOAD CSV`.
* <<config_dbms.index.default_schema_provider,dbms.index.default_schema_provider>>: Index provider to use for newly created schema indexes.
* <<config_dbms.index.fulltext.default_analyzer,dbms.index.fulltext.default_analyzer>>: The name of the analyzer that the fulltext indexes should use by default.
* <<config_dbms.index.fulltext.eventually_consistent,dbms.index.fulltext.eventually_consistent>>: Whether or not fulltext indexes should be eventually consistent by default or not.
* <<config_dbms.index.fulltext.eventually_consistent_index_update_queue_max_length,dbms.index.fulltext.eventually_consistent_index_update_queue_max_length>>: The eventually_consistent mode of the fulltext indexes works by queueing up index updates to be applied later in a background thread.
* <<config_dbms.index_sampling.background_enabled,dbms.index_sampling.background_enabled>>: Enable or disable background index sampling.
* <<config_dbms.index_sampling.buffer_size,dbms.index_sampling.buffer_size>>: Size of buffer used by index sampling.
* <<config_dbms.index_sampling.sample_size_limit,dbms.index_sampling.sample_size_limit>>: Index sampling chunk size limit.
* <<config_dbms.index_sampling.update_percentage,dbms.index_sampling.update_percentage>>: Percentage of index updates of total index size required before sampling of a given index is triggered.
* <<config_dbms.index_searcher_cache_size,dbms.index_searcher_cache_size>>: The maximum number of open Lucene index searchers.
* <<config_dbms.jvm.additional,dbms.jvm.additional>>: Additional JVM arguments.
* <<config_dbms.lock.acquisition.timeout,dbms.lock.acquisition.timeout>>: The maximum time interval within which lock should be acquired.
* <<config_dbms.logs.debug.level,dbms.logs.debug.level>>: Debug log level threshold.
* <<config_dbms.logs.debug.path,dbms.logs.debug.path>>: Path to the debug log file.
* <<config_dbms.logs.debug.rotation.delay,dbms.logs.debug.rotation.delay>>: Minimum time interval after last rotation of the debug log before it may be rotated again.
* <<config_dbms.logs.debug.rotation.keep_number,dbms.logs.debug.rotation.keep_number>>: Maximum number of history files for the debug log.
* <<config_dbms.logs.debug.rotation.size,dbms.logs.debug.rotation.size>>: Threshold for rotation of the debug log.
* <<config_dbms.logs.gc.enabled,dbms.logs.gc.enabled>>: Enable GC Logging.
* <<config_dbms.logs.gc.options,dbms.logs.gc.options>>: GC Logging Options.
* <<config_dbms.logs.gc.rotation.keep_number,dbms.logs.gc.rotation.keep_number>>: Number of GC logs to keep.
* <<config_dbms.logs.gc.rotation.size,dbms.logs.gc.rotation.size>>: Size of each GC log that is kept.
* <<config_dbms.logs.http.enabled,dbms.logs.http.enabled>>: Enable HTTP request logging.
* <<config_dbms.logs.http.path,dbms.logs.http.path>>: Path to HTTP request log.
* <<config_dbms.logs.http.rotation.keep_number,dbms.logs.http.rotation.keep_number>>: Number of HTTP logs to keep.
* <<config_dbms.logs.http.rotation.size,dbms.logs.http.rotation.size>>: Size of each HTTP log that is kept.
* <<config_dbms.logs.query.allocation_logging_enabled,dbms.logs.query.allocation_logging_enabled>>: Log allocated bytes for the executed queries being logged.
* <<config_dbms.logs.query.enabled,dbms.logs.query.enabled>>: Log executed queries that take longer than the configured threshold, dbms.logs.query.threshold.
* <<config_dbms.logs.query.page_logging_enabled,dbms.logs.query.page_logging_enabled>>: Log page hits and page faults for the executed queries being logged.
* <<config_dbms.logs.query.parameter_logging_enabled,dbms.logs.query.parameter_logging_enabled>>: Log parameters for the executed queries being logged.
* <<config_dbms.logs.query.path,dbms.logs.query.path>>: Path to the query log file.
* <<config_dbms.logs.query.rotation.keep_number,dbms.logs.query.rotation.keep_number>>: Maximum number of history files for the query log.
* <<config_dbms.logs.query.rotation.size,dbms.logs.query.rotation.size>>: The file size in bytes at which the query log will auto-rotate.
* <<config_dbms.logs.query.runtime_logging_enabled,dbms.logs.query.runtime_logging_enabled>>: Logs which runtime that was used to run the query.
* <<config_dbms.logs.query.threshold,dbms.logs.query.threshold>>: If the execution of query takes more time than this threshold, the query is logged - provided query logging is enabled.
* <<config_dbms.logs.query.time_logging_enabled,dbms.logs.query.time_logging_enabled>>: Log detailed time information for the executed queries being logged.
* <<config_dbms.logs.security.level,dbms.logs.security.level>>: Security log level threshold.
* <<config_dbms.logs.security.path,dbms.logs.security.path>>: Path to the security log file.
* <<config_dbms.logs.security.rotation.delay,dbms.logs.security.rotation.delay>>: Minimum time interval after last rotation of the security log before it may be rotated again.
* <<config_dbms.logs.security.rotation.keep_number,dbms.logs.security.rotation.keep_number>>: Maximum number of history files for the security log.
* <<config_dbms.logs.security.rotation.size,dbms.logs.security.rotation.size>>: Threshold for rotation of the security log.
* <<config_dbms.logs.timezone,dbms.logs.timezone>>: Database logs timezone.
* <<config_dbms.logs.user.path,dbms.logs.user.path>>: Path to the user log file.
* <<config_dbms.logs.user.rotation.delay,dbms.logs.user.rotation.delay>>: Minimum time interval after last rotation of the user log before it may be rotated again.
* <<config_dbms.logs.user.rotation.keep_number,dbms.logs.user.rotation.keep_number>>: Maximum number of history files for the user log.
* <<config_dbms.logs.user.rotation.size,dbms.logs.user.rotation.size>>: Threshold for rotation of the user log.
* <<config_dbms.logs.user.stdout_enabled,dbms.logs.user.stdout_enabled>>: Send user logs to the process stdout.
* <<config_dbms.memory.heap.initial_size,dbms.memory.heap.initial_size>>: Initial heap size.
* <<config_dbms.memory.heap.max_size,dbms.memory.heap.max_size>>: Maximum heap size.
* <<config_dbms.memory.pagecache.size,dbms.memory.pagecache.size>>: The amount of memory to use for mapping the store files, in bytes (or kilobytes with the 'k' suffix, megabytes with 'm' and gigabytes with 'g').
* <<config_dbms.memory.pagecache.swapper,dbms.memory.pagecache.swapper>>: Specify which page swapper to use for doing paged IO.
* <<config_dbms.mode,dbms.mode>>: Configure the operating mode of the database -- 'SINGLE' for stand-alone operation, 'HA' for operating as a member in an HA cluster, 'ARBITER' for a cluster member with no database in an HA cluster, 'CORE' for operating as a core member of a Causal Cluster, or 'READ_REPLICA' for operating as a read replica member of a Causal Cluster.
* <<config_dbms.netty.ssl.provider,dbms.netty.ssl.provider>>: Netty SSL provider.
* <<config_dbms.procedures.kill_query_verbose,dbms.procedures.kill_query_verbose>>: Specifies whether or not dbms.killQueries produces a verbose output, with information about which queries were not found.
* <<config_dbms.query_cache_size,dbms.query_cache_size>>: The number of Cypher query execution plans that are cached.
* <<config_dbms.read_only,dbms.read_only>>: Only allow read operations from this Neo4j instance.
* <<config_dbms.record_format,dbms.record_format>>: Database record format.
* <<config_dbms.relationship_grouping_threshold,dbms.relationship_grouping_threshold>>: Relationship count threshold for considering a node to be dense.
* <<config_dbms.rest.transaction.idle_timeout,dbms.rest.transaction.idle_timeout>>: Timeout for idle transactions in the REST endpoint.
* <<config_dbms.security.allow_csv_import_from_file_urls,dbms.security.allow_csv_import_from_file_urls>>: Determines if Cypher will allow using file URLs when loading data using `LOAD CSV`.
* <<config_dbms.security.auth_cache_max_capacity,dbms.security.auth_cache_max_capacity>>: The maximum capacity for authentication and authorization caches (respectively).
* <<config_dbms.security.auth_cache_ttl,dbms.security.auth_cache_ttl>>: The time to live (TTL) for cached authentication and authorization info when using external auth providers (LDAP or plugin).
* <<config_dbms.security.auth_cache_use_ttl,dbms.security.auth_cache_use_ttl>>: Enable time-based eviction of the authentication and authorization info cache for external auth providers (LDAP or plugin).
* <<config_dbms.security.auth_enabled,dbms.security.auth_enabled>>: Enable auth requirement to access Neo4j.
* <<config_dbms.security.auth_lock_time,dbms.security.auth_lock_time>>: The amount of time user account should be locked after a configured number of unsuccessful authentication attempts.
* <<config_dbms.security.auth_max_failed_attempts,dbms.security.auth_max_failed_attempts>>: The maximum number of unsuccessful authentication attempts before imposing a user lock for the configured amount of time.The locked out user will not be able to log in until the lock period expires, even if correct credentials are provided.
* <<config_dbms.security.auth_provider,dbms.security.auth_provider>>: The authentication and authorization provider that contains both the users and roles.
* <<config_dbms.security.causal_clustering_status_auth_enabled,dbms.security.causal_clustering_status_auth_enabled>>: Require authorization for access to the Causal Clustering status endpoints.
* <<config_dbms.security.ha_status_auth_enabled,dbms.security.ha_status_auth_enabled>>: Require authorization for access to the HA status endpoints.
* <<config_dbms.security.http_access_control_allow_origin,dbms.security.http_access_control_allow_origin>>: Value of the Access-Control-Allow-Origin header sent over any HTTP or HTTPS connector.
* <<config_dbms.security.http_authorization_classes,dbms.security.http_authorization_classes>>: Comma-separated list of custom security rules for Neo4j to use.
* <<config_dbms.security.http_strict_transport_security,dbms.security.http_strict_transport_security>>: Value of the HTTP Strict-Transport-Security (HSTS) response header.
* <<config_dbms.security.ldap.authentication.cache_enabled,dbms.security.ldap.authentication.cache_enabled>>: Determines if the result of authentication via the LDAP server should be cached or not.
* <<config_dbms.security.ldap.authentication.mechanism,dbms.security.ldap.authentication.mechanism>>: LDAP authentication mechanism.
* <<config_dbms.security.ldap.authentication.use_samaccountname,dbms.security.ldap.authentication.use_samaccountname>>: Perform authentication with sAMAccountName instead of DN.
Using this setting requires `dbms.security.ldap.authorization.system_username` and dbms.security.ldap.authorization.system_password to be used since there is no way to log in through ldap directly with the sAMAccountName, instead the login name will be resolved to a DN that will be used to log in with.
* <<config_dbms.security.ldap.authentication.user_dn_template,dbms.security.ldap.authentication.user_dn_template>>: LDAP user DN template.
* <<config_dbms.security.ldap.authorization.group_membership_attributes,dbms.security.ldap.authorization.group_membership_attributes>>: A list of attribute names on a user object that contains groups to be used for mapping to roles when LDAP authorization is enabled.
* <<config_dbms.security.ldap.authorization.group_to_role_mapping,dbms.security.ldap.authorization.group_to_role_mapping>>: An authorization mapping from LDAP group names to Neo4j role names.
* <<config_dbms.security.ldap.authorization.system_password,dbms.security.ldap.authorization.system_password>>: An LDAP system account password to use for authorization searches when `dbms.security.ldap.authorization.use_system_account` is `true`.
* <<config_dbms.security.ldap.authorization.system_username,dbms.security.ldap.authorization.system_username>>: An LDAP system account username to use for authorization searches when `dbms.security.ldap.authorization.use_system_account` is `true`.
* <<config_dbms.security.ldap.authorization.use_system_account,dbms.security.ldap.authorization.use_system_account>>: Perform LDAP search for authorization info using a system account instead of the user's own account.
If this is set to `false` (default), the search for group membership will be performed directly after authentication using the LDAP context bound with the user's own account.
* <<config_dbms.security.ldap.authorization.user_search_base,dbms.security.ldap.authorization.user_search_base>>: The name of the base object or named context to search for user objects when LDAP authorization is enabled.
* <<config_dbms.security.ldap.authorization.user_search_filter,dbms.security.ldap.authorization.user_search_filter>>: The LDAP search filter to search for a user principal when LDAP authorization is enabled.
* <<config_dbms.security.ldap.connection_timeout,dbms.security.ldap.connection_timeout>>: The timeout for establishing an LDAP connection.
* <<config_dbms.security.ldap.host,dbms.security.ldap.host>>: URL of LDAP server to use for authentication and authorization.
* <<config_dbms.security.ldap.read_timeout,dbms.security.ldap.read_timeout>>: The timeout for an LDAP read request (i.e.
* <<config_dbms.security.ldap.referral,dbms.security.ldap.referral>>: The LDAP referral behavior when creating a connection.
* <<config_dbms.security.ldap.use_starttls,dbms.security.ldap.use_starttls>>: Use secure communication with the LDAP server using opportunistic TLS.
* <<config_dbms.security.log_successful_authentication,dbms.security.log_successful_authentication>>: Set to log successful authentication events to the security log.
* <<config_dbms.security.procedures.default_allowed,dbms.security.procedures.default_allowed>>: The default role that can execute all procedures and user-defined functions that are not covered by the `dbms.security.procedures.roles` setting.
* <<config_dbms.security.procedures.roles,dbms.security.procedures.roles>>: This provides a finer level of control over which roles can execute procedures than the `dbms.security.procedures.default_allowed` setting.
* <<config_dbms.security.procedures.unrestricted,dbms.security.procedures.unrestricted>>: A list of procedures and user defined functions (comma separated) that are allowed full access to the database.
* <<config_dbms.security.procedures.whitelist,dbms.security.procedures.whitelist>>: A list of procedures (comma separated) that are to be loaded.
* <<config_dbms.security.property_level.blacklist,dbms.security.property_level.blacklist>>: An authorization mapping for property level access for roles.
* <<config_dbms.security.property_level.enabled,dbms.security.property_level.enabled>>: Set to true to enable property level security.
* <<config_dbms.shutdown_transaction_end_timeout,dbms.shutdown_transaction_end_timeout>>: The maximum amount of time to wait for running transactions to complete before allowing initiated database shutdown to continue.
* <<config_dbms.ssl.policy.-policyname-.allow_key_generation,dbms.ssl.policy.<policyname>.allow_key_generation>>: Allows the generation of a private key and associated self-signed certificate.
* <<config_dbms.ssl.policy.-policyname-.base_directory,dbms.ssl.policy.<policyname>.base_directory>>: The mandatory base directory for cryptographic objects of this policy.
* <<config_dbms.ssl.policy.-policyname-.ciphers,dbms.ssl.policy.<policyname>.ciphers>>: Restrict allowed ciphers.
* <<config_dbms.ssl.policy.-policyname-.client_auth,dbms.ssl.policy.<policyname>.client_auth>>: Client authentication stance.
* <<config_dbms.ssl.policy.-policyname-.private_key,dbms.ssl.policy.<policyname>.private_key>>: Private PKCS#8 key in PEM format.
* <<config_dbms.ssl.policy.-policyname-.public_certificate,dbms.ssl.policy.<policyname>.public_certificate>>: X.509 certificate (chain) of this server in PEM format.
* <<config_dbms.ssl.policy.-policyname-.revoked_dir,dbms.ssl.policy.<policyname>.revoked_dir>>: Path to directory of CRLs (Certificate Revocation Lists) in PEM format.
* <<config_dbms.ssl.policy.-policyname-.tls_versions,dbms.ssl.policy.<policyname>.tls_versions>>: Restrict allowed TLS protocol versions.
* <<config_dbms.ssl.policy.-policyname-.trust_all,dbms.ssl.policy.<policyname>.trust_all>>: Makes this policy trust all remote parties.
* <<config_dbms.ssl.policy.-policyname-.trusted_dir,dbms.ssl.policy.<policyname>.trusted_dir>>: Path to directory of X.509 certificates in PEM format for trusted parties.
* <<config_dbms.ssl.policy.-policyname-.verify_hostname,dbms.ssl.policy.<policyname>.verify_hostname>>: When true, this node will verify the hostname of every other instance it connects to by comparing the address it used to connect with it and the patterns described in the remote hosts public certificate Subject Alternative Names.
* <<config_dbms.threads.worker_count,dbms.threads.worker_count>>: Number of Neo4j worker threads.
* <<config_dbms.track_query_allocation,dbms.track_query_allocation>>: Enables or disables tracking of how many bytes are allocated by the execution of a query.
* <<config_dbms.track_query_cpu_time,dbms.track_query_cpu_time>>: Enables or disables tracking of how much time a query spends actively executing on the CPU.
* <<config_dbms.transaction.bookmark_ready_timeout,dbms.transaction.bookmark_ready_timeout>>: The maximum amount of time to wait for the database state represented by the bookmark.
* <<config_dbms.transaction.monitor.check.interval,dbms.transaction.monitor.check.interval>>: Configures the time interval between transaction monitor checks.
* <<config_dbms.transaction.timeout,dbms.transaction.timeout>>: The maximum time interval of a transaction within which it should be completed.
* <<config_dbms.tx_log.rotation.retention_policy,dbms.tx_log.rotation.retention_policy>>: Make Neo4j keep the logical transaction logs for being able to backup the database.
* <<config_dbms.tx_log.rotation.size,dbms.tx_log.rotation.size>>: Specifies at which file size the logical log will auto-rotate.
* <<config_dbms.tx_state.max_off_heap_memory,dbms.tx_state.max_off_heap_memory>>: The maximum amount of off-heap memory that can be used to store transaction state data; it's a total amount of memory shared across all active transactions.
* <<config_dbms.tx_state.memory_allocation,dbms.tx_state.memory_allocation>>: Defines whether memory for transaction state should be allocated on- or off-heap.
* <<config_dbms.tx_state.off_heap.block_cache_size,dbms.tx_state.off_heap.block_cache_size>>: Defines the size of the off-heap memory blocks cache.
* <<config_dbms.tx_state.off_heap.max_cacheable_block_size,dbms.tx_state.off_heap.max_cacheable_block_size>>: Defines the maximum size of an off-heap memory block that can be cached to speed up allocations for transaction state data.
* <<config_dbms.udc.enabled,dbms.udc.enabled>>: Enable the UDC extension.
* <<config_dbms.unmanaged_extension_classes,dbms.unmanaged_extension_classes>>: Comma-separated list of <classname>=<mount point> for unmanaged extensions.
* <<config_dbms.windows_service_name,dbms.windows_service_name>>: Name of the Windows Service.
* <<config_ha.allow_init_cluster,ha.allow_init_cluster>>: Whether to allow this instance to create a cluster if unable to join.
* <<config_ha.branched_data_copying_strategy,ha.branched_data_copying_strategy>>: Strategy for how to order handling of branched data on slaves and copying of the store from the master.
* <<config_ha.branched_data_policy,ha.branched_data_policy>>: Policy for how to handle branched data.
* <<config_ha.broadcast_timeout,ha.broadcast_timeout>>: Timeout for broadcasting values in cluster.
* <<config_ha.configuration_timeout,ha.configuration_timeout>>: Timeout for waiting for configuration from an existing cluster member during cluster join.
* <<config_ha.data_chunk_size,ha.data_chunk_size>>: Max size of the data chunks that flows between master and slaves in HA.
* <<config_ha.default_timeout,ha.default_timeout>>: Default timeout used for clustering timeouts.
* <<config_ha.election_timeout,ha.election_timeout>>: Timeout for waiting for other members to finish a role election.
* <<config_ha.heartbeat_interval,ha.heartbeat_interval>>: How often heartbeat messages should be sent.
* <<config_ha.heartbeat_timeout,ha.heartbeat_timeout>>: How long to wait for heartbeats from other instances before marking them as suspects for failure.
* <<config_ha.host.coordination,ha.host.coordination>>: Host and port to bind the cluster management communication.
* <<config_ha.host.data,ha.host.data>>: Hostname and port to bind the HA server.
* <<config_ha.initial_hosts,ha.initial_hosts>>: A comma-separated list of other members of the cluster to join.
* <<config_ha.internal_role_switch_timeout,ha.internal_role_switch_timeout>>: Timeout for waiting for internal conditions during state switch, like for transactions to complete, before switching to master or slave.
* <<config_ha.join_timeout,ha.join_timeout>>: Timeout for joining a cluster.
* <<config_ha.learn_timeout,ha.learn_timeout>>: Timeout for learning values.
* <<config_ha.leave_timeout,ha.leave_timeout>>: Timeout for waiting for cluster leave to finish.
* <<config_ha.max_acceptors,ha.max_acceptors>>: Maximum number of servers to involve when agreeing to membership changes.
* <<config_ha.max_channels_per_slave,ha.max_channels_per_slave>>: Maximum number of connections a slave can have to the master.
* <<config_ha.paxos_timeout,ha.paxos_timeout>>: Default value for all Paxos timeouts.
* <<config_ha.phase1_timeout,ha.phase1_timeout>>: Timeout for Paxos phase 1.
* <<config_ha.phase2_timeout,ha.phase2_timeout>>: Timeout for Paxos phase 2.
* <<config_ha.pull_batch_size,ha.pull_batch_size>>: Size of batches of transactions applied on slaves when pulling from master.
* <<config_ha.pull_interval,ha.pull_interval>>: Interval of pulling updates from master.
* <<config_ha.role_switch_timeout,ha.role_switch_timeout>>: Timeout for request threads waiting for instance to become master or slave.
* <<config_ha.server_id,ha.server_id>>: Id for a cluster instance.
* <<config_ha.slave_lock_timeout,ha.slave_lock_timeout>>: Timeout for taking remote (write) locks on slaves.
* <<config_ha.slave_only,ha.slave_only>>: Whether this instance should only participate as slave in cluster.
* <<config_ha.slave_read_timeout,ha.slave_read_timeout>>: How long a slave will wait for response from master before giving up.
* <<config_ha.tx_push_factor,ha.tx_push_factor>>: The amount of slaves the master will ask to replicate a committed transaction.
* <<config_ha.tx_push_strategy,ha.tx_push_strategy>>: Push strategy of a transaction to a slave during commit.
* <<config_https.ssl_policy,https.ssl_policy>>: SSL policy name.
* <<config_metrics.bolt.messages.enabled,metrics.bolt.messages.enabled>>: Enable reporting metrics about Bolt Protocol message processing.
* <<config_metrics.csv.enabled,metrics.csv.enabled>>: Set to `true` to enable exporting metrics to CSV files.
* <<config_metrics.csv.interval,metrics.csv.interval>>: The reporting interval for the CSV files.
* <<config_metrics.csv.rotation.keep_number,metrics.csv.rotation.keep_number>>: Maximum number of history files for the csv files.
* <<config_metrics.csv.rotation.size,metrics.csv.rotation.size>>: The file size in bytes at which the csv files will auto-rotate.
* <<config_metrics.cypher.replanning.enabled,metrics.cypher.replanning.enabled>>: Enable reporting metrics about number of occurred replanning events.
* <<config_metrics.enabled,metrics.enabled>>: The default enablement value for all the supported metrics.
* <<config_metrics.graphite.enabled,metrics.graphite.enabled>>: Set to `true` to enable exporting metrics to Graphite.
* <<config_metrics.graphite.interval,metrics.graphite.interval>>: The reporting interval for Graphite.
* <<config_metrics.graphite.server,metrics.graphite.server>>: The hostname or IP address of the Graphite server.
* <<config_metrics.jvm.buffers.enabled,metrics.jvm.buffers.enabled>>: Enable reporting metrics about the buffer pools.
* <<config_metrics.jvm.gc.enabled,metrics.jvm.gc.enabled>>: Enable reporting metrics about the duration of garbage collections.
* <<config_metrics.jvm.memory.enabled,metrics.jvm.memory.enabled>>: Enable reporting metrics about the memory usage.
* <<config_metrics.jvm.threads.enabled,metrics.jvm.threads.enabled>>: Enable reporting metrics about the current number of threads running.
* <<config_metrics.neo4j.causal_clustering.enabled,metrics.neo4j.causal_clustering.enabled>>: Enable reporting metrics about Causal Clustering mode.
* <<config_metrics.neo4j.checkpointing.enabled,metrics.neo4j.checkpointing.enabled>>: Enable reporting metrics about Neo4j check pointing.
* <<config_metrics.neo4j.cluster.enabled,metrics.neo4j.cluster.enabled>>: Enable reporting metrics about HA cluster info.
* <<config_metrics.neo4j.counts.enabled,metrics.neo4j.counts.enabled>>: Enable reporting metrics about approximately how many entities are in the database.
* <<config_metrics.neo4j.enabled,metrics.neo4j.enabled>>: The default enablement value for all Neo4j specific support metrics.
* <<config_metrics.neo4j.logrotation.enabled,metrics.neo4j.logrotation.enabled>>: Enable reporting metrics about the Neo4j log rotation.
* <<config_metrics.neo4j.network.enabled,metrics.neo4j.network.enabled>>: Enable reporting metrics about the network usage.
* <<config_metrics.neo4j.pagecache.enabled,metrics.neo4j.pagecache.enabled>>: Enable reporting metrics about the Neo4j page cache.
* <<config_metrics.neo4j.server.enabled,metrics.neo4j.server.enabled>>: Enable reporting metrics about Server threading info.
* <<config_metrics.neo4j.tx.enabled,metrics.neo4j.tx.enabled>>: Enable reporting metrics about transactions.
* <<config_metrics.prefix,metrics.prefix>>: A common prefix for the reported metrics field names.
* <<config_metrics.prometheus.enabled,metrics.prometheus.enabled>>: Set to `true` to enable the Prometheus endpoint.
* <<config_metrics.prometheus.endpoint,metrics.prometheus.endpoint>>: The hostname and port to use as Prometheus endpoint.
* <<config_tools.consistency_checker.check_graph,tools.consistency_checker.check_graph>>: This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead.
* <<config_tools.consistency_checker.check_index_structure,tools.consistency_checker.check_index_structure>>: This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead.
* <<config_tools.consistency_checker.check_indexes,tools.consistency_checker.check_indexes>>: This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead.
* <<config_tools.consistency_checker.check_label_scan_store,tools.consistency_checker.check_label_scan_store>>: This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead.
* <<config_tools.consistency_checker.check_property_owners,tools.consistency_checker.check_property_owners>>: This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead.
endif::nonhtmloutput[]


// end::settings-reference-all-settings[]

[[config_bolt.ssl_policy]]
.bolt.ssl_policy
[cols="<1h,<4"]
|===
|Description
a|Specify the SSL policy to use for the encrypted bolt connections.
|Valid values
a|bolt.ssl_policy is a string
|Default value
m|legacy
|===

[[config_browser.allow_outgoing_connections]]
.browser.allow_outgoing_connections
[cols="<1h,<4"]
|===
|Description
a|Configure the policy for outgoing Neo4j Browser connections.
|Valid values
a|browser.allow_outgoing_connections is a boolean
|Default value
m|true
|===

[[config_browser.credential_timeout]]
.browser.credential_timeout
[cols="<1h,<4"]
|===
|Description
a|Configure the Neo4j Browser to time out logged in users after this idle period. Setting this to 0 indicates no limit.
|Valid values
a|browser.credential_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|0s
|===

[[config_browser.post_connect_cmd]]
.browser.post_connect_cmd
[cols="<1h,<4"]
|===
|Description
a|Commands to be run when Neo4j Browser successfully connects to this server. Separate multiple commands with semi-colon.
|Valid values
a|browser.post_connect_cmd is a string
|Default value
m|
|===

[[config_browser.remote_content_hostname_whitelist]]
.browser.remote_content_hostname_whitelist
[cols="<1h,<4"]
|===
|Description
a|Whitelist of hosts for the Neo4j Browser to be allowed to fetch content from.
|Valid values
a|browser.remote_content_hostname_whitelist is a string
|Default value
m|guides.neo4j.com,localhost
|===

[[config_browser.retain_connection_credentials]]
.browser.retain_connection_credentials
[cols="<1h,<4"]
|===
|Description
a|Configure the Neo4j Browser to store or not store user credentials.
|Valid values
a|browser.retain_connection_credentials is a boolean
|Default value
m|true
|===

[[config_causal_clustering.array_block_id_allocation_size]]
.causal_clustering.array_block_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of ARRAY_BLOCK IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.array_block_id_allocation_size is an integer
|Default value
m|1024
|===

[[config_causal_clustering.catch_up_client_inactivity_timeout]]
.causal_clustering.catch_up_client_inactivity_timeout
[cols="<1h,<4"]
|===
|Description
a|The catch up protocol times out if the given duration elapses with no network activity. Every message received by the client from the server extends the time out duration.
|Valid values
a|causal_clustering.catch_up_client_inactivity_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|600s
|===

[[config_causal_clustering.catchup_batch_size]]
.causal_clustering.catchup_batch_size
[cols="<1h,<4"]
|===
|Description
a|The maximum batch size when catching up (in unit of entries)
|Valid values
a|causal_clustering.catchup_batch_size is an integer
|Default value
m|64
|===

[[config_causal_clustering.cluster_allow_reads_on_followers]]
.causal_clustering.cluster_allow_reads_on_followers
[cols="<1h,<4"]
|===
|Description
a|Configure if the `dbms.cluster.routing.getServers()` procedure should include followers as read endpoints or return only read replicas. Note: if there are no read replicas in the cluster, followers are returned as read end points regardless the value of this setting. Defaults to true so that followers are available for read-only queries in a typical heterogeneous setup.
|Valid values
a|causal_clustering.cluster_allow_reads_on_followers is a boolean
|Default value
m|true
|===

[[config_causal_clustering.cluster_binding_timeout]]
.causal_clustering.cluster_binding_timeout
[cols="<1h,<4"]
|===
|Description
a|The time allowed after the Causal Clustering components start for a Neo4j Core Server to either join a cluster or form a new cluster with the other Neo4j Core Servers provided by `<<config_causal_clustering.initial_discovery_members,causal_clustering.initial_discovery_members>>`.
|Valid values
a|causal_clustering.cluster_binding_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|300s
|===

[[config_causal_clustering.cluster_routing_ttl]]
.causal_clustering.cluster_routing_ttl
[cols="<1h,<4"]
|===
|Description
a|How long drivers should cache the data from the `dbms.cluster.routing.getServers()` procedure.
|Valid values
a|causal_clustering.cluster_routing_ttl is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's') which is minimum `PT1S`
|Default value
m|300s
|===

[[config_causal_clustering.cluster_topology_refresh]]
.causal_clustering.cluster_topology_refresh
[cols="<1h,<4"]
|===
|Description
a|Time between scanning the cluster to refresh current server's view of topology.
|Valid values
a|causal_clustering.cluster_topology_refresh is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's') which is minimum `PT1S`
|Default value
m|5s
|===

[[config_causal_clustering.connect-randomly-to-server-group]]
.causal_clustering.connect-randomly-to-server-group
[cols="<1h,<4"]
|===
|Description
a|Comma separated list of groups to be used by the connect-randomly-to-server-group selection strategy. The connect-randomly-to-server-group strategy is used if the list of strategies (`<<config_causal_clustering.upstream_selection_strategy,causal_clustering.upstream_selection_strategy>>`) includes the value `connect-randomly-to-server-group`. 
|Valid values
a|causal_clustering.connect-randomly-to-server-group is a list separated by "," where items are a string
|Default value
m|[]
|===

[[config_causal_clustering.database]]
.causal_clustering.database
[cols="<1h,<4"]
|===
|Description
a|The name of the database being hosted by this server instance. This configuration setting may be safely ignored unless deploying a multicluster. Instances may be allocated to distinct sub-clusters by assigning them distinct database names using this setting. For instance if you had 6 instances you could form 2 sub-clusters by assigning half the database name "foo", half the name "bar". The setting value must match exactly between members of the same sub-cluster. This setting is a one-off: once an instance is configured with a database name it may not be changed in future without using neo4j-admin unbind.
|Valid values
a|causal_clustering.database is a string
|Default value
m|default
|===

[[config_causal_clustering.disable_middleware_logging]]
.causal_clustering.disable_middleware_logging
[cols="<1h,<4"]
|===
|Description
a|Prevents the network middleware from dumping its own logs. Defaults to true.
|Valid values
a|causal_clustering.disable_middleware_logging is a boolean
|Default value
m|true
|===

[[config_causal_clustering.discovery_advertised_address]]
.causal_clustering.discovery_advertised_address
[cols="<1h,<4"]
|===
|Description
a|Advertised cluster member discovery management communication.
|Valid values
a|an advertised socket address
|Default value
m|localhost:5000
|===

[[config_causal_clustering.discovery_listen_address]]
.causal_clustering.discovery_listen_address
[cols="<1h,<4"]
|===
|Description
a|Host and port to bind the cluster member discovery management communication.
|Valid values
a|a listen socket address
|Default value
m|127.0.0.1:5000
|===

[[config_causal_clustering.discovery_type]]
.causal_clustering.discovery_type
[cols="<1h,<4"]
|===
|Description
a|Configure the discovery type used for cluster name resolution.
|Valid values
a|causal_clustering.discovery_type is one of `DNS`, `LIST`, `SRV`, `K8S`
|Default value
m|LIST
|===

[[config_causal_clustering.enable_pre_voting]]
.causal_clustering.enable_pre_voting
[cols="<1h,<4"]
|===
|Description
a|Enable pre-voting extension to the Raft protocol (this is breaking and must match between the core cluster members)
|Valid values
a|causal_clustering.enable_pre_voting is a boolean
|Default value
m|false
|===

[[config_causal_clustering.expected_core_cluster_size]]
.causal_clustering.expected_core_cluster_size
[cols="<1h,<4"]
|===
|Description
a|Expected number of Core machines in the cluster before startup.
|Valid values
a|causal_clustering.expected_core_cluster_size is an integer
|Default value
m|3
|Deprecated
a|The `causal_clustering.expected_core_cluster_size` configuration setting has been deprecated.
|Replaced by
a|<<config_causal_clustering.minimum_core_cluster_size_at_formation,causal_clustering.minimum_core_cluster_size_at_formation>>, <<config_causal_clustering.minimum_core_cluster_size_at_runtime,causal_clustering.minimum_core_cluster_size_at_runtime>>
|===

[[config_causal_clustering.global_session_tracker_state_size]]
.causal_clustering.global_session_tracker_state_size
[cols="<1h,<4"]
|===
|Description
a|The maximum file size before the global session tracker state file is rotated (in unit of entries)
|Valid values
a|causal_clustering.global_session_tracker_state_size is an integer
|Default value
m|1000
|===

[[config_causal_clustering.handshake_timeout]]
.causal_clustering.handshake_timeout
[cols="<1h,<4"]
|===
|Description
a|Time out for protocol negotiation handshake.
|Valid values
a|causal_clustering.handshake_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|20s
|===

[[config_causal_clustering.id_alloc_state_size]]
.causal_clustering.id_alloc_state_size
[cols="<1h,<4"]
|===
|Description
a|The maximum file size before the ID allocation file is rotated (in unit of entries)
|Valid values
a|causal_clustering.id_alloc_state_size is an integer
|Default value
m|1000
|===

[[config_causal_clustering.in_flight_cache.max_bytes]]
.causal_clustering.in_flight_cache.max_bytes
[cols="<1h,<4"]
|===
|Description
a|The maximum number of bytes in the in-flight cache.
|Valid values
a|causal_clustering.in_flight_cache.max_bytes is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`)
|Default value
m|2147483648
|===

[[config_causal_clustering.in_flight_cache.max_entries]]
.causal_clustering.in_flight_cache.max_entries
[cols="<1h,<4"]
|===
|Description
a|The maximum number of entries in the in-flight cache.
|Valid values
a|causal_clustering.in_flight_cache.max_entries is an integer
|Default value
m|1024
|===

[[config_causal_clustering.in_flight_cache.type]]
.causal_clustering.in_flight_cache.type
[cols="<1h,<4"]
|===
|Description
a|Type of in-flight cache.
|Valid values
a|causal_clustering.in_flight_cache.type is one of `NONE`, `CONSECUTIVE`, `UNBOUNDED`
|Default value
m|CONSECUTIVE
|===

[[config_causal_clustering.initial_discovery_members]]
.causal_clustering.initial_discovery_members
[cols="<1h,<4"]
|===
|Description
a|A comma-separated list of other members of the cluster to join.
|Valid values
a|causal_clustering.initial_discovery_members is a list separated by "," where items are an advertised socket address
|===

[[config_causal_clustering.join_catch_up_timeout]]
.causal_clustering.join_catch_up_timeout
[cols="<1h,<4"]
|===
|Description
a|Time out for a new member to catch up.
|Valid values
a|causal_clustering.join_catch_up_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|600s
|===

[[config_causal_clustering.kubernetes.address]]
.causal_clustering.kubernetes.address
[cols="<1h,<4"]
|===
|Description
a|Address for Kubernetes API.
|Valid values
a|causal_clustering.kubernetes.address is an advertised socket address
|Default value
m|kubernetes.default.svc:443
|===

[[config_causal_clustering.kubernetes.ca_crt]]
.causal_clustering.kubernetes.ca_crt
[cols="<1h,<4"]
|===
|Description
a|File location of CA certificate for Kubernetes API.
|Valid values
a|causal_clustering.kubernetes.ca_crt is a path
|Default value
m|/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
|===

[[config_causal_clustering.kubernetes.label_selector]]
.causal_clustering.kubernetes.label_selector
[cols="<1h,<4"]
|===
|Description
a|LabelSelector for Kubernetes API.
|Valid values
a|causal_clustering.kubernetes.label_selector is a string
|===

[[config_causal_clustering.kubernetes.namespace]]
.causal_clustering.kubernetes.namespace
[cols="<1h,<4"]
|===
|Description
a|File location of namespace for Kubernetes API.
|Valid values
a|causal_clustering.kubernetes.namespace is a path
|Default value
m|/var/run/secrets/kubernetes.io/serviceaccount/namespace
|===

[[config_causal_clustering.kubernetes.service_port_name]]
.causal_clustering.kubernetes.service_port_name
[cols="<1h,<4"]
|===
|Description
a|Service port name for discovery for Kubernetes API.
|Valid values
a|causal_clustering.kubernetes.service_port_name is a string
|===

[[config_causal_clustering.kubernetes.token]]
.causal_clustering.kubernetes.token
[cols="<1h,<4"]
|===
|Description
a|File location of token for Kubernetes API.
|Valid values
a|causal_clustering.kubernetes.token is a path
|Default value
m|/var/run/secrets/kubernetes.io/serviceaccount/token
|===

[[config_causal_clustering.label_token_id_allocation_size]]
.causal_clustering.label_token_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of LABEL_TOKEN IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.label_token_id_allocation_size is an integer
|Default value
m|32
|===

[[config_causal_clustering.label_token_name_id_allocation_size]]
.causal_clustering.label_token_name_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of LABEL_TOKEN_NAME IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.label_token_name_id_allocation_size is an integer
|Default value
m|1024
|===

[[config_causal_clustering.last_applied_state_size]]
.causal_clustering.last_applied_state_size
[cols="<1h,<4"]
|===
|Description
a|The maximum file size before the storage file is rotated (in unit of entries)
|Valid values
a|causal_clustering.last_applied_state_size is an integer
|Default value
m|1000
|===

[[config_causal_clustering.leader_election_timeout]]
.causal_clustering.leader_election_timeout
[cols="<1h,<4"]
|===
|Description
a|The time limit within which a new leader election will occur if no messages are received.
|Valid values
a|causal_clustering.leader_election_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|7s
|===

[[config_causal_clustering.load_balancing.config]]
.causal_clustering.load_balancing.config
[cols="<1h,<4"]
|===
|Description
a|The configuration must be valid for the configured plugin and usually existsunder matching subkeys, e.g. ..config.server_policies.*This is just a top-level placeholder for the plugin-specific configuration.
|Valid values
a|causal_clustering.load_balancing.config is a string
|Default value
m|
|===

[[config_causal_clustering.load_balancing.plugin]]
.causal_clustering.load_balancing.plugin
[cols="<1h,<4"]
|===
|Description
a|The load balancing plugin to use.
|Valid values
a|causal_clustering.load_balancing.plugin is a string
|Default value
m|server_policies
|===

[[config_causal_clustering.load_balancing.shuffle]]
.causal_clustering.load_balancing.shuffle
[cols="<1h,<4"]
|===
|Description
a|Enables shuffling of the returned load balancing result.
|Valid values
a|causal_clustering.load_balancing.shuffle is a boolean
|Default value
m|true
|===

[[config_causal_clustering.log_shipping_max_lag]]
.causal_clustering.log_shipping_max_lag
[cols="<1h,<4"]
|===
|Description
a|The maximum lag allowed before log shipping pauses (in unit of entries)
|Valid values
a|causal_clustering.log_shipping_max_lag is an integer
|Default value
m|256
|===

[[config_causal_clustering.middleware_logging.level]]
.causal_clustering.middleware_logging.level
[cols="<1h,<4"]
|===
|Description
a|The level of middleware logging.
|Valid values
a|causal_clustering.middleware_logging.level is an integer
|Default value
m|500
|===

[[config_causal_clustering.minimum_core_cluster_size_at_formation]]
.causal_clustering.minimum_core_cluster_size_at_formation
[cols="<1h,<4"]
|===
|Description
a|Minimum number of Core machines initially required to form a cluster. The cluster will form when at least this many Core members have discovered each other.
|Valid values
a|causal_clustering.minimum_core_cluster_size_at_formation is an integer which is minimum `2`
|Default value
m|3
|===

[[config_causal_clustering.minimum_core_cluster_size_at_runtime]]
.causal_clustering.minimum_core_cluster_size_at_runtime
[cols="<1h,<4"]
|===
|Description
a|The minimum size of the dynamically adjusted voting set (which only core members may be a part of). Adjustments to the voting set happen automatically as the availability of core members changes, due to explicit operations such as starting or stopping a member, or unintended issues such as network partitions. Note that this dynamic scaling of the voting set is generally desirable as under some circumstances it can increase the number of instance failures which may be tolerated. A majority of the voting set must be available before voting in or out members.
|Valid values
a|causal_clustering.minimum_core_cluster_size_at_runtime is an integer which is minimum `2`
|Default value
m|3
|===

[[config_causal_clustering.multi_dc_license]]
.causal_clustering.multi_dc_license
[cols="<1h,<4"]
|===
|Description
a|Enable multi-data center features. Requires appropriate licensing.
|Valid values
a|causal_clustering.multi_dc_license is a boolean
|Default value
m|false
|===

[[config_causal_clustering.neostore_block_id_allocation_size]]
.causal_clustering.neostore_block_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of NEOSTORE_BLOCK IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.neostore_block_id_allocation_size is an integer
|Default value
m|1024
|===

[[config_causal_clustering.node_id_allocation_size]]
.causal_clustering.node_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of NODE IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.node_id_allocation_size is an integer
|Default value
m|1024
|===

[[config_causal_clustering.node_labels_id_allocation_size]]
.causal_clustering.node_labels_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of NODE_LABELS IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.node_labels_id_allocation_size is an integer
|Default value
m|1024
|===

[[config_causal_clustering.property_id_allocation_size]]
.causal_clustering.property_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of PROPERTY IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.property_id_allocation_size is an integer
|Default value
m|1024
|===

[[config_causal_clustering.property_key_token_id_allocation_size]]
.causal_clustering.property_key_token_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of PROPERTY_KEY_TOKEN IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.property_key_token_id_allocation_size is an integer
|Default value
m|32
|===

[[config_causal_clustering.property_key_token_name_id_allocation_size]]
.causal_clustering.property_key_token_name_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of PROPERTY_KEY_TOKEN_NAME IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.property_key_token_name_id_allocation_size is an integer
|Default value
m|1024
|===

[[config_causal_clustering.protocol_implementations.catchup]]
.causal_clustering.protocol_implementations.catchup
[cols="<1h,<4"]
|===
|Description
a|Catchup protocol implementation versions that this instance will allow in negotiation as a comma-separated list. Order is not relevant: the greatest value will be preferred. An empty list will allow all supported versions.
|Valid values
a|causal_clustering.protocol_implementations.catchup is a list separated by "," where items are an integer
|Default value
m|[]
|===

[[config_causal_clustering.protocol_implementations.compression]]
.causal_clustering.protocol_implementations.compression
[cols="<1h,<4"]
|===
|Description
a|Network compression algorithms that this instance will allow in negotiation as a comma-separated list. Listed in descending order of preference for incoming connections. An empty list implies no compression. For outgoing connections this merely specifies the allowed set of algorithms and the preference of the  remote peer will be used for making the decision. Allowable values: [Gzip,Snappy,Snappy_validating,LZ4,LZ4_high_compression,LZ_validating,LZ4_high_compression_validating]
|Valid values
a|causal_clustering.protocol_implementations.compression is a list separated by "," where items are a string
|Default value
m|[]
|===

[[config_causal_clustering.protocol_implementations.raft]]
.causal_clustering.protocol_implementations.raft
[cols="<1h,<4"]
|===
|Description
a|Raft protocol implementation versions that this instance will allow in negotiation as a comma-separated list. Order is not relevant: the greatest value will be preferred. An empty list will allow all supported versions.
|Valid values
a|causal_clustering.protocol_implementations.raft is a list separated by "," where items are an integer
|Default value
m|[]
|===

[[config_causal_clustering.pull_interval]]
.causal_clustering.pull_interval
[cols="<1h,<4"]
|===
|Description
a|Interval of pulling updates from cores.
|Valid values
a|causal_clustering.pull_interval is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|1s
|===

[[config_causal_clustering.raft_advertised_address]]
.causal_clustering.raft_advertised_address
[cols="<1h,<4"]
|===
|Description
a|Advertised hostname/IP address and port for the RAFT server.
|Valid values
a|an advertised socket address
|Default value
m|localhost:7000
|===

[[config_causal_clustering.raft_in_queue_max_batch_bytes]]
.causal_clustering.raft_in_queue_max_batch_bytes
[cols="<1h,<4"]
|===
|Description
a|Largest batch processed by RAFT in bytes.
|Valid values
a|causal_clustering.raft_in_queue_max_batch_bytes is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`)
|Default value
m|8388608
|===

[[config_causal_clustering.raft_in_queue_max_bytes]]
.causal_clustering.raft_in_queue_max_bytes
[cols="<1h,<4"]
|===
|Description
a|Maximum number of bytes in the RAFT in-queue.
|Valid values
a|causal_clustering.raft_in_queue_max_bytes is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`)
|Default value
m|2147483648
|===

[[config_causal_clustering.raft_listen_address]]
.causal_clustering.raft_listen_address
[cols="<1h,<4"]
|===
|Description
a|Network interface and port for the RAFT server to listen on.
|Valid values
a|a listen socket address
|Default value
m|127.0.0.1:7000
|===

[[config_causal_clustering.raft_log_implementation]]
.causal_clustering.raft_log_implementation
[cols="<1h,<4"]
|===
|Description
a|RAFT log implementation.
|Valid values
a|causal_clustering.raft_log_implementation is a string
|Default value
m|SEGMENTED
|===

[[config_causal_clustering.raft_log_prune_strategy]]
.causal_clustering.raft_log_prune_strategy
[cols="<1h,<4"]
|===
|Description
a|RAFT log pruning strategy.
|Valid values
a|causal_clustering.raft_log_prune_strategy is a string
|Default value
m|1g size
|===

[[config_causal_clustering.raft_log_pruning_frequency]]
.causal_clustering.raft_log_pruning_frequency
[cols="<1h,<4"]
|===
|Description
a|RAFT log pruning frequency.
|Valid values
a|causal_clustering.raft_log_pruning_frequency is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|600s
|===

[[config_causal_clustering.raft_log_reader_pool_size]]
.causal_clustering.raft_log_reader_pool_size
[cols="<1h,<4"]
|===
|Description
a|RAFT log reader pool size.
|Valid values
a|causal_clustering.raft_log_reader_pool_size is an integer
|Default value
m|8
|===

[[config_causal_clustering.raft_log_rotation_size]]
.causal_clustering.raft_log_rotation_size
[cols="<1h,<4"]
|===
|Description
a|RAFT log rotation size.
|Valid values
a|causal_clustering.raft_log_rotation_size is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`) which is minimum `1024`
|Default value
m|262144000
|===

[[config_causal_clustering.raft_membership_state_size]]
.causal_clustering.raft_membership_state_size
[cols="<1h,<4"]
|===
|Description
a|The maximum file size before the membership state file is rotated (in unit of entries)
|Valid values
a|causal_clustering.raft_membership_state_size is an integer
|Default value
m|1000
|===

[[config_causal_clustering.raft_term_state_size]]
.causal_clustering.raft_term_state_size
[cols="<1h,<4"]
|===
|Description
a|The maximum file size before the term state file is rotated (in unit of entries)
|Valid values
a|causal_clustering.raft_term_state_size is an integer
|Default value
m|1000
|===

[[config_causal_clustering.raft_vote_state_size]]
.causal_clustering.raft_vote_state_size
[cols="<1h,<4"]
|===
|Description
a|The maximum file size before the vote state file is rotated (in unit of entries)
|Valid values
a|causal_clustering.raft_vote_state_size is an integer
|Default value
m|1000
|===

[[config_causal_clustering.read_replica_time_to_live]]
.causal_clustering.read_replica_time_to_live
[cols="<1h,<4"]
|===
|Description
a|Time To Live before read replica is considered unavailable.
|Valid values
a|causal_clustering.read_replica_time_to_live is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's') which is minimum `PT1M`
|Default value
m|60s
|===

[[config_causal_clustering.reconnection_backoff]]
.causal_clustering.reconnection_backoff
[cols="<1h,<4"]
|===
|Description
a|Minimum time between connection attempts.
|Valid values
a|causal_clustering.reconnection_backoff is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|5s
|===

[[config_causal_clustering.refuse_to_be_leader]]
.causal_clustering.refuse_to_be_leader
[cols="<1h,<4"]
|===
|Description
a|Prevents the current instance from volunteering to become Raft leader. Defaults to false, and should only be used in exceptional circumstances by expert users. Using this can result in reduced availability for the cluster.
|Valid values
a|causal_clustering.refuse_to_be_leader is a boolean
|Default value
m|false
|===

[[config_causal_clustering.relationship_group_id_allocation_size]]
.causal_clustering.relationship_group_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of RELATIONSHIP_GROUP IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.relationship_group_id_allocation_size is an integer
|Default value
m|1024
|===

[[config_causal_clustering.relationship_id_allocation_size]]
.causal_clustering.relationship_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of RELATIONSHIP IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.relationship_id_allocation_size is an integer
|Default value
m|1024
|===

[[config_causal_clustering.relationship_type_token_id_allocation_size]]
.causal_clustering.relationship_type_token_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of RELATIONSHIP_TYPE_TOKEN IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.relationship_type_token_id_allocation_size is an integer
|Default value
m|32
|===

[[config_causal_clustering.relationship_type_token_name_id_allocation_size]]
.causal_clustering.relationship_type_token_name_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of RELATIONSHIP_TYPE_TOKEN_NAME IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.relationship_type_token_name_id_allocation_size is an integer
|Default value
m|1024
|===

[[config_causal_clustering.replicated_lock_token_state_size]]
.causal_clustering.replicated_lock_token_state_size
[cols="<1h,<4"]
|===
|Description
a|The maximum file size before the replicated lock token state file is rotated (in unit of entries)
|Valid values
a|causal_clustering.replicated_lock_token_state_size is an integer
|Default value
m|1000
|===

[[config_causal_clustering.replication_retry_timeout_base]]
.causal_clustering.replication_retry_timeout_base
[cols="<1h,<4"]
|===
|Description
a|The initial timeout until replication is retried. The timeout will increase exponentially.
|Valid values
a|causal_clustering.replication_retry_timeout_base is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|10s
|===

[[config_causal_clustering.replication_retry_timeout_limit]]
.causal_clustering.replication_retry_timeout_limit
[cols="<1h,<4"]
|===
|Description
a|The upper limit for the exponentially incremented retry timeout.
|Valid values
a|causal_clustering.replication_retry_timeout_limit is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|60s
|===

[[config_causal_clustering.schema_id_allocation_size]]
.causal_clustering.schema_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of SCHEMA IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.schema_id_allocation_size is an integer
|Default value
m|1024
|===

[[config_causal_clustering.server_groups]]
.causal_clustering.server_groups
[cols="<1h,<4"]
|===
|Description
a|A list of group names for the server used when configuring load balancing and replication policies.
|Valid values
a|causal_clustering.server_groups is a list separated by "," where items are a string
|Default value
m|[]
|===

[[config_causal_clustering.ssl_policy]]
.causal_clustering.ssl_policy
[cols="<1h,<4"]
|===
|Description
a|Name of the SSL policy to be used by the clustering, as defined under the dbms.ssl.policy.* settings. If no policy is configured then the communication will not be secured.
|Valid values
a|causal_clustering.ssl_policy is a string
|===

[[config_causal_clustering.state_machine_apply_max_batch_size]]
.causal_clustering.state_machine_apply_max_batch_size
[cols="<1h,<4"]
|===
|Description
a|The maximum number of operations to be batched during applications of operations in the state machines.
|Valid values
a|causal_clustering.state_machine_apply_max_batch_size is an integer
|Default value
m|16
|===

[[config_causal_clustering.state_machine_flush_window_size]]
.causal_clustering.state_machine_flush_window_size
[cols="<1h,<4"]
|===
|Description
a|The number of operations to be processed before the state machines flush to disk.
|Valid values
a|causal_clustering.state_machine_flush_window_size is an integer
|Default value
m|4096
|===

[[config_causal_clustering.store_copy_max_retry_time_per_request]]
.causal_clustering.store_copy_max_retry_time_per_request
[cols="<1h,<4"]
|===
|Description
a|Maximum retry time per request during store copy. Regular store files and indexes are downloaded in separate requests during store copy. This configures the maximum time failed requests are allowed to resend. 
|Valid values
a|causal_clustering.store_copy_max_retry_time_per_request is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|1200s
|===

[[config_causal_clustering.string_block_id_allocation_size]]
.causal_clustering.string_block_id_allocation_size
[cols="<1h,<4"]
|===
|Description
a|The size of the ID allocation requests Core servers will make when they run out of STRING_BLOCK IDs. Larger values mean less frequent requests but also result in more unused IDs (and unused disk space) in the event of a crash.
|Valid values
a|causal_clustering.string_block_id_allocation_size is an integer
|Default value
m|1024
|===

[[config_causal_clustering.transaction_advertised_address]]
.causal_clustering.transaction_advertised_address
[cols="<1h,<4"]
|===
|Description
a|Advertised hostname/IP address and port for the transaction shipping server.
|Valid values
a|an advertised socket address
|Default value
m|localhost:6000
|===

[[config_causal_clustering.transaction_listen_address]]
.causal_clustering.transaction_listen_address
[cols="<1h,<4"]
|===
|Description
a|Network interface and port for the transaction shipping server to listen on. Please note that it is also possible to run the backup client against this port so always limit access to it via the firewall and configure an ssl policy.
|Valid values
a|a listen socket address
|Default value
m|127.0.0.1:6000
|===

[[config_causal_clustering.unknown_address_logging_throttle]]
.causal_clustering.unknown_address_logging_throttle
[cols="<1h,<4"]
|===
|Description
a|Throttle limit for logging unknown cluster member address.
|Valid values
a|causal_clustering.unknown_address_logging_throttle is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|10s
|===

[[config_causal_clustering.upstream_selection_strategy]]
.causal_clustering.upstream_selection_strategy
[cols="<1h,<4"]
|===
|Description
a|An ordered list in descending preference of the strategy which read replicas use to choose the upstream server from which to pull transactional updates.
|Valid values
a|causal_clustering.upstream_selection_strategy is a list separated by "," where items are a string
|Default value
m|[default]
|===

[[config_causal_clustering.user_defined_upstream_strategy]]
.causal_clustering.user_defined_upstream_strategy
[cols="<1h,<4"]
|===
|Description
a|Configuration of a user-defined upstream selection strategy. The user-defined strategy is used if the list of strategies (`<<config_causal_clustering.upstream_selection_strategy,causal_clustering.upstream_selection_strategy>>`) includes the value `user_defined`. 
|Valid values
a|causal_clustering.user_defined_upstream_strategy is a string
|Default value
m|
|===

[[config_cypher.default_language_version]]
.cypher.default_language_version
[cols="<1h,<4"]
|===
|Description
a|Set this to specify the default parser (language version).
|Valid values
a|cypher.default_language_version is one of `2.3`, `3.1`, `3.4`, `3.5`, `default`
|Default value
m|default
|===

[[config_cypher.forbid_exhaustive_shortestpath]]
.cypher.forbid_exhaustive_shortestpath
[cols="<1h,<4"]
|===
|Description
a|This setting is associated with performance optimization. Set this to `true` in situations where it is preferable to have any queries using the 'shortestPath' function terminate as soon as possible with no answer, rather than potentially running for a long time attempting to find an answer (even if there is no path to be found). For most queries, the 'shortestPath' algorithm will return the correct answer very quickly. However there are some cases where it is possible that the fast bidirectional breadth-first search algorithm will find no results even if they exist. This can happen when the predicates in the `WHERE` clause applied to 'shortestPath' cannot be applied to each step of the traversal, and can only be applied to the entire path. When the query planner detects these special cases, it will plan to perform an exhaustive depth-first search if the fast algorithm finds no paths. However, the exhaustive search may be orders of magnitude slower than the fast algorithm. If it is critical that queries terminate as soon as possible, it is recommended that this option be set to `true`, which means that Neo4j will never consider using the exhaustive search for shortestPath queries. However, please note that if no paths are found, an error will be thrown at run time, which will need to be handled by the application.
|Valid values
a|cypher.forbid_exhaustive_shortestpath is a boolean
|Default value
m|false
|===

[[config_cypher.forbid_shortestpath_common_nodes]]
.cypher.forbid_shortestpath_common_nodes
[cols="<1h,<4"]
|===
|Description
a|This setting is associated with performance optimization. The shortest path algorithm does not work when the start and end nodes are the same. With this setting set to `false` no path will be returned when that happens. The default value of `true` will instead throw an exception. This can happen if you perform a shortestPath search after a cartesian product that might have the same start and end nodes for some of the rows passed to shortestPath. If it is preferable to not experience this exception, and acceptable for results to be missing for those rows, then set this to `false`. If you cannot accept missing results, and really want the shortestPath between two common nodes, then re-write the query using a standard Cypher variable length pattern expression followed by ordering by path length and limiting to one result.
|Valid values
a|cypher.forbid_shortestpath_common_nodes is a boolean
|Default value
m|true
|===

[[config_cypher.hints_error]]
.cypher.hints_error
[cols="<1h,<4"]
|===
|Description
a|Set this to specify the behavior when Cypher planner or runtime hints cannot be fulfilled. If true, then non-conformance will result in an error, otherwise only a warning is generated.
|Valid values
a|cypher.hints_error is a boolean
|Default value
m|false
|===

[[config_cypher.lenient_create_relationship]]
.cypher.lenient_create_relationship
[cols="<1h,<4"]
|===
|Description
a|Set this to change the behavior for Cypher create relationship when the start or end node is missing. By default this fails the query and stops execution, but by setting this flag the create operation is simply not performed and execution continues.
|Valid values
a|cypher.lenient_create_relationship is a boolean
|Default value
m|false
|===

[[config_cypher.min_replan_interval]]
.cypher.min_replan_interval
[cols="<1h,<4"]
|===
|Description
a|The minimum time between possible cypher query replanning events. After this time, the graph statistics will be evaluated, and if they have changed by more than the value set by <<config_cypher.statistics_divergence_threshold,cypher.statistics_divergence_threshold>>, the query will be replanned. If the statistics have not changed sufficiently, the same interval will need to pass before the statistics will be evaluated again. Each time they are evaluated, the divergence threshold will be reduced slightly until it reaches 10% after 7h, so that even moderately changing databases will see query replanning after a sufficiently long time interval.
|Valid values
a|cypher.min_replan_interval is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|10s
|===

[[config_cypher.planner]]
.cypher.planner
[cols="<1h,<4"]
|===
|Description
a|Set this to specify the default planner for the default language version.
|Valid values
a|cypher.planner is one of `COST`, `RULE`, `default`
|Default value
m|default
|===

[[config_cypher.statistics_divergence_threshold]]
.cypher.statistics_divergence_threshold
[cols="<1h,<4"]
|===
|Description
a|The threshold when a plan is considered stale. If any of the underlying statistics used to create the plan have changed more than this value, the plan will be considered stale and will be replanned. Change is calculated as abs(a-b)/max(a,b). This means that a value of 0.75 requires the database to approximately quadruple in size. A value of 0 means replan as soon as possible, with the soonest being defined by the <<config_cypher.min_replan_interval,cypher.min_replan_interval>> which defaults to 10s. After this interval the divergence threshold will slowly start to decline, reaching 10% after about 7h. This will ensure that long running databases will still get query replanning on even modest changes, while not replanning frequently unless the changes are very large.
|Valid values
a|cypher.statistics_divergence_threshold is a double which is in the range `0.0` to `1.0`
|Default value
m|0.75
|===

[[config_db.temporal.timezone]]
.db.temporal.timezone
[cols="<1h,<4"]
|===
|Description
a|Database timezone for temporal functions. All Time and DateTime values that are created without an explicit timezone will use this configured default timezone.
|Valid values
a|db.temporal.timezone is a string describing a timezone, either described by offset (e.g. '+02:00') or by name (e.g. 'Europe/Stockholm')
|Default value
m|Z
|===

[[config_dbms.active_database]]
.dbms.active_database
[cols="<1h,<4"]
|===
|Description
a|Name of the database to load.
|Valid values
a|dbms.active_database is a string which is not `system.db`
|Default value
m|graph.db
|Deprecated
a|The `dbms.active_database` configuration setting has been deprecated.
|===

[[config_dbms.allow_format_migration]]
.dbms.allow_format_migration
[cols="<1h,<4"]
|===
|Description
a|Whether to allow a store upgrade in case the current version of the database starts against an older store version. Setting this to `true` does not guarantee successful upgrade, it just allows an upgrade to be performed.
|Valid values
a|dbms.allow_format_migration is a boolean
|Default value
m|false
|Deprecated
a|The `dbms.allow_format_migration` configuration setting has been deprecated.
|Replaced by
a|<<config_dbms.allow_upgrade,dbms.allow_upgrade>>
|===

[[config_dbms.allow_upgrade]]
.dbms.allow_upgrade
[cols="<1h,<4"]
|===
|Description
a|Whether to allow an upgrade in case the current version of the database starts against an older version.
|Valid values
a|dbms.allow_upgrade is a boolean
|Default value
m|false
|===

[[config_dbms.backup.address]]
.dbms.backup.address
[cols="<1h,<4"]
|===
|Description
a|Listening server for online backups. The protocol running varies depending on deployment. In a Causal Clustering environment this is the same protocol that runs on <<config_causal_clustering.transaction_listen_address,causal_clustering.transaction_listen_address>>. The port range is only respected in a HA or single instance deployment. In Causal Clustering a single port should be used.
|Valid values
a|dbms.backup.address is a hostname and port
|Default value
m|127.0.0.1:6362-6372
|===

[[config_dbms.backup.enabled]]
.dbms.backup.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable support for running online backups.
|Valid values
a|dbms.backup.enabled is a boolean
|Default value
m|true
|===

[[config_dbms.backup.ssl_policy]]
.dbms.backup.ssl_policy
[cols="<1h,<4"]
|===
|Description
a|Name of the SSL policy to be used by backup, as defined under the dbms.ssl.policy.* settings. If no policy is configured then the communication will not be secured.
|Valid values
a|dbms.backup.ssl_policy is a string
|===

[[config_dbms.checkpoint]]
.dbms.checkpoint
[cols="<1h,<4"]
|===
|Description
a|Configures the general policy for when check-points should occur. The default policy is the 'periodic' check-point policy, as specified by the '<<config_dbms.checkpoint.interval.tx,dbms.checkpoint.interval.tx>>' and '<<config_dbms.checkpoint.interval.time,dbms.checkpoint.interval.time>>' settings. The Neo4j Enterprise Edition provides two alternative policies: The first is the 'continuous' check-point policy, which will ignore those settings and run the check-point process all the time. The second is the 'volumetric' check-point policy, which makes a best-effort at check-pointing often enough so that the database doesn't get too far behind on deleting old transaction logs in accordance with the '<<config_dbms.tx_log.rotation.retention_policy,dbms.tx_log.rotation.retention_policy>>' setting.
|Valid values
a|dbms.checkpoint is a string
|Default value
m|periodic
|===

[[config_dbms.checkpoint.interval.time]]
.dbms.checkpoint.interval.time
[cols="<1h,<4"]
|===
|Description
a|Configures the time interval between check-points. The database will not check-point more often than this (unless check pointing is triggered by a different event), but might check-point less often than this interval, if performing a check-point takes longer time than the configured interval. A check-point is a point in the transaction logs, from which recovery would start from. Longer check-point intervals typically means that recovery will take longer to complete in case of a crash. On the other hand, a longer check-point interval can also reduce the I/O load that the database places on the system, as each check-point implies a flushing and forcing of all the store files.
|Valid values
a|dbms.checkpoint.interval.time is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|900s
|===

[[config_dbms.checkpoint.interval.tx]]
.dbms.checkpoint.interval.tx
[cols="<1h,<4"]
|===
|Description
a|Configures the transaction interval between check-points. The database will not check-point more often  than this (unless check pointing is triggered by a different event), but might check-point less often than this interval, if performing a check-point takes longer time than the configured interval. A check-point is a point in the transaction logs, from which recovery would start from. Longer check-point intervals typically means that recovery will take longer to complete in case of a crash. On the other hand, a longer check-point interval can also reduce the I/O load that the database places on the system, as each check-point implies a flushing and forcing of all the store files.  The default is '100000' for a check-point every 100000 transactions.
|Valid values
a|dbms.checkpoint.interval.tx is an integer which is minimum `1`
|Default value
m|100000
|===

[[config_dbms.checkpoint.iops.limit]]
.dbms.checkpoint.iops.limit
[cols="<1h,<4"]
|===
|Description
a|Limit the number of IOs the background checkpoint process will consume per second. This setting is advisory, is ignored in Neo4j Community Edition, and is followed to best effort in Enterprise Edition. An IO is in this case a 8 KiB (mostly sequential) write. Limiting the write IO in this way will leave more bandwidth in the IO subsystem to service random-read IOs, which is important for the response time of queries when the database cannot fit entirely in memory. The only drawback of this setting is that longer checkpoint times may lead to slightly longer recovery times in case of a database or system crash. A lower number means lower IO pressure, and consequently longer checkpoint times. Set this to -1 to disable the IOPS limit and remove the limitation entirely; this will let the checkpointer flush data as fast as the hardware will go. Removing the setting, or commenting it out, will set the default value of 300.
|Valid values
a|dbms.checkpoint.iops.limit is an integer
|Dynamic a|true
|Default value
m|300
|===

[[config_dbms.config.strict_validation]]
.dbms.config.strict_validation
[cols="<1h,<4"]
|===
|Description
a|A strict configuration validation will prevent the database from starting up if unknown configuration options are specified in the neo4j settings namespace (such as dbms., ha., cypher., etc). This is currently false by default but will be true by default in 4.0.
|Valid values
a|dbms.config.strict_validation is a boolean
|Default value
m|false
|===

[[config_dbms.connector.bolt.advertised_address]]
.dbms.connector.bolt.advertised_address
[cols="<1h,<4"]
|===
|Description
a|Advertised address for this connector.
|Valid values
a|an advertised socket address
|Default value
m|localhost:7687
|===

[[config_dbms.connector.bolt.enabled]]
.dbms.connector.bolt.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable this connector.
|Valid values
a|dbms.connector.bolt.enabled is a boolean
|Default value
m|true
|===

[[config_dbms.connector.bolt.listen_address]]
.dbms.connector.bolt.listen_address
[cols="<1h,<4"]
|===
|Description
a|Address the connector should bind to.
|Valid values
a|a listen socket address
|Default value
m|127.0.0.1:7687
|===

[[config_dbms.connector.bolt.thread_pool_keep_alive]]
.dbms.connector.bolt.thread_pool_keep_alive
[cols="<1h,<4"]
|===
|Description
a|The maximum time an idle thread in the thread pool bound to this connector will wait for new tasks.
|Valid values
a|dbms.connector.bolt.thread_pool_keep_alive is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|300s
|===

[[config_dbms.connector.bolt.thread_pool_max_size]]
.dbms.connector.bolt.thread_pool_max_size
[cols="<1h,<4"]
|===
|Description
a|The maximum number of threads allowed in the thread pool bound to this connector.
|Valid values
a|dbms.connector.bolt.thread_pool_max_size is an integer
|Default value
m|400
|===

[[config_dbms.connector.bolt.thread_pool_min_size]]
.dbms.connector.bolt.thread_pool_min_size
[cols="<1h,<4"]
|===
|Description
a|The number of threads to keep in the thread pool bound to this connector, even if they are idle.
|Valid values
a|dbms.connector.bolt.thread_pool_min_size is an integer
|Default value
m|5
|===

[[config_dbms.connector.bolt.tls_level]]
.dbms.connector.bolt.tls_level
[cols="<1h,<4"]
|===
|Description
a|Encryption level to require this connector to use.
|Valid values
a|dbms.connector.bolt.tls_level is one of `REQUIRED`, `OPTIONAL`, `DISABLED`
|Default value
m|OPTIONAL
|===

[[config_dbms.connector.http.advertised_address]]
.dbms.connector.http.advertised_address
[cols="<1h,<4"]
|===
|Description
a|Advertised address for this connector.
|Valid values
a|an advertised socket address
|Default value
m|localhost:7474
|===

[[config_dbms.connector.http.enabled]]
.dbms.connector.http.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable this connector.
|Valid values
a|dbms.connector.http.enabled is a boolean
|Default value
m|true
|===

[[config_dbms.connector.http.listen_address]]
.dbms.connector.http.listen_address
[cols="<1h,<4"]
|===
|Description
a|Address the connector should bind to.
|Valid values
a|a listen socket address
|Default value
m|127.0.0.1:7474
|===

[[config_dbms.connector.https.advertised_address]]
.dbms.connector.https.advertised_address
[cols="<1h,<4"]
|===
|Description
a|Advertised address for this connector.
|Valid values
a|an advertised socket address
|Default value
m|localhost:7473
|===

[[config_dbms.connector.https.enabled]]
.dbms.connector.https.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable this connector.
|Valid values
a|dbms.connector.https.enabled is a boolean
|Default value
m|true
|===

[[config_dbms.connector.https.listen_address]]
.dbms.connector.https.listen_address
[cols="<1h,<4"]
|===
|Description
a|Address the connector should bind to.
|Valid values
a|a listen socket address
|Default value
m|127.0.0.1:7473
|===

[[config_dbms.connectors.default_advertised_address]]
.dbms.connectors.default_advertised_address
[cols="<1h,<4"]
|===
|Description
a|Default hostname or IP address the server uses to advertise itself to its connectors. To advertise a specific hostname or IP address for a specific connector, specify the advertised_address property for the specific connector.
|Valid values
a|dbms.connectors.default_advertised_address is a string
|Default value
m|localhost
|===

[[config_dbms.connectors.default_listen_address]]
.dbms.connectors.default_listen_address
[cols="<1h,<4"]
|===
|Description
a|Default network interface to listen for incoming connections. To listen for connections on all interfaces, use "0.0.0.0". To bind specific connectors to a specific network interfaces, specify the listen_address properties for the specific connector.
|Valid values
a|dbms.connectors.default_listen_address is a string
|Default value
m|127.0.0.1
|===

[[config_dbms.db.timezone]]
.dbms.db.timezone
[cols="<1h,<4"]
|===
|Description
a|Database timezone. Among other things, this setting influences which timezone the logs and monitoring procedures use.
|Valid values
a|dbms.db.timezone is one of `UTC`, `SYSTEM`
|Default value
m|UTC
|===

[[config_dbms.directories.certificates]]
.dbms.directories.certificates
[cols="<1h,<4"]
|===
|Description
a|Directory for storing certificates to be used by Neo4j for TLS connections.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|certificates
|===

[[config_dbms.directories.data]]
.dbms.directories.data
[cols="<1h,<4"]
|===
|Description
a|Path of the data directory. You must not configure more than one Neo4j installation to use the same data directory.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|data
|===

[[config_dbms.directories.import]]
.dbms.directories.import
[cols="<1h,<4"]
|===
|Description
a|Sets the root directory for file URLs used with the Cypher `LOAD CSV` clause. This should be set to a directory relative to the Neo4j installation path, restricting access to only those files within that directory and its subdirectories. For example the value "import" will only enable access to files within the 'import' folder. Removing this setting will disable the security feature, allowing all files in the local system to be imported. Setting this to an empty field will allow access to all files within the Neo4j installation folder.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|===

[[config_dbms.directories.lib]]
.dbms.directories.lib
[cols="<1h,<4"]
|===
|Description
a|Path of the lib directory.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|lib
|===

[[config_dbms.directories.logs]]
.dbms.directories.logs
[cols="<1h,<4"]
|===
|Description
a|Path of the logs directory.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|logs
|===

[[config_dbms.directories.metrics]]
.dbms.directories.metrics
[cols="<1h,<4"]
|===
|Description
a|The target location of the CSV files: a path to a directory wherein a CSV file per reported field  will be written.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|metrics
|===

[[config_dbms.directories.plugins]]
.dbms.directories.plugins
[cols="<1h,<4"]
|===
|Description
a|Location of the database plugin directory. Compiled Java JAR files that contain database procedures will be loaded if they are placed in this directory.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|plugins
|===

[[config_dbms.directories.run]]
.dbms.directories.run
[cols="<1h,<4"]
|===
|Description
a|Path of the run directory. This directory holds Neo4j's runtime state, such as a pidfile when it is running in the background. The pidfile is created when starting neo4j and removed when stopping it. It may be placed on an in-memory filesystem such as tmpfs.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|run
|===

[[config_dbms.directories.tx_log]]
.dbms.directories.tx_log
[cols="<1h,<4"]
|===
|Description
a|Location where Neo4j keeps the logical transaction logs.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.database>_
|Default value
m|data/databases/graph.db
|===

[[config_dbms.filewatcher.enabled]]
.dbms.filewatcher.enabled
[cols="<1h,<4"]
|===
|Description
a|Allows the enabling or disabling of the file watcher service. This is an auxiliary service but should be left enabled in almost all cases.
|Valid values
a|dbms.filewatcher.enabled is a boolean
|Default value
m|true
|===

[[config_dbms.ids.reuse.types.override]]
.dbms.ids.reuse.types.override
[cols="<1h,<4"]
|===
|Description
a|Specified names of id types (comma separated) that should be reused. Currently only 'node' and 'relationship' types are supported. This feature is available in the Neo4j Enterprise Edition.
|Valid values
a|dbms.ids.reuse.types.override is a list separated by "," where items are one of `NODE`, `RELATIONSHIP`
|Default value
m|[RELATIONSHIP, NODE]
|===

[[config_dbms.import.csv.buffer_size]]
.dbms.import.csv.buffer_size
[cols="<1h,<4"]
|===
|Description
a|The size of the internal buffer in bytes used by `LOAD CSV`. If the csv file contains huge fields this value may have to be increased.
|Valid values
a|dbms.import.csv.buffer_size is an integer which is minimum `1`
|Default value
m|2097152
|===

[[config_dbms.import.csv.legacy_quote_escaping]]
.dbms.import.csv.legacy_quote_escaping
[cols="<1h,<4"]
|===
|Description
a|Selects whether to conform to the standard https://tools.ietf.org/html/rfc4180 for interpreting escaped quotation characters in CSV files loaded using `LOAD CSV`. Setting this to `false` will use the standard, interpreting repeated quotes '""' as a single in-lined quote, while `true` will use the legacy convention originally supported in Neo4j 3.0 and 3.1, allowing a backslash to include quotes in-lined in fields.
|Valid values
a|dbms.import.csv.legacy_quote_escaping is a boolean
|Default value
m|true
|===

[[config_dbms.index.default_schema_provider]]
.dbms.index.default_schema_provider
[cols="<1h,<4"]
|===
|Description
a|Index provider to use for newly created schema indexes. An index provider may store different value types in separate physical indexes. lucene-1.0: Spatial and temporal value types are stored in native indexes, remaining value types in Lucene index. lucene+native-1.0: Spatial, temporal and number value types are stored in native indexes and remaining value types in Lucene index. lucene+native-2.0: Spatial, temporal, number and string value types are stored in native indexes and remaining value types in Lucene index. native-btree-1.0: All value types and arrays of all value types, even composite keys, are stored in one native index. A native index has faster updates, less heap and CPU usage compared to a Lucene index. A native index has these limitations: Index key (be it single or composite) size limit of 4039 bytes - transaction resulting in index key surpassing that will fail. Reduced performance of CONTAINS and ENDS WITH string index queries, compared to a Lucene index.
|Valid values
a|dbms.index.default_schema_provider is a string
|Default value
m|native-btree-1.0
|===

[[config_dbms.index.fulltext.default_analyzer]]
.dbms.index.fulltext.default_analyzer
[cols="<1h,<4"]
|===
|Description
a|The name of the analyzer that the fulltext indexes should use by default.
|Valid values
a|dbms.index.fulltext.default_analyzer is a string
|Default value
m|standard
|===

[[config_dbms.index.fulltext.eventually_consistent]]
.dbms.index.fulltext.eventually_consistent
[cols="<1h,<4"]
|===
|Description
a|Whether or not fulltext indexes should be eventually consistent by default or not.
|Valid values
a|dbms.index.fulltext.eventually_consistent is a boolean
|Default value
m|false
|===

[[config_dbms.index.fulltext.eventually_consistent_index_update_queue_max_length]]
.dbms.index.fulltext.eventually_consistent_index_update_queue_max_length
[cols="<1h,<4"]
|===
|Description
a|The eventually_consistent mode of the fulltext indexes works by queueing up index updates to be applied later in a background thread. This setting sets an upper bound on how many index updates are allowed to be in this queue at any one point in time. When it is reached, the commit process will slow down and wait for the index update applier thread to make some more room in the queue.
|Valid values
a|dbms.index.fulltext.eventually_consistent_index_update_queue_max_length is an integer which is minimum `1`, and is maximum `50000000`
|Default value
m|10000
|===

[[config_dbms.index_sampling.background_enabled]]
.dbms.index_sampling.background_enabled
[cols="<1h,<4"]
|===
|Description
a|Enable or disable background index sampling.
|Valid values
a|dbms.index_sampling.background_enabled is a boolean
|Default value
m|true
|===

[[config_dbms.index_sampling.buffer_size]]
.dbms.index_sampling.buffer_size
[cols="<1h,<4"]
|===
|Description
a|Size of buffer used by index sampling. This configuration setting is no longer applicable as from Neo4j 3.0.3. Please use <<config_dbms.index_sampling.sample_size_limit,dbms.index_sampling.sample_size_limit>> instead.
|Valid values
a|dbms.index_sampling.buffer_size is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`) which is in the range `1048576` to `2147483647`
|Default value
m|67108864
|Deprecated
a|The `dbms.index_sampling.buffer_size` configuration setting has been deprecated.
|Replaced by
a|<<config_dbms.index_sampling.sample_size_limit,dbms.index_sampling.sample_size_limit>>
|===

[[config_dbms.index_sampling.sample_size_limit]]
.dbms.index_sampling.sample_size_limit
[cols="<1h,<4"]
|===
|Description
a|Index sampling chunk size limit.
|Valid values
a|dbms.index_sampling.sample_size_limit is an integer which is in the range `1048576` to `2147483647`
|Default value
m|8388608
|===

[[config_dbms.index_sampling.update_percentage]]
.dbms.index_sampling.update_percentage
[cols="<1h,<4"]
|===
|Description
a|Percentage of index updates of total index size required before sampling of a given index is triggered.
|Valid values
a|dbms.index_sampling.update_percentage is an integer which is minimum `0`
|Default value
m|5
|===

[[config_dbms.index_searcher_cache_size]]
.dbms.index_searcher_cache_size
[cols="<1h,<4"]
|===
|Description
a|The maximum number of open Lucene index searchers.
|Valid values
a|dbms.index_searcher_cache_size is an integer which is minimum `1`
|Default value
m|2147483647
|===

[[config_dbms.jvm.additional]]
.dbms.jvm.additional
[cols="<1h,<4"]
|===
|Description
a|Additional JVM arguments. Argument order can be significant. To use a Java commercial feature, the argument to unlock commercial features must precede the argument to enable the specific feature in the config value string. For example, to use Flight Recorder, `-XX:+UnlockCommercialFeatures` must come before `-XX:+FlightRecorder`.
|Valid values
a|a string
|===

[[config_dbms.lock.acquisition.timeout]]
.dbms.lock.acquisition.timeout
[cols="<1h,<4"]
|===
|Description
a|The maximum time interval within which lock should be acquired.
|Valid values
a|dbms.lock.acquisition.timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|0s
|===

[[config_dbms.logs.debug.level]]
.dbms.logs.debug.level
[cols="<1h,<4"]
|===
|Description
a|Debug log level threshold.
|Valid values
a|dbms.logs.debug.level is one of `DEBUG`, `INFO`, `WARN`, `ERROR`, `NONE`
|Default value
m|INFO
|===

[[config_dbms.logs.debug.path]]
.dbms.logs.debug.path
[cols="<1h,<4"]
|===
|Description
a|Path to the debug log file.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|logs/debug.log
|===

[[config_dbms.logs.debug.rotation.delay]]
.dbms.logs.debug.rotation.delay
[cols="<1h,<4"]
|===
|Description
a|Minimum time interval after last rotation of the debug log before it may be rotated again.
|Valid values
a|dbms.logs.debug.rotation.delay is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|300s
|===

[[config_dbms.logs.debug.rotation.keep_number]]
.dbms.logs.debug.rotation.keep_number
[cols="<1h,<4"]
|===
|Description
a|Maximum number of history files for the debug log.
|Valid values
a|dbms.logs.debug.rotation.keep_number is an integer which is minimum `1`
|Default value
m|7
|===

[[config_dbms.logs.debug.rotation.size]]
.dbms.logs.debug.rotation.size
[cols="<1h,<4"]
|===
|Description
a|Threshold for rotation of the debug log.
|Valid values
a|dbms.logs.debug.rotation.size is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`) which is in the range `0` to `9223372036854775807`
|Default value
m|20971520
|===

[[config_dbms.logs.gc.enabled]]
.dbms.logs.gc.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable GC Logging.
|Valid values
a|dbms.logs.gc.enabled is a boolean
|Default value
m|false
|===

[[config_dbms.logs.gc.options]]
.dbms.logs.gc.options
[cols="<1h,<4"]
|===
|Description
a|GC Logging Options.
|Valid values
a|dbms.logs.gc.options is a string
|Default value
m|-XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintPromotionFailure -XX:+PrintTenuringDistribution
|===

[[config_dbms.logs.gc.rotation.keep_number]]
.dbms.logs.gc.rotation.keep_number
[cols="<1h,<4"]
|===
|Description
a|Number of GC logs to keep.
|Valid values
a|dbms.logs.gc.rotation.keep_number is an integer
|Default value
m|5
|===

[[config_dbms.logs.gc.rotation.size]]
.dbms.logs.gc.rotation.size
[cols="<1h,<4"]
|===
|Description
a|Size of each GC log that is kept.
|Valid values
a|dbms.logs.gc.rotation.size is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`) which is in the range `0` to `9223372036854775807`
|Default value
m|20971520
|===

[[config_dbms.logs.http.enabled]]
.dbms.logs.http.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable HTTP request logging.
|Valid values
a|dbms.logs.http.enabled is a boolean
|Default value
m|false
|===

[[config_dbms.logs.http.path]]
.dbms.logs.http.path
[cols="<1h,<4"]
|===
|Description
a|Path to HTTP request log.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|logs/http.log
|===

[[config_dbms.logs.http.rotation.keep_number]]
.dbms.logs.http.rotation.keep_number
[cols="<1h,<4"]
|===
|Description
a|Number of HTTP logs to keep.
|Valid values
a|dbms.logs.http.rotation.keep_number is an integer
|Default value
m|5
|===

[[config_dbms.logs.http.rotation.size]]
.dbms.logs.http.rotation.size
[cols="<1h,<4"]
|===
|Description
a|Size of each HTTP log that is kept.
|Valid values
a|dbms.logs.http.rotation.size is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`) which is in the range `0` to `9223372036854775807`
|Default value
m|20971520
|===

[[config_dbms.logs.query.allocation_logging_enabled]]
.dbms.logs.query.allocation_logging_enabled
[cols="<1h,<4"]
|===
|Description
a|Log allocated bytes for the executed queries being logged. The logged number is cumulative over the duration of the query, i.e. for memory intense or long-running queries the value may be larger than the current memory allocation. Requires `<<config_dbms.track_query_allocation,dbms.track_query_allocation>>=true`
|Valid values
a|dbms.logs.query.allocation_logging_enabled is a boolean
|Dynamic a|true
|Default value
m|false
|===

[[config_dbms.logs.query.enabled]]
.dbms.logs.query.enabled
[cols="<1h,<4"]
|===
|Description
a|Log executed queries that take longer than the configured threshold, <<config_dbms.logs.query.threshold,dbms.logs.query.threshold>>. Log entries are by default written to the file __query.log__ located in the Logs directory. For location of the Logs directory, see <<file-locations>>. This feature is available in the Neo4j Enterprise Edition.
|Valid values
a|dbms.logs.query.enabled is a boolean
|Dynamic a|true
|Default value
m|false
|===

[[config_dbms.logs.query.page_logging_enabled]]
.dbms.logs.query.page_logging_enabled
[cols="<1h,<4"]
|===
|Description
a|Log page hits and page faults for the executed queries being logged.
|Valid values
a|dbms.logs.query.page_logging_enabled is a boolean
|Dynamic a|true
|Default value
m|false
|===

[[config_dbms.logs.query.parameter_logging_enabled]]
.dbms.logs.query.parameter_logging_enabled
[cols="<1h,<4"]
|===
|Description
a|Log parameters for the executed queries being logged.
|Valid values
a|dbms.logs.query.parameter_logging_enabled is a boolean
|Dynamic a|true
|Default value
m|true
|===

[[config_dbms.logs.query.path]]
.dbms.logs.query.path
[cols="<1h,<4"]
|===
|Description
a|Path to the query log file.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|logs/query.log
|===

[[config_dbms.logs.query.rotation.keep_number]]
.dbms.logs.query.rotation.keep_number
[cols="<1h,<4"]
|===
|Description
a|Maximum number of history files for the query log.
|Valid values
a|dbms.logs.query.rotation.keep_number is an integer which is minimum `1`
|Dynamic a|true
|Default value
m|7
|===

[[config_dbms.logs.query.rotation.size]]
.dbms.logs.query.rotation.size
[cols="<1h,<4"]
|===
|Description
a|The file size in bytes at which the query log will auto-rotate. If set to zero then no rotation will occur. Accepts a binary suffix `k`, `m` or `g`.
|Valid values
a|dbms.logs.query.rotation.size is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`) which is in the range `0` to `9223372036854775807`
|Dynamic a|true
|Default value
m|20971520
|===

[[config_dbms.logs.query.runtime_logging_enabled]]
.dbms.logs.query.runtime_logging_enabled
[cols="<1h,<4"]
|===
|Description
a|Logs which runtime that was used to run the query.
|Valid values
a|dbms.logs.query.runtime_logging_enabled is a boolean
|Dynamic a|true
|Default value
m|false
|===

[[config_dbms.logs.query.threshold]]
.dbms.logs.query.threshold
[cols="<1h,<4"]
|===
|Description
a|If the execution of query takes more time than this threshold, the query is logged - provided query logging is enabled. Defaults to 0 seconds, that is all queries are logged.
|Valid values
a|dbms.logs.query.threshold is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Dynamic a|true
|Default value
m|0s
|===

[[config_dbms.logs.query.time_logging_enabled]]
.dbms.logs.query.time_logging_enabled
[cols="<1h,<4"]
|===
|Description
a|Log detailed time information for the executed queries being logged. Requires `<<config_dbms.track_query_cpu_time,dbms.track_query_cpu_time>>=true`
|Valid values
a|dbms.logs.query.time_logging_enabled is a boolean
|Dynamic a|true
|Default value
m|false
|===

[[config_dbms.logs.security.level]]
.dbms.logs.security.level
[cols="<1h,<4"]
|===
|Description
a|Security log level threshold.
|Valid values
a|dbms.logs.security.level is one of `DEBUG`, `INFO`, `WARN`, `ERROR`, `NONE`
|Default value
m|INFO
|===

[[config_dbms.logs.security.path]]
.dbms.logs.security.path
[cols="<1h,<4"]
|===
|Description
a|Path to the security log file.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|logs/security.log
|===

[[config_dbms.logs.security.rotation.delay]]
.dbms.logs.security.rotation.delay
[cols="<1h,<4"]
|===
|Description
a|Minimum time interval after last rotation of the security log before it may be rotated again.
|Valid values
a|dbms.logs.security.rotation.delay is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|300s
|===

[[config_dbms.logs.security.rotation.keep_number]]
.dbms.logs.security.rotation.keep_number
[cols="<1h,<4"]
|===
|Description
a|Maximum number of history files for the security log.
|Valid values
a|dbms.logs.security.rotation.keep_number is an integer which is minimum `1`
|Default value
m|7
|===

[[config_dbms.logs.security.rotation.size]]
.dbms.logs.security.rotation.size
[cols="<1h,<4"]
|===
|Description
a|Threshold for rotation of the security log.
|Valid values
a|dbms.logs.security.rotation.size is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`) which is in the range `0` to `9223372036854775807`
|Default value
m|20971520
|===

[[config_dbms.logs.timezone]]
.dbms.logs.timezone
[cols="<1h,<4"]
|===
|Description
a|Database logs timezone.
|Valid values
a|dbms.logs.timezone is one of `UTC`, `SYSTEM`
|Default value
m|UTC
|Deprecated
a|The `dbms.logs.timezone` configuration setting has been deprecated.
|Replaced by
a|<<config_dbms.db.timezone,dbms.db.timezone>>
|===

[[config_dbms.logs.user.path]]
.dbms.logs.user.path
[cols="<1h,<4"]
|===
|Description
a|Path to the user log file. Note that if <<config_dbms.logs.user.stdout_enabled,dbms.logs.user.stdout_enabled>> is enabled this setting will be ignored.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|logs/neo4j.log
|===

[[config_dbms.logs.user.rotation.delay]]
.dbms.logs.user.rotation.delay
[cols="<1h,<4"]
|===
|Description
a|Minimum time interval after last rotation of the user log before it may be rotated again. Note that if <<config_dbms.logs.user.stdout_enabled,dbms.logs.user.stdout_enabled>> is enabled this setting will be ignored.
|Valid values
a|dbms.logs.user.rotation.delay is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|300s
|===

[[config_dbms.logs.user.rotation.keep_number]]
.dbms.logs.user.rotation.keep_number
[cols="<1h,<4"]
|===
|Description
a|Maximum number of history files for the user log. Note that if <<config_dbms.logs.user.stdout_enabled,dbms.logs.user.stdout_enabled>> is enabled this setting will be ignored.
|Valid values
a|dbms.logs.user.rotation.keep_number is an integer which is minimum `1`
|Default value
m|7
|===

[[config_dbms.logs.user.rotation.size]]
.dbms.logs.user.rotation.size
[cols="<1h,<4"]
|===
|Description
a|Threshold for rotation of the user log. If set to 0 log rotation is disabled. Note that if <<config_dbms.logs.user.stdout_enabled,dbms.logs.user.stdout_enabled>> is enabled this setting will be ignored.
|Valid values
a|dbms.logs.user.rotation.size is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`) which is in the range `0` to `9223372036854775807`
|Default value
m|0
|===

[[config_dbms.logs.user.stdout_enabled]]
.dbms.logs.user.stdout_enabled
[cols="<1h,<4"]
|===
|Description
a|Send user logs to the process stdout. If this is disabled then logs will instead be sent to the file __neo4j.log__ located in the logs directory. For location of the Logs directory, see <<file-locations>>.
|Valid values
a|dbms.logs.user.stdout_enabled is a boolean
|Default value
m|true
|===

[[config_dbms.memory.heap.initial_size]]
.dbms.memory.heap.initial_size
[cols="<1h,<4"]
|===
|Description
a|Initial heap size. By default it is calculated based on available system resources.
|Valid values
a|a byte size (valid units are `k`, `K`, `m`, `M`, `g`, `G`)
|===

[[config_dbms.memory.heap.max_size]]
.dbms.memory.heap.max_size
[cols="<1h,<4"]
|===
|Description
a|Maximum heap size. By default it is calculated based on available system resources.
|Valid values
a|a byte size (valid units are `k`, `K`, `m`, `M`, `g`, `G`)
|===

[[config_dbms.memory.pagecache.size]]
.dbms.memory.pagecache.size
[cols="<1h,<4"]
|===
|Description
a|The amount of memory to use for mapping the store files, in bytes (or kilobytes with the 'k' suffix, megabytes with 'm' and gigabytes with 'g'). If Neo4j is running on a dedicated server, then it is generally recommended to leave about 2-4 gigabytes for the operating system, give the JVM enough heap to hold all your transaction state and query context, and then leave the rest for the page cache. If no page cache memory is configured, then a heuristic setting is computed based on available system resources.
|Valid values
a|dbms.memory.pagecache.size is a string
|===

[[config_dbms.memory.pagecache.swapper]]
.dbms.memory.pagecache.swapper
[cols="<1h,<4"]
|===
|Description
a|Specify which page swapper to use for doing paged IO. This is only used when integrating with proprietary storage technology.
|Valid values
a|dbms.memory.pagecache.swapper is a string
|===

[[config_dbms.mode]]
.dbms.mode
[cols="<1h,<4"]
|===
|Description
a|Configure the operating mode of the database -- 'SINGLE' for stand-alone operation, 'HA' for operating as a member in an HA cluster, 'ARBITER' for a cluster member with no database in an HA cluster, 'CORE' for operating as a core member of a Causal Cluster, or 'READ_REPLICA' for operating as a read replica member of a Causal Cluster.
|Valid values
a|dbms.mode is one of `SINGLE`, `HA`, `ARBITER`, `CORE`, `READ_REPLICA`
|Default value
m|SINGLE
|===

[[config_dbms.netty.ssl.provider]]
.dbms.netty.ssl.provider
[cols="<1h,<4"]
|===
|Description
a|Netty SSL provider.
|Valid values
a|dbms.netty.ssl.provider is one of `JDK`, `OPENSSL`, `OPENSSL_REFCNT`
|Default value
m|JDK
|===

[[config_dbms.procedures.kill_query_verbose]]
.dbms.procedures.kill_query_verbose
[cols="<1h,<4"]
|===
|Description
a|Specifies whether or not dbms.killQueries produces a verbose output, with information about which queries were not found.
|Valid values
a|dbms.procedures.kill_query_verbose is a boolean
|Default value
m|true
|===

[[config_dbms.query_cache_size]]
.dbms.query_cache_size
[cols="<1h,<4"]
|===
|Description
a|The number of Cypher query execution plans that are cached.
|Valid values
a|dbms.query_cache_size is an integer which is minimum `0`
|Default value
m|1000
|===

[[config_dbms.read_only]]
.dbms.read_only
[cols="<1h,<4"]
|===
|Description
a|Only allow read operations from this Neo4j instance. This mode still requires write access to the directory for lock purposes.
|Valid values
a|dbms.read_only is a boolean
|Default value
m|false
|===

[[config_dbms.record_format]]
.dbms.record_format
[cols="<1h,<4"]
|===
|Description
a|Database record format. Valid values: `standard`, `high_limit`. The `high_limit` format is available for Enterprise Edition only. It is required if you have a graph that is larger than 34 billion nodes, 34 billion relationships, or 68 billion properties. A change of the record format is irreversible. Certain operations may suffer from a performance penalty of up to 10%, which is why this format is not switched on by default.
|Valid values
a|dbms.record_format is a string
|Default value
m|
|===

[[config_dbms.relationship_grouping_threshold]]
.dbms.relationship_grouping_threshold
[cols="<1h,<4"]
|===
|Description
a|Relationship count threshold for considering a node to be dense.
|Valid values
a|dbms.relationship_grouping_threshold is an integer which is minimum `1`
|Default value
m|50
|===

[[config_dbms.rest.transaction.idle_timeout]]
.dbms.rest.transaction.idle_timeout
[cols="<1h,<4"]
|===
|Description
a|Timeout for idle transactions in the REST endpoint.
|Valid values
a|dbms.rest.transaction.idle_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|60s
|===

[[config_dbms.security.allow_csv_import_from_file_urls]]
.dbms.security.allow_csv_import_from_file_urls
[cols="<1h,<4"]
|===
|Description
a|Determines if Cypher will allow using file URLs when loading data using `LOAD CSV`. Setting this value to `false` will cause Neo4j to fail `LOAD CSV` clauses that load data from the file system.
|Valid values
a|dbms.security.allow_csv_import_from_file_urls is a boolean
|Default value
m|true
|===

[[config_dbms.security.auth_cache_max_capacity]]
.dbms.security.auth_cache_max_capacity
[cols="<1h,<4"]
|===
|Description
a|The maximum capacity for authentication and authorization caches (respectively).
|Valid values
a|dbms.security.auth_cache_max_capacity is an integer
|Default value
m|10000
|===

[[config_dbms.security.auth_cache_ttl]]
.dbms.security.auth_cache_ttl
[cols="<1h,<4"]
|===
|Description
a|The time to live (TTL) for cached authentication and authorization info when using external auth providers (LDAP or plugin). Setting the TTL to 0 will disable auth caching. Disabling caching while using the LDAP auth provider requires the use of an LDAP system account for resolving authorization information.
|Valid values
a|dbms.security.auth_cache_ttl is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|600s
|===

[[config_dbms.security.auth_cache_use_ttl]]
.dbms.security.auth_cache_use_ttl
[cols="<1h,<4"]
|===
|Description
a|Enable time-based eviction of the authentication and authorization info cache for external auth providers (LDAP or plugin). Disabling this setting will make the cache live forever and only be evicted when `<<config_dbms.security.auth_cache_max_capacity,dbms.security.auth_cache_max_capacity>>` is exceeded.
|Valid values
a|dbms.security.auth_cache_use_ttl is a boolean
|Default value
m|true
|===

[[config_dbms.security.auth_enabled]]
.dbms.security.auth_enabled
[cols="<1h,<4"]
|===
|Description
a|Enable auth requirement to access Neo4j.
|Valid values
a|dbms.security.auth_enabled is a boolean
|Default value
m|true
|===

[[config_dbms.security.auth_lock_time]]
.dbms.security.auth_lock_time
[cols="<1h,<4"]
|===
|Description
a|The amount of time user account should be locked after a configured number of unsuccessful authentication attempts. The locked out user will not be able to log in until the lock period expires, even if correct credentials are provided. Setting this configuration option to a low value is not recommended because it might make it easier for an attacker to brute force the password.
|Valid values
a|dbms.security.auth_lock_time is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's') which is minimum `PT0S`
|Default value
m|5s
|===

[[config_dbms.security.auth_max_failed_attempts]]
.dbms.security.auth_max_failed_attempts
[cols="<1h,<4"]
|===
|Description
a|The maximum number of unsuccessful authentication attempts before imposing a user lock for the configured amount of time.The locked out user will not be able to log in until the lock period expires, even if correct credentials are provided. Setting this configuration option to values less than 3 is not recommended because it might make it easier for an attacker to brute force the password.
|Valid values
a|dbms.security.auth_max_failed_attempts is an integer which is minimum `0`
|Default value
m|3
|===

[[config_dbms.security.auth_provider]]
.dbms.security.auth_provider
[cols="<1h,<4"]
|===
|Description
a|The authentication and authorization provider that contains both the users and roles. This can be one of the built-in `native` or `ldap` providers, or it can be an externally provided plugin, with a custom name prefixed by `plugin-`, i.e. `plugin-<AUTH_PROVIDER_NAME>`. 
|Valid values
a|dbms.security.auth_provider is a string
|Default value
m|native
|===

[[config_dbms.security.causal_clustering_status_auth_enabled]]
.dbms.security.causal_clustering_status_auth_enabled
[cols="<1h,<4"]
|===
|Description
a|Require authorization for access to the Causal Clustering status endpoints.
|Valid values
a|dbms.security.causal_clustering_status_auth_enabled is a boolean
|Default value
m|true
|===

[[config_dbms.security.ha_status_auth_enabled]]
.dbms.security.ha_status_auth_enabled
[cols="<1h,<4"]
|===
|Description
a|Require authorization for access to the HA status endpoints.
|Valid values
a|dbms.security.ha_status_auth_enabled is a boolean
|Default value
m|true
|Deprecated
a|The `dbms.security.ha_status_auth_enabled` configuration setting has been deprecated.
|===

[[config_dbms.security.http_access_control_allow_origin]]
.dbms.security.http_access_control_allow_origin
[cols="<1h,<4"]
|===
|Description
a|Value of the Access-Control-Allow-Origin header sent over any HTTP or HTTPS connector. This defaults to '*', which allows broadest compatibility. Note that any URI provided here limits HTTP/HTTPS access to that URI only.
|Valid values
a|dbms.security.http_access_control_allow_origin is a string
|Default value
m|*
|===

[[config_dbms.security.http_authorization_classes]]
.dbms.security.http_authorization_classes
[cols="<1h,<4"]
|===
|Description
a|Comma-separated list of custom security rules for Neo4j to use.
|Valid values
a|dbms.security.http_authorization_classes is a list separated by "," where items are a string
|Default value
m|[]
|===

[[config_dbms.security.http_strict_transport_security]]
.dbms.security.http_strict_transport_security
[cols="<1h,<4"]
|===
|Description
a|Value of the HTTP Strict-Transport-Security (HSTS) response header. This header tells browsers that a webpage should only be accessed using HTTPS instead of HTTP. It is attached to every HTTPS response. Setting is not set by default so 'Strict-Transport-Security' header is not sent. Value is expected to contain directives like 'max-age', 'includeSubDomains' and 'preload'.
|Valid values
a|dbms.security.http_strict_transport_security is a string
|===

[[config_dbms.security.ldap.authentication.cache_enabled]]
.dbms.security.ldap.authentication.cache_enabled
[cols="<1h,<4"]
|===
|Description
a|Determines if the result of authentication via the LDAP server should be cached or not. Caching is used to limit the number of LDAP requests that have to be made over the network for users that have already been authenticated successfully. A user can be authenticated against an existing cache entry (instead of via an LDAP server) as long as it is alive (see `<<config_dbms.security.auth_cache_ttl,dbms.security.auth_cache_ttl>>`).
An important consequence of setting this to `true` is that Neo4j then needs to cache a hashed version of the credentials in order to perform credentials matching. This hashing is done using a cryptographic hash function together with a random salt. Preferably a conscious decision should be made if this method is considered acceptable by the security standards of the organization in which this Neo4j instance is deployed.
|Valid values
a|dbms.security.ldap.authentication.cache_enabled is a boolean
|Default value
m|true
|===

[[config_dbms.security.ldap.authentication.mechanism]]
.dbms.security.ldap.authentication.mechanism
[cols="<1h,<4"]
|===
|Description
a|LDAP authentication mechanism. This is one of `simple` or a SASL mechanism supported by JNDI, for example `DIGEST-MD5`. `simple` is basic username and password authentication and SASL is used for more advanced mechanisms. See RFC 2251 LDAPv3 documentation for more details.
|Valid values
a|dbms.security.ldap.authentication.mechanism is a string
|Default value
m|simple
|===

[[config_dbms.security.ldap.authentication.use_samaccountname]]
.dbms.security.ldap.authentication.use_samaccountname
[cols="<1h,<4"]
|===
|Description
a|Perform authentication with sAMAccountName instead of DN.
Using this setting requires `<<config_dbms.security.ldap.authorization.system_username,dbms.security.ldap.authorization.system_username>>` and <<config_dbms.security.ldap.authorization.system_password,dbms.security.ldap.authorization.system_password>> to be used since there is no way to log in through ldap directly with the sAMAccountName, instead the login name will be resolved to a DN that will be used to log in with.
|Valid values
a|dbms.security.ldap.authentication.use_samaccountname is a boolean
|Default value
m|false
|===

[[config_dbms.security.ldap.authentication.user_dn_template]]
.dbms.security.ldap.authentication.user_dn_template
[cols="<1h,<4"]
|===
|Description
a|LDAP user DN template. An LDAP object is referenced by its distinguished name (DN), and a user DN is an LDAP fully-qualified unique user identifier. This setting is used to generate an LDAP DN that conforms with the LDAP directory's schema from the user principal that is submitted with the authentication token when logging in. The special token {0} is a placeholder where the user principal will be substituted into the DN string.
|Valid values
a|dbms.security.ldap.authentication.user_dn_template is a string
|Default value
m|uid={0},ou=users,dc=example,dc=com
|===

[[config_dbms.security.ldap.authorization.group_membership_attributes]]
.dbms.security.ldap.authorization.group_membership_attributes
[cols="<1h,<4"]
|===
|Description
a|A list of attribute names on a user object that contains groups to be used for mapping to roles when LDAP authorization is enabled.
|Valid values
a|dbms.security.ldap.authorization.group_membership_attributes is a list separated by "," where items are a string
|Default value
m|[memberOf]
|===

[[config_dbms.security.ldap.authorization.group_to_role_mapping]]
.dbms.security.ldap.authorization.group_to_role_mapping
[cols="<1h,<4"]
|===
|Description
a|An authorization mapping from LDAP group names to Neo4j role names. The map should be formatted as a semicolon separated list of key-value pairs, where the key is the LDAP group name and the value is a comma separated list of corresponding role names. For example: group1=role1;group2=role2;group3=role3,role4,role5
You could also use whitespaces and quotes around group names to make this mapping more readable, for example: 
----
dbms.security.ldap.authorization.group_to_role_mapping=\
         "cn=Neo4j Read Only,cn=users,dc=example,dc=com"      = reader;    \
         "cn=Neo4j Read-Write,cn=users,dc=example,dc=com"     = publisher; \
         "cn=Neo4j Schema Manager,cn=users,dc=example,dc=com" = architect; \
         "cn=Neo4j Administrator,cn=users,dc=example,dc=com"  = admin
----
Deprecated: This will be replaced by dynamic configuration in the system graph in 4.0, including a migration step for the existing setting value. +

|Valid values
a|dbms.security.ldap.authorization.group_to_role_mapping is a string
|Deprecated
a|The `dbms.security.ldap.authorization.group_to_role_mapping` configuration setting has been deprecated.
|===

[[config_dbms.security.ldap.authorization.system_password]]
.dbms.security.ldap.authorization.system_password
[cols="<1h,<4"]
|===
|Description
a|An LDAP system account password to use for authorization searches when `<<config_dbms.security.ldap.authorization.use_system_account,dbms.security.ldap.authorization.use_system_account>>` is `true`.
|Valid values
a|dbms.security.ldap.authorization.system_password is a string
|===

[[config_dbms.security.ldap.authorization.system_username]]
.dbms.security.ldap.authorization.system_username
[cols="<1h,<4"]
|===
|Description
a|An LDAP system account username to use for authorization searches when `<<config_dbms.security.ldap.authorization.use_system_account,dbms.security.ldap.authorization.use_system_account>>` is `true`. Note that the `<<config_dbms.security.ldap.authentication.user_dn_template,dbms.security.ldap.authentication.user_dn_template>>` will not be applied to this username, so you may have to specify a full DN.
|Valid values
a|dbms.security.ldap.authorization.system_username is a string
|===

[[config_dbms.security.ldap.authorization.use_system_account]]
.dbms.security.ldap.authorization.use_system_account
[cols="<1h,<4"]
|===
|Description
a|Perform LDAP search for authorization info using a system account instead of the user's own account.
If this is set to `false` (default), the search for group membership will be performed directly after authentication using the LDAP context bound with the user's own account. The mapped roles will be cached for the duration of `<<config_dbms.security.auth_cache_ttl,dbms.security.auth_cache_ttl>>`, and then expire, requiring re-authentication. To avoid frequently having to re-authenticate sessions you may want to set a relatively long auth cache expiration time together with this option. NOTE: This option will only work if the users are permitted to search for their own group membership attributes in the directory.
If this is set to `true`, the search will be performed using a special system account user with read access to all the users in the directory. You need to specify the username and password using the settings `<<config_dbms.security.ldap.authorization.system_username,dbms.security.ldap.authorization.system_username>>` and `<<config_dbms.security.ldap.authorization.system_password,dbms.security.ldap.authorization.system_password>>` with this option. Note that this account only needs read access to the relevant parts of the LDAP directory and does not need to have access rights to Neo4j, or any other systems.
|Valid values
a|dbms.security.ldap.authorization.use_system_account is a boolean
|Default value
m|false
|===

[[config_dbms.security.ldap.authorization.user_search_base]]
.dbms.security.ldap.authorization.user_search_base
[cols="<1h,<4"]
|===
|Description
a|The name of the base object or named context to search for user objects when LDAP authorization is enabled. A common case is that this matches the last part of `<<config_dbms.security.ldap.authentication.user_dn_template,dbms.security.ldap.authentication.user_dn_template>>`.
|Valid values
a|dbms.security.ldap.authorization.user_search_base is a string
|Default value
m|ou=users,dc=example,dc=com
|===

[[config_dbms.security.ldap.authorization.user_search_filter]]
.dbms.security.ldap.authorization.user_search_filter
[cols="<1h,<4"]
|===
|Description
a|The LDAP search filter to search for a user principal when LDAP authorization is enabled. The filter should contain the placeholder token {0} which will be substituted for the user principal.
|Valid values
a|dbms.security.ldap.authorization.user_search_filter is a string
|Default value
m|(&(objectClass=*)(uid={0}))
|===

[[config_dbms.security.ldap.connection_timeout]]
.dbms.security.ldap.connection_timeout
[cols="<1h,<4"]
|===
|Description
a|The timeout for establishing an LDAP connection. If a connection with the LDAP server cannot be established within the given time the attempt is aborted. A value of 0 means to use the network protocol's (i.e., TCP's) timeout value.
|Valid values
a|dbms.security.ldap.connection_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|30s
|===

[[config_dbms.security.ldap.host]]
.dbms.security.ldap.host
[cols="<1h,<4"]
|===
|Description
a|URL of LDAP server to use for authentication and authorization. The format of the setting is `<protocol>://<hostname>:<port>`, where hostname is the only required field. The supported values for protocol are `ldap` (default) and `ldaps`. The default port for `ldap` is 389 and for `ldaps` 636. For example: `ldaps://ldap.example.com:10389`.
You may want to consider using STARTTLS (`<<config_dbms.security.ldap.use_starttls,dbms.security.ldap.use_starttls>>`) instead of LDAPS for secure connections, in which case the correct protocol is `ldap`.
|Valid values
a|dbms.security.ldap.host is a string
|Default value
m|localhost
|===

[[config_dbms.security.ldap.read_timeout]]
.dbms.security.ldap.read_timeout
[cols="<1h,<4"]
|===
|Description
a|The timeout for an LDAP read request (i.e. search). If the LDAP server does not respond within the given time the request will be aborted. A value of 0 means wait for a response indefinitely.
|Valid values
a|dbms.security.ldap.read_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|30s
|===

[[config_dbms.security.ldap.referral]]
.dbms.security.ldap.referral
[cols="<1h,<4"]
|===
|Description
a|The LDAP referral behavior when creating a connection. This is one of `follow`, `ignore` or `throw`.
* `follow` automatically follows any referrals
* `ignore` ignores any referrals
* `throw` throws an exception, which will lead to authentication failure.
|Valid values
a|dbms.security.ldap.referral is a string
|Default value
m|follow
|===

[[config_dbms.security.ldap.use_starttls]]
.dbms.security.ldap.use_starttls
[cols="<1h,<4"]
|===
|Description
a|Use secure communication with the LDAP server using opportunistic TLS. First an initial insecure connection will be made with the LDAP server, and a STARTTLS command will be issued to negotiate an upgrade of the connection to TLS before initiating authentication.
|Valid values
a|dbms.security.ldap.use_starttls is a boolean
|Default value
m|false
|===

[[config_dbms.security.log_successful_authentication]]
.dbms.security.log_successful_authentication
[cols="<1h,<4"]
|===
|Description
a|Set to log successful authentication events to the security log. If this is set to `false` only failed authentication events will be logged, which could be useful if you find that the successful events spam the logs too much, and you do not require full auditing capability.
|Valid values
a|dbms.security.log_successful_authentication is a boolean
|Default value
m|true
|===

[[config_dbms.security.procedures.default_allowed]]
.dbms.security.procedures.default_allowed
[cols="<1h,<4"]
|===
|Description
a|The default role that can execute all procedures and user-defined functions that are not covered by the `<<config_dbms.security.procedures.roles,dbms.security.procedures.roles>>` setting. If the ``dbms.security.procedures.default_allowed`` setting is the empty string (default), procedures will be executed according to the same security rules as normal Cypher statements.
Deprecated: This will be replaced by dynamic configuration in the system graph in 4.0, including a migration step for the existing setting value.
|Valid values
a|dbms.security.procedures.default_allowed is a string
|Default value
m|
|Deprecated
a|The `dbms.security.procedures.default_allowed` configuration setting has been deprecated.
|===

[[config_dbms.security.procedures.roles]]
.dbms.security.procedures.roles
[cols="<1h,<4"]
|===
|Description
a|This provides a finer level of control over which roles can execute procedures than the `<<config_dbms.security.procedures.default_allowed,dbms.security.procedures.default_allowed>>` setting. For example: `+dbms.security.procedures.roles=apoc.convert.*:reader;apoc.load.json*:writer;apoc.trigger.add:TriggerHappy+` will allow the role `reader` to execute all procedures in the `apoc.convert` namespace, the role `writer` to execute all procedures in the `apoc.load` namespace that starts with `json` and the role `TriggerHappy` to execute the specific procedure `apoc.trigger.add`. Procedures not matching any of these patterns will be subject to the `<<config_dbms.security.procedures.default_allowed,dbms.security.procedures.default_allowed>>` setting.
Deprecated: This will be replaced by dynamic configuration in the system graph in 4.0, including a migration step for the existing setting value.
|Valid values
a|dbms.security.procedures.roles is a string
|Default value
m|
|Deprecated
a|The `dbms.security.procedures.roles` configuration setting has been deprecated.
|===

[[config_dbms.security.procedures.unrestricted]]
.dbms.security.procedures.unrestricted
[cols="<1h,<4"]
|===
|Description
a|A list of procedures and user defined functions (comma separated) that are allowed full access to the database. The list may contain both fully-qualified procedure names, and partial names with the wildcard '*'. Note that this enables these procedures to bypass security. Use with caution.
|Valid values
a|dbms.security.procedures.unrestricted is a string
|Default value
m|
|===

[[config_dbms.security.procedures.whitelist]]
.dbms.security.procedures.whitelist
[cols="<1h,<4"]
|===
|Description
a|A list of procedures (comma separated) that are to be loaded. The list may contain both fully-qualified procedure names, and partial names with the wildcard '*'. If this setting is left empty no procedures will be loaded.
|Valid values
a|dbms.security.procedures.whitelist is a string
|Default value
m|*
|===

[[config_dbms.security.property_level.blacklist]]
.dbms.security.property_level.blacklist
[cols="<1h,<4"]
|===
|Description
a|An authorization mapping for property level access for roles. The map should be formatted as a semicolon separated list of key-value pairs, where the key is the role name and the value is a comma separated list of blacklisted properties. For example: role1=prop1;role2=prop2;role3=prop3,prop4,prop5
You could also use whitespaces and quotes around group names to make this mapping more readable, for example: `dbms.security.property_level.blacklist`=\
         "role1"      = ssn;    \
         "role2"      = ssn,income; \
Deprecated: This will be replaced by dynamic configuration in the system graph in 4.0, including a migration step for the existing setting value.
|Valid values
a|dbms.security.property_level.blacklist is a string
|Deprecated
a|The `dbms.security.property_level.blacklist` configuration setting has been deprecated.
|===

[[config_dbms.security.property_level.enabled]]
.dbms.security.property_level.enabled
[cols="<1h,<4"]
|===
|Description
a|Set to true to enable property level security.
|Valid values
a|dbms.security.property_level.enabled is a boolean
|Default value
m|false
|Deprecated
a|The `dbms.security.property_level.enabled` configuration setting has been deprecated.
|===

[[config_dbms.shutdown_transaction_end_timeout]]
.dbms.shutdown_transaction_end_timeout
[cols="<1h,<4"]
|===
|Description
a|The maximum amount of time to wait for running transactions to complete before allowing initiated database shutdown to continue.
|Valid values
a|dbms.shutdown_transaction_end_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|10s
|===

[[config_dbms.ssl.policy.-policyname-.allow_key_generation]]
.dbms.ssl.policy.<policyname>.allow_key_generation
[cols="<1h,<4"]
|===
|Description
a|Allows the generation of a private key and associated self-signed certificate. Only performed when both objects cannot be found.
|Valid values
a|dbms.ssl.policy.<policyname>.allow_key_generation is a boolean
|Default value
m|false
|===

[[config_dbms.ssl.policy.-policyname-.base_directory]]
.dbms.ssl.policy.<policyname>.base_directory
[cols="<1h,<4"]
|===
|Description
a|The mandatory base directory for cryptographic objects of this policy. It is also possible to override each individual configuration with absolute paths.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|===

[[config_dbms.ssl.policy.-policyname-.ciphers]]
.dbms.ssl.policy.<policyname>.ciphers
[cols="<1h,<4"]
|===
|Description
a|Restrict allowed ciphers.
|Valid values
a|dbms.ssl.policy.<policyname>.ciphers is a list separated by "," where items are a string
|===

[[config_dbms.ssl.policy.-policyname-.client_auth]]
.dbms.ssl.policy.<policyname>.client_auth
[cols="<1h,<4"]
|===
|Description
a|Client authentication stance.
|Valid values
a|dbms.ssl.policy.<policyname>.client_auth is one of `NONE`, `OPTIONAL`, `REQUIRE`
|Default value
m|REQUIRE
|===

[[config_dbms.ssl.policy.-policyname-.private_key]]
.dbms.ssl.policy.<policyname>.private_key
[cols="<1h,<4"]
|===
|Description
a|Private PKCS#8 key in PEM format.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|private.key
|===

[[config_dbms.ssl.policy.-policyname-.public_certificate]]
.dbms.ssl.policy.<policyname>.public_certificate
[cols="<1h,<4"]
|===
|Description
a|X.509 certificate (chain) of this server in PEM format.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|public.crt
|===

[[config_dbms.ssl.policy.-policyname-.revoked_dir]]
.dbms.ssl.policy.<policyname>.revoked_dir
[cols="<1h,<4"]
|===
|Description
a|Path to directory of CRLs (Certificate Revocation Lists) in PEM format.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|revoked
|===

[[config_dbms.ssl.policy.-policyname-.tls_versions]]
.dbms.ssl.policy.<policyname>.tls_versions
[cols="<1h,<4"]
|===
|Description
a|Restrict allowed TLS protocol versions.
|Valid values
a|dbms.ssl.policy.<policyname>.tls_versions is a list separated by "," where items are a string
|Default value
m|[TLSv1.2]
|===

[[config_dbms.ssl.policy.-policyname-.trust_all]]
.dbms.ssl.policy.<policyname>.trust_all
[cols="<1h,<4"]
|===
|Description
a|Makes this policy trust all remote parties. Enabling this is not recommended and the trusted directory will be ignored.
|Valid values
a|dbms.ssl.policy.<policyname>.trust_all is a boolean
|Default value
m|false
|===

[[config_dbms.ssl.policy.-policyname-.trusted_dir]]
.dbms.ssl.policy.<policyname>.trusted_dir
[cols="<1h,<4"]
|===
|Description
a|Path to directory of X.509 certificates in PEM format for trusted parties.
|Valid values
a|A filesystem path; relative paths are resolved against the root, _<unsupported.dbms.directories.neo4j_home>_
|Default value
m|trusted
|===

[[config_dbms.ssl.policy.-policyname-.verify_hostname]]
.dbms.ssl.policy.<policyname>.verify_hostname
[cols="<1h,<4"]
|===
|Description
a|When true, this node will verify the hostname of every other instance it connects to by comparing the address it used to connect with it and the patterns described in the remote hosts public certificate Subject Alternative Names.
|Valid values
a|dbms.ssl.policy.<policyname>.verify_hostname is a boolean
|Default value
m|false
|===

[[config_dbms.threads.worker_count]]
.dbms.threads.worker_count
[cols="<1h,<4"]
|===
|Description
a|Number of Neo4j worker threads. This setting is only valid for REST, and does not influence bolt-server. It sets the amount of worker threads for the Jetty server used by neo4j-server. This option can be tuned when you plan to execute multiple, concurrent REST requests, with the aim of getting more throughput from the database. Your OS might enforce a lower limit than the maximum value specified here.
|Valid values
a|dbms.threads.worker_count is an integer which is in the range `1` to `44738`
|Default value
m|Number of available processors, or 500 for machines which have more than 500 processors.
|===

[[config_dbms.track_query_allocation]]
.dbms.track_query_allocation
[cols="<1h,<4"]
|===
|Description
a|Enables or disables tracking of how many bytes are allocated by the execution of a query. Calling `dbms.listQueries` will display the time. This can also be logged in the query log by using `log_queries_allocation_logging_enabled`.
|Valid values
a|dbms.track_query_allocation is a boolean
|Dynamic a|true
|Default value
m|false
|===

[[config_dbms.track_query_cpu_time]]
.dbms.track_query_cpu_time
[cols="<1h,<4"]
|===
|Description
a|Enables or disables tracking of how much time a query spends actively executing on the CPU. Calling `dbms.listQueries` will display the time. This can also be logged in the query log by using `<<config_dbms.logs.query.time_logging_enabled,dbms.logs.query.time_logging_enabled>>`.
|Valid values
a|dbms.track_query_cpu_time is a boolean
|Dynamic a|true
|Default value
m|false
|===

[[config_dbms.transaction.bookmark_ready_timeout]]
.dbms.transaction.bookmark_ready_timeout
[cols="<1h,<4"]
|===
|Description
a|The maximum amount of time to wait for the database state represented by the bookmark.
|Valid values
a|dbms.transaction.bookmark_ready_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's') which is minimum `PT1S`
|Default value
m|30s
|===

[[config_dbms.transaction.monitor.check.interval]]
.dbms.transaction.monitor.check.interval
[cols="<1h,<4"]
|===
|Description
a|Configures the time interval between transaction monitor checks. Determines how often monitor thread will check transaction for timeout.
|Valid values
a|dbms.transaction.monitor.check.interval is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|2s
|===

[[config_dbms.transaction.timeout]]
.dbms.transaction.timeout
[cols="<1h,<4"]
|===
|Description
a|The maximum time interval of a transaction within which it should be completed.
|Valid values
a|dbms.transaction.timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Dynamic a|true
|Default value
m|0s
|===

[[config_dbms.tx_log.rotation.retention_policy]]
.dbms.tx_log.rotation.retention_policy
[cols="<1h,<4"]
|===
|Description
a|Make Neo4j keep the logical transaction logs for being able to backup the database. Can be used for specifying the threshold to prune logical logs after. For example "10 days" will prune logical logs that only contains transactions older than 10 days from the current time, or "100k txs" will keep the 100k latest transactions and prune any older transactions.
|Valid values
a|dbms.tx_log.rotation.retention_policy is a string which must be `true`, `false` or of format `<number><optional unit> <type>`. Valid units are `k`, `M` and `G`. Valid types are `files`, `size`, `txs`, `entries`, `hours` and `days`. For example, `100M size` will limiting logical log space on disk to 100Mb, or `200k txs` will limiting the number of transactions to keep to 200 000 (matches the pattern `^(true{vbar}keep_all{vbar}false{vbar}keep_none{vbar}(\d+[KkMmGg]?( (files{vbar}size{vbar}txs{vbar}entries{vbar}hours{vbar}days))))$`)
|Dynamic a|true
|Default value
m|7 days
|===

[[config_dbms.tx_log.rotation.size]]
.dbms.tx_log.rotation.size
[cols="<1h,<4"]
|===
|Description
a|Specifies at which file size the logical log will auto-rotate. Minimum accepted value is 1M. 
|Valid values
a|dbms.tx_log.rotation.size is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`) which is minimum `1048576`
|Dynamic a|true
|Default value
m|262144000
|===

[[config_dbms.tx_state.max_off_heap_memory]]
.dbms.tx_state.max_off_heap_memory
[cols="<1h,<4"]
|===
|Description
a|The maximum amount of off-heap memory that can be used to store transaction state data; it's a total amount of memory shared across all active transactions. Zero means 'unlimited'. Used when <<config_dbms.tx_state.memory_allocation,dbms.tx_state.memory_allocation>> is set to 'OFF_HEAP'.
|Valid values
a|dbms.tx_state.max_off_heap_memory is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`) which is minimum `0`
|Default value
m|2147483648
|===

[[config_dbms.tx_state.memory_allocation]]
.dbms.tx_state.memory_allocation
[cols="<1h,<4"]
|===
|Description
a|Defines whether memory for transaction state should be allocated on- or off-heap.
|Valid values
a|dbms.tx_state.memory_allocation is one of `ON_HEAP`, `OFF_HEAP`
|Default value
m|ON_HEAP
|===

[[config_dbms.tx_state.off_heap.block_cache_size]]
.dbms.tx_state.off_heap.block_cache_size
[cols="<1h,<4"]
|===
|Description
a|Defines the size of the off-heap memory blocks cache. The cache will contain this number of blocks for each block size that is power of two. Thus, maximum amount of memory used by blocks cache can be calculated as 2 * <<config_dbms.tx_state.off_heap.max_cacheable_block_size,dbms.tx_state.off_heap.max_cacheable_block_size>> * `dbms.tx_state.off_heap.block_cache_size`
|Valid values
a|dbms.tx_state.off_heap.block_cache_size is an integer which is minimum `16`
|Default value
m|128
|===

[[config_dbms.tx_state.off_heap.max_cacheable_block_size]]
.dbms.tx_state.off_heap.max_cacheable_block_size
[cols="<1h,<4"]
|===
|Description
a|Defines the maximum size of an off-heap memory block that can be cached to speed up allocations for transaction state data. The value must be a power of 2.
|Valid values
a|dbms.tx_state.off_heap.max_cacheable_block_size is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`) which is minimum `4096`, and is power of 2
|Default value
m|524288
|===

[[config_dbms.udc.enabled]]
.dbms.udc.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable the UDC extension.
|Valid values
a|dbms.udc.enabled is a boolean
|Default value
m|true
|===

[[config_dbms.unmanaged_extension_classes]]
.dbms.unmanaged_extension_classes
[cols="<1h,<4"]
|===
|Description
a|Comma-separated list of <classname>=<mount point> for unmanaged extensions.
|Valid values
a|dbms.unmanaged_extension_classes is a comma-separated list of <classname>=<mount point> strings
|Default value
m|[]
|===

[[config_dbms.windows_service_name]]
.dbms.windows_service_name
[cols="<1h,<4"]
|===
|Description
a|Name of the Windows Service.
|Valid values
a|a string
|===

[[config_ha.allow_init_cluster]]
.ha.allow_init_cluster
[cols="<1h,<4"]
|===
|Description
a|Whether to allow this instance to create a cluster if unable to join.
|Valid values
a|ha.allow_init_cluster is a boolean
|Default value
m|true
|===

[[config_ha.branched_data_copying_strategy]]
.ha.branched_data_copying_strategy
[cols="<1h,<4"]
|===
|Description
a|Strategy for how to order handling of branched data on slaves and copying of the store from the master. The default is copy_then_branch, which, when combined with the keep_last or keep_none branch handling strategies results in a safer branching strategy, as there is always a store present so store failure to copy a store (for example, because of network failure) does not leave the instance without a store.
|Valid values
a|ha.branched_data_copying_strategy is one of `branch_then_copy`, `copy_then_branch`
|Default value
m|branch_then_copy
|Deprecated
a|The `ha.branched_data_copying_strategy` configuration setting has been deprecated.
|===

[[config_ha.branched_data_policy]]
.ha.branched_data_policy
[cols="<1h,<4"]
|===
|Description
a|Policy for how to handle branched data.
|Valid values
a|ha.branched_data_policy is one of `keep_all`, `keep_last`, `keep_none`
|Default value
m|keep_all
|Deprecated
a|The `ha.branched_data_policy` configuration setting has been deprecated.
|===

[[config_ha.broadcast_timeout]]
.ha.broadcast_timeout
[cols="<1h,<4"]
|===
|Description
a|Timeout for broadcasting values in cluster. Must consider end-to-end duration of Paxos algorithm. This value is the default value for the <<config_ha.join_timeout,ha.join_timeout>> and <<config_ha.leave_timeout,ha.leave_timeout>> settings.
|Valid values
a|ha.broadcast_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|30s
|===

[[config_ha.configuration_timeout]]
.ha.configuration_timeout
[cols="<1h,<4"]
|===
|Description
a|Timeout for waiting for configuration from an existing cluster member during cluster join.
|Valid values
a|ha.configuration_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|1s
|===

[[config_ha.data_chunk_size]]
.ha.data_chunk_size
[cols="<1h,<4"]
|===
|Description
a|Max size of the data chunks that flows between master and slaves in HA. Bigger size may increase throughput, but may also be more sensitive to variations in bandwidth, whereas lower size increases tolerance for bandwidth variations.
|Valid values
a|ha.data_chunk_size is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`) which is minimum `1024`
|Default value
m|2097152
|Deprecated
a|The `ha.data_chunk_size` configuration setting has been deprecated.
|===

[[config_ha.default_timeout]]
.ha.default_timeout
[cols="<1h,<4"]
|===
|Description
a|Default timeout used for clustering timeouts. Override  specific timeout settings with proper values if necessary. This value is the default value for the <<config_ha.heartbeat_interval,ha.heartbeat_interval>>, <<config_ha.paxos_timeout,ha.paxos_timeout>> and <<config_ha.learn_timeout,ha.learn_timeout>> settings.
|Valid values
a|ha.default_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|5s
|===

[[config_ha.election_timeout]]
.ha.election_timeout
[cols="<1h,<4"]
|===
|Description
a|Timeout for waiting for other members to finish a role election. Defaults to <<config_ha.paxos_timeout,ha.paxos_timeout>>.
|Valid values
a|ha.election_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|5s
|===

[[config_ha.heartbeat_interval]]
.ha.heartbeat_interval
[cols="<1h,<4"]
|===
|Description
a|How often heartbeat messages should be sent. Defaults to <<config_ha.default_timeout,ha.default_timeout>>.
|Valid values
a|ha.heartbeat_interval is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|5s
|===

[[config_ha.heartbeat_timeout]]
.ha.heartbeat_timeout
[cols="<1h,<4"]
|===
|Description
a|How long to wait for heartbeats from other instances before marking them as suspects for failure. This value reflects considerations of network latency, expected duration of garbage collection pauses and other factors that can delay message sending and processing. Larger values will result in more stable masters but also will result in longer waits before a failover in case of master failure. This value should not be set to less than twice the <<config_ha.heartbeat_interval,ha.heartbeat_interval>> value otherwise there is a high risk of frequent master switches and possibly branched data occurrence.
|Valid values
a|ha.heartbeat_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|40s
|===

[[config_ha.host.coordination]]
.ha.host.coordination
[cols="<1h,<4"]
|===
|Description
a|Host and port to bind the cluster management communication.
|Valid values
a|ha.host.coordination is a hostname and port
|Default value
m|0.0.0.0:5001-5099
|===

[[config_ha.host.data]]
.ha.host.data
[cols="<1h,<4"]
|===
|Description
a|Hostname and port to bind the HA server.
|Valid values
a|ha.host.data is a hostname and port
|Default value
m|0.0.0.0:6001-6011
|Deprecated
a|The `ha.host.data` configuration setting has been deprecated.
|===

[[config_ha.initial_hosts]]
.ha.initial_hosts
[cols="<1h,<4"]
|===
|Description
a|A comma-separated list of other members of the cluster to join.
|Valid values
a|ha.initial_hosts is a list separated by "," where items are a hostname and port
|===

[[config_ha.internal_role_switch_timeout]]
.ha.internal_role_switch_timeout
[cols="<1h,<4"]
|===
|Description
a|Timeout for waiting for internal conditions during state switch, like for transactions to complete, before switching to master or slave.
|Valid values
a|ha.internal_role_switch_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|10s
|Deprecated
a|The `ha.internal_role_switch_timeout` configuration setting has been deprecated.
|===

[[config_ha.join_timeout]]
.ha.join_timeout
[cols="<1h,<4"]
|===
|Description
a|Timeout for joining a cluster. Defaults to <<config_ha.broadcast_timeout,ha.broadcast_timeout>>. Note that if the timeout expires during cluster formation, the operator may have to restart the instance or instances.
|Valid values
a|ha.join_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|30s
|===

[[config_ha.learn_timeout]]
.ha.learn_timeout
[cols="<1h,<4"]
|===
|Description
a|Timeout for learning values. Defaults to <<config_ha.default_timeout,ha.default_timeout>>.
|Valid values
a|ha.learn_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|5s
|===

[[config_ha.leave_timeout]]
.ha.leave_timeout
[cols="<1h,<4"]
|===
|Description
a|Timeout for waiting for cluster leave to finish. Defaults to <<config_ha.broadcast_timeout,ha.broadcast_timeout>>.
|Valid values
a|ha.leave_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|30s
|===

[[config_ha.max_acceptors]]
.ha.max_acceptors
[cols="<1h,<4"]
|===
|Description
a|Maximum number of servers to involve when agreeing to membership changes. In very large clusters, the probability of half the cluster failing is low, but protecting against any arbitrary half failing is expensive. Therefore you may wish to set this parameter to a value less than the cluster size.
|Valid values
a|ha.max_acceptors is an integer which is minimum `1`
|Default value
m|21
|===

[[config_ha.max_channels_per_slave]]
.ha.max_channels_per_slave
[cols="<1h,<4"]
|===
|Description
a|Maximum number of connections a slave can have to the master.
|Valid values
a|ha.max_channels_per_slave is an integer which is minimum `1`
|Default value
m|20
|Deprecated
a|The `ha.max_channels_per_slave` configuration setting has been deprecated.
|===

[[config_ha.paxos_timeout]]
.ha.paxos_timeout
[cols="<1h,<4"]
|===
|Description
a|Default value for all Paxos timeouts. This setting controls the default value for the <<config_ha.phase1_timeout,ha.phase1_timeout>>, <<config_ha.phase2_timeout,ha.phase2_timeout>> and <<config_ha.election_timeout,ha.election_timeout>> settings. If it is not given a value it defaults to <<config_ha.default_timeout,ha.default_timeout>> and will implicitly change if <<config_ha.default_timeout,ha.default_timeout>> changes. This is an advanced parameter which should only be changed if specifically advised by Neo4j Professional Services.
|Valid values
a|ha.paxos_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|5s
|===

[[config_ha.phase1_timeout]]
.ha.phase1_timeout
[cols="<1h,<4"]
|===
|Description
a|Timeout for Paxos phase 1. If it is not given a value it defaults to <<config_ha.paxos_timeout,ha.paxos_timeout>> and will implicitly change if <<config_ha.paxos_timeout,ha.paxos_timeout>> changes. This is an advanced parameter which should only be changed if specifically advised by Neo4j Professional Services. 
|Valid values
a|ha.phase1_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|5s
|===

[[config_ha.phase2_timeout]]
.ha.phase2_timeout
[cols="<1h,<4"]
|===
|Description
a|Timeout for Paxos phase 2. If it is not given a value it defaults to <<config_ha.paxos_timeout,ha.paxos_timeout>> and will implicitly change if <<config_ha.paxos_timeout,ha.paxos_timeout>> changes. This is an advanced parameter which should only be changed if specifically advised by Neo4j Professional Services. 
|Valid values
a|ha.phase2_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|5s
|===

[[config_ha.pull_batch_size]]
.ha.pull_batch_size
[cols="<1h,<4"]
|===
|Description
a|Size of batches of transactions applied on slaves when pulling from master.
|Valid values
a|ha.pull_batch_size is an integer
|Default value
m|100
|Deprecated
a|The `ha.pull_batch_size` configuration setting has been deprecated.
|===

[[config_ha.pull_interval]]
.ha.pull_interval
[cols="<1h,<4"]
|===
|Description
a|Interval of pulling updates from master.
|Valid values
a|ha.pull_interval is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|10s
|Deprecated
a|The `ha.pull_interval` configuration setting has been deprecated.
|===

[[config_ha.role_switch_timeout]]
.ha.role_switch_timeout
[cols="<1h,<4"]
|===
|Description
a|Timeout for request threads waiting for instance to become master or slave.
|Valid values
a|ha.role_switch_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|120s
|Deprecated
a|The `ha.role_switch_timeout` configuration setting has been deprecated.
|===

[[config_ha.server_id]]
.ha.server_id
[cols="<1h,<4"]
|===
|Description
a|Id for a cluster instance. Must be unique within the cluster.
|Valid values
a|ha.server_id is an instance id, which has to be a valid integer
|===

[[config_ha.slave_lock_timeout]]
.ha.slave_lock_timeout
[cols="<1h,<4"]
|===
|Description
a|Timeout for taking remote (write) locks on slaves. Defaults to <<config_ha.slave_read_timeout,ha.slave_read_timeout>>.
|Valid values
a|ha.slave_lock_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|20s
|Deprecated
a|The `ha.slave_lock_timeout` configuration setting has been deprecated.
|===

[[config_ha.slave_only]]
.ha.slave_only
[cols="<1h,<4"]
|===
|Description
a|Whether this instance should only participate as slave in cluster. If set to `true`, it will never be elected as master.
|Valid values
a|ha.slave_only is a boolean
|Default value
m|false
|Deprecated
a|The `ha.slave_only` configuration setting has been deprecated.
|===

[[config_ha.slave_read_timeout]]
.ha.slave_read_timeout
[cols="<1h,<4"]
|===
|Description
a|How long a slave will wait for response from master before giving up.
|Valid values
a|ha.slave_read_timeout is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|20s
|Deprecated
a|The `ha.slave_read_timeout` configuration setting has been deprecated.
|===

[[config_ha.tx_push_factor]]
.ha.tx_push_factor
[cols="<1h,<4"]
|===
|Description
a|The amount of slaves the master will ask to replicate a committed transaction. 
|Valid values
a|ha.tx_push_factor is an integer which is minimum `0`
|Default value
m|1
|Deprecated
a|The `ha.tx_push_factor` configuration setting has been deprecated.
|===

[[config_ha.tx_push_strategy]]
.ha.tx_push_strategy
[cols="<1h,<4"]
|===
|Description
a|Push strategy of a transaction to a slave during commit.
|Valid values
a|ha.tx_push_strategy is one of `round_robin`, `fixed_descending`, `fixed_ascending`
|Default value
m|fixed_ascending
|Deprecated
a|The `ha.tx_push_strategy` configuration setting has been deprecated.
|===

[[config_https.ssl_policy]]
.https.ssl_policy
[cols="<1h,<4"]
|===
|Description
a|SSL policy name.
|Valid values
a|https.ssl_policy is a string
|Default value
m|legacy
|===

[[config_metrics.bolt.messages.enabled]]
.metrics.bolt.messages.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about Bolt Protocol message processing.
|Valid values
a|metrics.bolt.messages.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.csv.enabled]]
.metrics.csv.enabled
[cols="<1h,<4"]
|===
|Description
a|Set to `true` to enable exporting metrics to CSV files.
|Valid values
a|metrics.csv.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.csv.interval]]
.metrics.csv.interval
[cols="<1h,<4"]
|===
|Description
a|The reporting interval for the CSV files. That is, how often new rows with numbers are appended to the CSV files.
|Valid values
a|metrics.csv.interval is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|3s
|===

[[config_metrics.csv.rotation.keep_number]]
.metrics.csv.rotation.keep_number
[cols="<1h,<4"]
|===
|Description
a|Maximum number of history files for the csv files.
|Valid values
a|metrics.csv.rotation.keep_number is an integer which is minimum `1`
|Default value
m|7
|===

[[config_metrics.csv.rotation.size]]
.metrics.csv.rotation.size
[cols="<1h,<4"]
|===
|Description
a|The file size in bytes at which the csv files will auto-rotate. If set to zero then no rotation will occur. Accepts a binary suffix `k`, `m` or `g`.
|Valid values
a|metrics.csv.rotation.size is a byte size (valid multipliers are `k`, `m`, `g`, `K`, `M`, `G`) which is in the range `0` to `9223372036854775807`
|Default value
m|10485760
|===

[[config_metrics.cypher.replanning.enabled]]
.metrics.cypher.replanning.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about number of occurred replanning events.
|Valid values
a|metrics.cypher.replanning.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.enabled]]
.metrics.enabled
[cols="<1h,<4"]
|===
|Description
a|The default enablement value for all the supported metrics. Set this to `false` to turn off all metrics by default. The individual settings can then be used to selectively re-enable specific metrics.
|Valid values
a|metrics.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.graphite.enabled]]
.metrics.graphite.enabled
[cols="<1h,<4"]
|===
|Description
a|Set to `true` to enable exporting metrics to Graphite.
|Valid values
a|metrics.graphite.enabled is a boolean
|Default value
m|false
|===

[[config_metrics.graphite.interval]]
.metrics.graphite.interval
[cols="<1h,<4"]
|===
|Description
a|The reporting interval for Graphite. That is, how often to send updated metrics to Graphite.
|Valid values
a|metrics.graphite.interval is a duration (Valid units are: 'ms', 's', 'm' and 'h'; default unit is 's')
|Default value
m|3s
|===

[[config_metrics.graphite.server]]
.metrics.graphite.server
[cols="<1h,<4"]
|===
|Description
a|The hostname or IP address of the Graphite server.
|Valid values
a|metrics.graphite.server is a hostname and port
|Default value
m|:2003
|===

[[config_metrics.jvm.buffers.enabled]]
.metrics.jvm.buffers.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about the buffer pools.
|Valid values
a|metrics.jvm.buffers.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.jvm.gc.enabled]]
.metrics.jvm.gc.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about the duration of garbage collections.
|Valid values
a|metrics.jvm.gc.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.jvm.memory.enabled]]
.metrics.jvm.memory.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about the memory usage.
|Valid values
a|metrics.jvm.memory.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.jvm.threads.enabled]]
.metrics.jvm.threads.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about the current number of threads running.
|Valid values
a|metrics.jvm.threads.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.neo4j.causal_clustering.enabled]]
.metrics.neo4j.causal_clustering.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about Causal Clustering mode.
|Valid values
a|metrics.neo4j.causal_clustering.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.neo4j.checkpointing.enabled]]
.metrics.neo4j.checkpointing.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about Neo4j check pointing; when it occurs and how much time it takes to complete.
|Valid values
a|metrics.neo4j.checkpointing.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.neo4j.cluster.enabled]]
.metrics.neo4j.cluster.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about HA cluster info.
|Valid values
a|metrics.neo4j.cluster.enabled is a boolean
|Default value
m|true
|Deprecated
a|The `metrics.neo4j.cluster.enabled` configuration setting has been deprecated.
|===

[[config_metrics.neo4j.counts.enabled]]
.metrics.neo4j.counts.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about approximately how many entities are in the database; nodes, relationships, properties, etc.
|Valid values
a|metrics.neo4j.counts.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.neo4j.enabled]]
.metrics.neo4j.enabled
[cols="<1h,<4"]
|===
|Description
a|The default enablement value for all Neo4j specific support metrics. Set this to `false` to turn off all Neo4j specific metrics by default. The individual `metrics.neo4j.*` metrics can then be turned on selectively.
|Valid values
a|metrics.neo4j.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.neo4j.logrotation.enabled]]
.metrics.neo4j.logrotation.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about the Neo4j log rotation; when it occurs and how much time it takes to complete.
|Valid values
a|metrics.neo4j.logrotation.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.neo4j.network.enabled]]
.metrics.neo4j.network.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about the network usage.
|Valid values
a|metrics.neo4j.network.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.neo4j.pagecache.enabled]]
.metrics.neo4j.pagecache.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about the Neo4j page cache; page faults, evictions, flushes, exceptions, etc.
|Valid values
a|metrics.neo4j.pagecache.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.neo4j.server.enabled]]
.metrics.neo4j.server.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about Server threading info.
|Valid values
a|metrics.neo4j.server.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.neo4j.tx.enabled]]
.metrics.neo4j.tx.enabled
[cols="<1h,<4"]
|===
|Description
a|Enable reporting metrics about transactions; number of transactions started, committed, etc.
|Valid values
a|metrics.neo4j.tx.enabled is a boolean
|Default value
m|true
|===

[[config_metrics.prefix]]
.metrics.prefix
[cols="<1h,<4"]
|===
|Description
a|A common prefix for the reported metrics field names. By default, this is either be 'neo4j', or a computed value based on the cluster and instance names, when running in an HA configuration.
|Valid values
a|metrics.prefix is a string
|Default value
m|neo4j
|===

[[config_metrics.prometheus.enabled]]
.metrics.prometheus.enabled
[cols="<1h,<4"]
|===
|Description
a|Set to `true` to enable the Prometheus endpoint.
|Valid values
a|metrics.prometheus.enabled is a boolean
|Default value
m|false
|===

[[config_metrics.prometheus.endpoint]]
.metrics.prometheus.endpoint
[cols="<1h,<4"]
|===
|Description
a|The hostname and port to use as Prometheus endpoint.
|Valid values
a|metrics.prometheus.endpoint is a hostname and port
|Default value
m|localhost:2004
|===

[[config_tools.consistency_checker.check_graph]]
.tools.consistency_checker.check_graph
[cols="<1h,<4"]
|===
|Description
a|This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead. Perform checks between nodes, relationships, properties, types and tokens.
|Valid values
a|tools.consistency_checker.check_graph is a boolean
|Default value
m|true
|Deprecated
a|The `tools.consistency_checker.check_graph` configuration setting has been deprecated.
|===

[[config_tools.consistency_checker.check_index_structure]]
.tools.consistency_checker.check_index_structure
[cols="<1h,<4"]
|===
|Description
a|This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead. Perform structural checks on indexes. This is done in separate step before consistency check on store starts. Checking indexes is more expensive than checking the native stores, so it may be useful to turn off this check for very large databases.
|Valid values
a|tools.consistency_checker.check_index_structure is a boolean
|Default value
m|false
|Deprecated
a|The `tools.consistency_checker.check_index_structure` configuration setting has been deprecated.
|===

[[config_tools.consistency_checker.check_indexes]]
.tools.consistency_checker.check_indexes
[cols="<1h,<4"]
|===
|Description
a|This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead. Perform checks on indexes. Checking indexes is more expensive than checking the native stores, so it may be useful to turn off this check for very large databases.
|Valid values
a|tools.consistency_checker.check_indexes is a boolean
|Default value
m|true
|Deprecated
a|The `tools.consistency_checker.check_indexes` configuration setting has been deprecated.
|===

[[config_tools.consistency_checker.check_label_scan_store]]
.tools.consistency_checker.check_label_scan_store
[cols="<1h,<4"]
|===
|Description
a|This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead. Perform checks on the label scan store. Checking this store is more expensive than checking the native stores, so it may be useful to turn off this check for very large databases.
|Valid values
a|tools.consistency_checker.check_label_scan_store is a boolean
|Default value
m|true
|Deprecated
a|The `tools.consistency_checker.check_label_scan_store` configuration setting has been deprecated.
|===

[[config_tools.consistency_checker.check_property_owners]]
.tools.consistency_checker.check_property_owners
[cols="<1h,<4"]
|===
|Description
a|This setting is deprecated. See commandline arguments for neoj4-admin check-consistency instead. Perform optional additional checking on property ownership. This can detect a theoretical inconsistency where a property could be owned by multiple entities. However, the check is very expensive in time and memory, so it is skipped by default.
|Valid values
a|tools.consistency_checker.check_property_owners is a boolean
|Default value
m|false
|Deprecated
a|The `tools.consistency_checker.check_property_owners` configuration setting has been deprecated.
|===

